{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quelle est la complexité temporelle du tri fusion ? D) O(log n) C) O(n) A) O(n log n) B) O(n^2) La réponse correcte est A) O(n log n).\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# modèle RNN\n",
    "class RNNModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = tf.keras.layers.SimpleRNN(hidden_size)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.embedding(inputs)\n",
    "        x = self.rnn(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "data = [\n",
    "    (\"Quel est l'algorithme de tri le plus rapide ?\", [\"A)Tri par insertion\", \"B)Tri fusion\", \"C)Tri rapide\", \"D)Tri à bulles\"], \"C)Tri rapide\"),\n",
    "    (\"Quelle est la complexité temporelle du tri fusion ?\", [\"A) O(n log n)\", \"B) O(n^2)\", \"C) O(n)\", \"D) O(log n)\"], \"A) O(n log n)\"),\n",
    "]\n",
    "\n",
    "# Encoder les données en indices\n",
    "word_to_ix = {}\n",
    "for question, options, _ in data:\n",
    "    for word in question.split():\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "    for option in options:\n",
    "        if option not in word_to_ix:\n",
    "            word_to_ix[option] = len(word_to_ix)\n",
    "\n",
    "# Taille du vocabulaire\n",
    "vocab_size = len(word_to_ix)\n",
    "\n",
    "embedding_dim = 10\n",
    "\n",
    "model = RNNModel(vocab_size, embedding_dim, 10)\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "for epoch in range(100):\n",
    "    random.shuffle(data)\n",
    "    for question, options, answer in data:\n",
    "        model.reset_states()\n",
    "        input_tensor = tf.constant([word_to_ix[word] for word in question.split()], dtype=tf.int32)\n",
    "        input_tensor = tf.expand_dims(input_tensor, axis=0) \n",
    "        target_tensor = tf.constant([word_to_ix[answer]], dtype=tf.int32) \n",
    "        with tf.GradientTape() as tape:\n",
    "            output = model(input_tensor)\n",
    "            loss = loss_fn(target_tensor, output)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "def generate_exam_question(question, options, answer):\n",
    "    random.shuffle(options)\n",
    "    exam_question = f\"{question} {' '.join(options)} La réponse correcte est {answer}.\"\n",
    "    return exam_question\n",
    "\n",
    "random_question, random_options, random_answer = random.choice(data)\n",
    "\n",
    "exam_question = generate_exam_question(random_question, random_options, random_answer)\n",
    "\n",
    "print(exam_question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 6.2058, Accuracy: 0.5000\n",
      "Epoch 2/100, Loss: 6.1328, Accuracy: 0.5000\n",
      "Epoch 3/100, Loss: 6.0677, Accuracy: 0.5000\n",
      "Epoch 4/100, Loss: 6.0042, Accuracy: 0.5000\n",
      "Epoch 5/100, Loss: 5.9414, Accuracy: 1.0000\n",
      "Epoch 6/100, Loss: 5.8791, Accuracy: 1.0000\n",
      "Epoch 7/100, Loss: 5.8170, Accuracy: 1.0000\n",
      "Epoch 8/100, Loss: 5.7549, Accuracy: 1.0000\n",
      "Epoch 9/100, Loss: 5.6927, Accuracy: 1.0000\n",
      "Epoch 10/100, Loss: 5.6302, Accuracy: 1.0000\n",
      "Epoch 11/100, Loss: 5.5672, Accuracy: 1.0000\n",
      "Epoch 12/100, Loss: 5.5035, Accuracy: 1.0000\n",
      "Epoch 13/100, Loss: 5.4391, Accuracy: 1.0000\n",
      "Epoch 14/100, Loss: 5.3736, Accuracy: 1.0000\n",
      "Epoch 15/100, Loss: 5.3071, Accuracy: 1.0000\n",
      "Epoch 16/100, Loss: 5.2395, Accuracy: 1.0000\n",
      "Epoch 17/100, Loss: 5.1705, Accuracy: 1.0000\n",
      "Epoch 18/100, Loss: 5.1003, Accuracy: 1.0000\n",
      "Epoch 19/100, Loss: 5.0287, Accuracy: 1.0000\n",
      "Epoch 20/100, Loss: 4.9558, Accuracy: 1.0000\n",
      "Epoch 21/100, Loss: 4.8815, Accuracy: 1.0000\n",
      "Epoch 22/100, Loss: 4.8059, Accuracy: 1.0000\n",
      "Epoch 23/100, Loss: 4.7292, Accuracy: 1.0000\n",
      "Epoch 24/100, Loss: 4.6514, Accuracy: 1.0000\n",
      "Epoch 25/100, Loss: 4.5728, Accuracy: 1.0000\n",
      "Epoch 26/100, Loss: 4.4937, Accuracy: 1.0000\n",
      "Epoch 27/100, Loss: 4.4141, Accuracy: 1.0000\n",
      "Epoch 28/100, Loss: 4.3345, Accuracy: 1.0000\n",
      "Epoch 29/100, Loss: 4.2551, Accuracy: 1.0000\n",
      "Epoch 30/100, Loss: 4.1762, Accuracy: 1.0000\n",
      "Epoch 31/100, Loss: 4.0978, Accuracy: 1.0000\n",
      "Epoch 32/100, Loss: 4.0203, Accuracy: 1.0000\n",
      "Epoch 33/100, Loss: 3.9438, Accuracy: 1.0000\n",
      "Epoch 34/100, Loss: 3.8683, Accuracy: 1.0000\n",
      "Epoch 35/100, Loss: 3.7939, Accuracy: 1.0000\n",
      "Epoch 36/100, Loss: 3.7206, Accuracy: 1.0000\n",
      "Epoch 37/100, Loss: 3.6482, Accuracy: 1.0000\n",
      "Epoch 38/100, Loss: 3.5769, Accuracy: 1.0000\n",
      "Epoch 39/100, Loss: 3.5065, Accuracy: 1.0000\n",
      "Epoch 40/100, Loss: 3.4370, Accuracy: 1.0000\n",
      "Epoch 41/100, Loss: 3.3683, Accuracy: 1.0000\n",
      "Epoch 42/100, Loss: 3.3004, Accuracy: 1.0000\n",
      "Epoch 43/100, Loss: 3.2331, Accuracy: 1.0000\n",
      "Epoch 44/100, Loss: 3.1666, Accuracy: 1.0000\n",
      "Epoch 45/100, Loss: 3.1009, Accuracy: 1.0000\n",
      "Epoch 46/100, Loss: 3.0358, Accuracy: 1.0000\n",
      "Epoch 47/100, Loss: 2.9716, Accuracy: 1.0000\n",
      "Epoch 48/100, Loss: 2.9081, Accuracy: 1.0000\n",
      "Epoch 49/100, Loss: 2.8454, Accuracy: 1.0000\n",
      "Epoch 50/100, Loss: 2.7836, Accuracy: 1.0000\n",
      "Epoch 51/100, Loss: 2.7227, Accuracy: 1.0000\n",
      "Epoch 52/100, Loss: 2.6627, Accuracy: 1.0000\n",
      "Epoch 53/100, Loss: 2.6037, Accuracy: 1.0000\n",
      "Epoch 54/100, Loss: 2.5456, Accuracy: 1.0000\n",
      "Epoch 55/100, Loss: 2.4884, Accuracy: 1.0000\n",
      "Epoch 56/100, Loss: 2.4323, Accuracy: 1.0000\n",
      "Epoch 57/100, Loss: 2.3771, Accuracy: 1.0000\n",
      "Epoch 58/100, Loss: 2.3229, Accuracy: 1.0000\n",
      "Epoch 59/100, Loss: 2.2697, Accuracy: 1.0000\n",
      "Epoch 60/100, Loss: 2.2175, Accuracy: 1.0000\n",
      "Epoch 61/100, Loss: 2.1662, Accuracy: 1.0000\n",
      "Epoch 62/100, Loss: 2.1160, Accuracy: 1.0000\n",
      "Epoch 63/100, Loss: 2.0667, Accuracy: 1.0000\n",
      "Epoch 64/100, Loss: 2.0184, Accuracy: 1.0000\n",
      "Epoch 65/100, Loss: 1.9712, Accuracy: 1.0000\n",
      "Epoch 66/100, Loss: 1.9248, Accuracy: 1.0000\n",
      "Epoch 67/100, Loss: 1.8795, Accuracy: 1.0000\n",
      "Epoch 68/100, Loss: 1.8352, Accuracy: 1.0000\n",
      "Epoch 69/100, Loss: 1.7918, Accuracy: 1.0000\n",
      "Epoch 70/100, Loss: 1.7494, Accuracy: 1.0000\n",
      "Epoch 71/100, Loss: 1.7080, Accuracy: 1.0000\n",
      "Epoch 72/100, Loss: 1.6676, Accuracy: 1.0000\n",
      "Epoch 73/100, Loss: 1.6281, Accuracy: 1.0000\n",
      "Epoch 74/100, Loss: 1.5895, Accuracy: 1.0000\n",
      "Epoch 75/100, Loss: 1.5519, Accuracy: 1.0000\n",
      "Epoch 76/100, Loss: 1.5152, Accuracy: 1.0000\n",
      "Epoch 77/100, Loss: 1.4794, Accuracy: 1.0000\n",
      "Epoch 78/100, Loss: 1.4446, Accuracy: 1.0000\n",
      "Epoch 79/100, Loss: 1.4106, Accuracy: 1.0000\n",
      "Epoch 80/100, Loss: 1.3775, Accuracy: 1.0000\n",
      "Epoch 81/100, Loss: 1.3453, Accuracy: 1.0000\n",
      "Epoch 82/100, Loss: 1.3139, Accuracy: 1.0000\n",
      "Epoch 83/100, Loss: 1.2834, Accuracy: 1.0000\n",
      "Epoch 84/100, Loss: 1.2537, Accuracy: 1.0000\n",
      "Epoch 85/100, Loss: 1.2248, Accuracy: 1.0000\n",
      "Epoch 86/100, Loss: 1.1966, Accuracy: 1.0000\n",
      "Epoch 87/100, Loss: 1.1693, Accuracy: 1.0000\n",
      "Epoch 88/100, Loss: 1.1427, Accuracy: 1.0000\n",
      "Epoch 89/100, Loss: 1.1168, Accuracy: 1.0000\n",
      "Epoch 90/100, Loss: 1.0917, Accuracy: 1.0000\n",
      "Epoch 91/100, Loss: 1.0672, Accuracy: 1.0000\n",
      "Epoch 92/100, Loss: 1.0435, Accuracy: 1.0000\n",
      "Epoch 93/100, Loss: 1.0204, Accuracy: 1.0000\n",
      "Epoch 94/100, Loss: 0.9980, Accuracy: 1.0000\n",
      "Epoch 95/100, Loss: 0.9762, Accuracy: 1.0000\n",
      "Epoch 96/100, Loss: 0.9550, Accuracy: 1.0000\n",
      "Epoch 97/100, Loss: 0.9344, Accuracy: 1.0000\n",
      "Epoch 98/100, Loss: 0.9144, Accuracy: 1.0000\n",
      "Epoch 99/100, Loss: 0.8950, Accuracy: 1.0000\n",
      "Epoch 100/100, Loss: 0.8761, Accuracy: 1.0000\n",
      "Quel est l'algorithme de tri le plus rapide ? C)Tri rapide D)Tri à bulles B)Tri fusion A)Tri par insertion La réponse correcte est C)Tri rapide.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "class RNNModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = tf.keras.layers.SimpleRNN(hidden_size)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.embedding(inputs)\n",
    "        x = tf.expand_dims(x, axis=0)\n",
    "        x = self.rnn(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "data = [\n",
    "    (\"Quel est l'algorithme de tri le plus rapide ?\", [\"A)Tri par insertion\", \"B)Tri fusion\", \"C)Tri rapide\", \"D)Tri à bulles\"], \"C)Tri rapide\"),\n",
    "    (\"Quelle est la complexité temporelle du tri fusion ?\", [\"A) O(n log n)\", \"B) O(n^2)\", \"C) O(n)\", \"D) O(log n)\"], \"A) O(n log n)\"),\n",
    "]\n",
    "\n",
    "# Encoder les données en indices\n",
    "word_to_ix = {}\n",
    "for question, options, _ in data:\n",
    "    for word in question.split():\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "    for option in options:\n",
    "        if option not in word_to_ix:\n",
    "            word_to_ix[option] = len(word_to_ix)\n",
    "\n",
    "# Taille du vocabulaire\n",
    "vocab_size = len(word_to_ix)\n",
    "\n",
    "embedding_dim = 10\n",
    "\n",
    "model = RNNModel(vocab_size, embedding_dim, 10)\n",
    "\n",
    "train_questions = [tf.constant([word_to_ix[word] for word in question.split()], dtype=tf.int32) for question, _, _ in data]\n",
    "train_answers = [tf.constant([word_to_ix[answer]], dtype=tf.int32) for _, _, answer in data]\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    train_accuracy.reset_states() \n",
    "    for input_tensor, target_tensor in zip(train_questions, train_answers):\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(input_tensor)\n",
    "            loss = loss_fn(target_tensor, predictions)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        epoch_loss += loss\n",
    "        train_accuracy.update_state(target_tensor, predictions)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss.numpy():.4f}, Accuracy: {train_accuracy.result().numpy():.4f}\")\n",
    "\n",
    "model.save_weights(\"model_weights.h5\")\n",
    "\n",
    "def generate_exam_question(model, word_to_ix, data):\n",
    "    random_question, random_options, random_answer = random.choice(data)\n",
    "    input_tensor = tf.constant([word_to_ix[word] for word in random_question.split()], dtype=tf.int32)\n",
    "    predictions = model(input_tensor)\n",
    "    predicted_answer_index = tf.argmax(predictions, axis=-1).numpy()[0]\n",
    "    predicted_answer = list(word_to_ix.keys())[predicted_answer_index]\n",
    "    \n",
    "    shuffled_options = random_options[:]\n",
    "    random.shuffle(shuffled_options)\n",
    "\n",
    "    return random_question, shuffled_options, predicted_answer\n",
    "\n",
    "model.load_weights(\"model_weights.h5\")\n",
    "\n",
    "random_question, random_options, predicted_answer = generate_exam_question(model, word_to_ix, data)\n",
    "exam_question = f\"{random_question} {' '.join(random_options)} La réponse correcte est {predicted_answer}.\"\n",
    "\n",
    "print(exam_question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.3733\n",
      "Epoch 2/4\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.0154\n",
      "Epoch 3/4\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.8618\n",
      "Epoch 4/4\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1046\n",
      "Question 1:\n",
      "Quel est l'algorithme de tri le plus rapide ?\n",
      "B) [1. 0. 0. 0.]\n",
      "C) [0. 1. 0. 0.]\n",
      "D) [0. 0. 1. 0.]\n",
      "E) [0. 0. 0. 1.]\n",
      "Réponse correcte: C\n",
      "\n",
      "Question 2:\n",
      "Quelle est la complexité temporelle du tri fusion ?\n",
      "B) [1. 0. 0. 0.]\n",
      "C) [0. 1. 0. 0.]\n",
      "D) [0. 0. 1. 0.]\n",
      "E) [0. 0. 0. 1.]\n",
      "Réponse correcte: A\n",
      "\n",
      "Question 3:\n",
      "Quel est l'algorithme de recherche le plus efficace ?\n",
      "B) [1. 0. 0. 0.]\n",
      "C) [0. 1. 0. 0.]\n",
      "D) [0. 0. 1. 0.]\n",
      "E) [0. 0. 0. 1.]\n",
      "Réponse correcte: B\n",
      "\n",
      "Question 4:\n",
      "Quelle est la complexité temporelle de la recherche binaire ?\n",
      "B) [1. 0. 0. 0.]\n",
      "C) [0. 1. 0. 0.]\n",
      "D) [0. 0. 1. 0.]\n",
      "E) [0. 0. 0. 1.]\n",
      "Réponse correcte: A\n",
      "\n",
      "Question 5:\n",
      "Quel est l'algorithme de tri adapté aux listes presque triées ?\n",
      "B) [1. 0. 0. 0.]\n",
      "C) [0. 1. 0. 0.]\n",
      "D) [0. 0. 1. 0.]\n",
      "E) [0. 0. 0. 1.]\n",
      "Réponse correcte: A\n",
      "\n",
      "Question 6:\n",
      "Quel est l'algorithme de tri adapté aux listes de petite taille ?\n",
      "B) [1. 0. 0. 0.]\n",
      "C) [0. 1. 0. 0.]\n",
      "D) [0. 0. 1. 0.]\n",
      "E) [0. 0. 0. 1.]\n",
      "Réponse correcte: A\n",
      "\n",
      "Question 7:\n",
      "Quelle est la complexité temporelle de la recherche séquentielle ?\n",
      "B) [1. 0. 0. 0.]\n",
      "C) [0. 1. 0. 0.]\n",
      "D) [0. 0. 1. 0.]\n",
      "E) [0. 0. 0. 1.]\n",
      "Réponse correcte: B\n",
      "\n",
      "Question 8:\n",
      "Quelle est la complexité spatiale de l'algorithme de tri rapide ?\n",
      "B) [1. 0. 0. 0.]\n",
      "C) [0. 1. 0. 0.]\n",
      "D) [0. 0. 1. 0.]\n",
      "E) [0. 0. 0. 1.]\n",
      "Réponse correcte: B\n",
      "\n",
      "Question 9:\n",
      "Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe pondéré ?\n",
      "B) [1. 0. 0. 0.]\n",
      "C) [0. 1. 0. 0.]\n",
      "D) [0. 0. 1. 0.]\n",
      "E) [0. 0. 0. 1.]\n",
      "Réponse correcte: A\n",
      "\n",
      "Question 10:\n",
      "Quelle est la complexité temporelle de l'algorithme de recherche linéaire ?\n",
      "B) [1. 0. 0. 0.]\n",
      "C) [0. 1. 0. 0.]\n",
      "D) [0. 0. 1. 0.]\n",
      "E) [0. 0. 0. 1.]\n",
      "Réponse correcte: B\n",
      "\n",
      "Question 11:\n",
      "Quel est l'algorithme utilisé pour trouver un arbre couvrant minimal dans un graphe pondéré ?\n",
      "B) [1. 0. 0. 0.]\n",
      "C) [0. 1. 0. 0.]\n",
      "D) [0. 0. 1. 0.]\n",
      "E) [0. 0. 0. 1.]\n",
      "Réponse correcte: A\n",
      "\n",
      "Question 12:\n",
      "Quelle est la complexité temporelle de l'algorithme de Kruskal ?\n",
      "B) [1. 0. 0. 0.]\n",
      "C) [0. 1. 0. 0.]\n",
      "D) [0. 0. 1. 0.]\n",
      "E) [0. 0. 0. 1.]\n",
      "Réponse correcte: A\n",
      "\n",
      "Question 13:\n",
      "Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe avec des arêtes de poids négatif ?\n",
      "B) [1. 0. 0. 0.]\n",
      "C) [0. 1. 0. 0.]\n",
      "D) [0. 0. 1. 0.]\n",
      "E) [0. 0. 0. 1.]\n",
      "Réponse correcte: B\n",
      "\n",
      "Question 14:\n",
      "Quelle est la complexité temporelle de l'algorithme de Floyd-Warshall ?\n",
      "B) [1. 0. 0. 0.]\n",
      "C) [0. 1. 0. 0.]\n",
      "D) [0. 0. 1. 0.]\n",
      "E) [0. 0. 0. 1.]\n",
      "Réponse correcte: A\n",
      "\n",
      "Question 15:\n",
      "Quel est l'algorithme utilisé pour effectuer une recherche en profondeur dans un graphe ?\n",
      "B) [1. 0. 0. 0.]\n",
      "C) [0. 1. 0. 0.]\n",
      "D) [0. 0. 1. 0.]\n",
      "E) [0. 0. 0. 1.]\n",
      "Réponse correcte: A\n",
      "\n",
      "Question 16:\n",
      "Quelle est la complexité temporelle de l'algorithme de recherche en profondeur ?\n",
      "B) [1. 0. 0. 0.]\n",
      "C) [0. 1. 0. 0.]\n",
      "D) [0. 0. 1. 0.]\n",
      "E) [0. 0. 0. 1.]\n",
      "Réponse correcte: A\n",
      "\n",
      "Question 17:\n",
      "Quel est l'algorithme utilisé pour effectuer une recherche en largeur dans un graphe ?\n",
      "B) [1. 0. 0. 0.]\n",
      "C) [0. 1. 0. 0.]\n",
      "D) [0. 0. 1. 0.]\n",
      "E) [0. 0. 0. 1.]\n",
      "Réponse correcte: A\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Activation, Dense, LSTM\n",
    "\n",
    "data = [\n",
    "    (\"Quel est l'algorithme de tri le plus rapide ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri rapide\"),\n",
    "    (\"Quelle est la complexité temporelle du tri fusion ?\", \n",
    "     [\"O(n log n)\", \"O(n^2)\", \"O(n)\", \"O(log n)\"], \n",
    "     \"O(n log n)\"),\n",
    "    (\"Quel est l'algorithme de recherche le plus efficace ?\", \n",
    "     [\"Recherche séquentielle\", \"Recherche binaire\", \"Recherche exponentielle\", \"Recherche linéaire\"], \n",
    "     \"Recherche binaire\"),\n",
    "    (\"Quelle est la complexité temporelle de la recherche binaire ?\", \n",
    "     [\"O(log n)\", \"O(n)\", \"O(n log n)\", \"O(n^2)\"], \n",
    "     \"O(log n)\"),\n",
    "    (\"Quel est l'algorithme de tri adapté aux listes presque triées ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri par insertion\"),\n",
    "    (\"Quel est l'algorithme de tri adapté aux listes de petite taille ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri par insertion\"),\n",
    "    (\"Quelle est la complexité temporelle de la recherche séquentielle ?\", \n",
    "     [\"O(n log n)\", \"O(n)\", \"O(log n)\", \"O(n^2)\"], \n",
    "     \"O(n)\"),\n",
    "    (\"Quelle est la complexité spatiale de l'algorithme de tri rapide ?\", \n",
    "     [\"O(n)\", \"O(log n)\", \"O(n^2)\", \"O(n log n)\"], \n",
    "     \"O(log n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe pondéré ?\", \n",
    "     [\"Algorithme de Dijkstra\", \"Algorithme de Bellman-Ford\", \"Algorithme de Floyd-Warshall\", \"Algorithme de Kruskal\"], \n",
    "     \"Algorithme de Dijkstra\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de recherche linéaire ?\", \n",
    "     [\"O(log n)\", \"O(n)\", \"O(n log n)\", \"O(n^2)\"], \n",
    "     \"O(n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour trouver un arbre couvrant minimal dans un graphe pondéré ?\", \n",
    "     [\"Algorithme de Prim\", \"Algorithme de Kruskal\", \"Algorithme de Dijkstra\", \"Algorithme de Bellman-Ford\"], \n",
    "     \"Algorithme de Prim\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de Kruskal ?\", \n",
    "     [\"O(n log n)\", \"O(n)\", \"O(log n)\", \"O(n^2)\"], \n",
    "     \"O(n log n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe avec des arêtes de poids négatif ?\", \n",
    "     [\"Algorithme de Dijkstra\", \"Algorithme de Bellman-Ford\", \"Algorithme de Floyd-Warshall\", \"Algorithme de Kruskal\"], \n",
    "     \"Algorithme de Bellman-Ford\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de Floyd-Warshall ?\", \n",
    "     [\"O(n^3)\", \"O(n^2)\", \"O(n log n)\", \"O(n)\"], \n",
    "     \"O(n^3)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour effectuer une recherche en profondeur dans un graphe ?\", \n",
    "     [\"Parcours en profondeur d'abord (DFS)\", \"Parcours en largeur d'abord (BFS)\", \"Algorithme de Kruskal\", \"Algorithme de Prim\"], \n",
    "     \"Parcours en profondeur d'abord (DFS)\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de recherche en profondeur ?\", \n",
    "     [\"O(n)\", \"O(log n)\", \"O(n^2)\", \"O(n log n)\"], \n",
    "     \"O(n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour effectuer une recherche en largeur dans un graphe ?\", \n",
    "     [\"Parcours en largeur d'abord (BFS)\", \"Parcours en profondeur d'abord (DFS)\", \"Algorithme de Kruskal\", \"Algorithme de Prim\"], \n",
    "     \"Parcours en largeur d'abord (BFS)\")\n",
    "]\n",
    "\n",
    "def preprocess_data(data):\n",
    "    processed_data = []\n",
    "    for question, options, answer in data:\n",
    "        options_one_hot = [tf.keras.utils.to_categorical(i, num_classes=len(options)) for i in range(len(options))]\n",
    "        answer_index = options.index(answer)\n",
    "        answer_one_hot = tf.keras.utils.to_categorical(answer_index, num_classes=len(options))\n",
    "        processed_data.append((question, options_one_hot, answer_one_hot))\n",
    "    return processed_data\n",
    "\n",
    "processed_data = preprocess_data(data)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(None, len(processed_data[0][1]))))\n",
    "model.add(Dense(len(processed_data[0][1]), activation='softmax'))  \n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01)) \n",
    "\n",
    "x_train = np.array([options for _, options, _ in processed_data])\n",
    "y_train = np.array([answer for _, _, answer in processed_data])\n",
    "model.fit(x_train, y_train, batch_size=256, epochs=4)\n",
    "\n",
    "def generate_exam(model):\n",
    "    exam = \"\"\n",
    "    for i, (question, options, correct_answer) in enumerate(processed_data, start=1):  \n",
    "        exam += f\"Question {i}:\\n{question}\\n\"  \n",
    "        for j, option in enumerate(options, start=1):\n",
    "            exam += f\"{chr(65 + j)}) {option}\\n\"  \n",
    "        exam += f\"Réponse correcte: {chr(65 + np.argmax(correct_answer))}\\n\\n\"  # Affichage de la réponse correcte\n",
    "    return exam\n",
    "\n",
    "print(generate_exam(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.4151\n",
      "Epoch 2/4\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0526\n",
      "Epoch 3/4\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8722\n",
      "Epoch 4/4\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1387\n",
      "Question 1:\n",
      "Quel est l'algorithme de tri le plus rapide ?\n",
      "A) Tri par insertion\n",
      "B) Tri fusion\n",
      "C) Tri rapide\n",
      "D) Tri à bulles\n",
      "Réponse correcte: C\n",
      "\n",
      "Question 2:\n",
      "Quelle est la complexité temporelle du tri fusion ?\n",
      "A) O(n log n)\n",
      "B) O(n^2)\n",
      "C) O(n)\n",
      "D) O(log n)\n",
      "Réponse correcte: A\n",
      "\n",
      "Question 3:\n",
      "Quel est l'algorithme de recherche le plus efficace ?\n",
      "A) Recherche séquentielle\n",
      "B) Recherche binaire\n",
      "C) Recherche exponentielle\n",
      "D) Recherche linéaire\n",
      "Réponse correcte: B\n",
      "\n",
      "Question 4:\n",
      "Quelle est la complexité temporelle de la recherche binaire ?\n",
      "A) O(log n)\n",
      "B) O(n)\n",
      "C) O(n log n)\n",
      "D) O(n^2)\n",
      "Réponse correcte: A\n",
      "\n",
      "Question 5:\n",
      "Quel est l'algorithme de tri adapté aux listes presque triées ?\n",
      "A) Tri par insertion\n",
      "B) Tri fusion\n",
      "C) Tri rapide\n",
      "D) Tri à bulles\n",
      "Réponse correcte: A\n",
      "\n",
      "Question 6:\n",
      "Quel est l'algorithme de tri adapté aux listes de petite taille ?\n",
      "A) Tri par insertion\n",
      "B) Tri fusion\n",
      "C) Tri rapide\n",
      "D) Tri à bulles\n",
      "Réponse correcte: A\n",
      "\n",
      "Question 7:\n",
      "Quelle est la complexité temporelle de la recherche séquentielle ?\n",
      "A) O(n log n)\n",
      "B) O(n)\n",
      "C) O(log n)\n",
      "D) O(n^2)\n",
      "Réponse correcte: B\n",
      "\n",
      "Question 8:\n",
      "Quelle est la complexité spatiale de l'algorithme de tri rapide ?\n",
      "A) O(n)\n",
      "B) O(log n)\n",
      "C) O(n^2)\n",
      "D) O(n log n)\n",
      "Réponse correcte: B\n",
      "\n",
      "Question 9:\n",
      "Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe pondéré ?\n",
      "A) Algorithme de Dijkstra\n",
      "B) Algorithme de Bellman-Ford\n",
      "C) Algorithme de Floyd-Warshall\n",
      "D) Algorithme de Kruskal\n",
      "Réponse correcte: A\n",
      "\n",
      "Question 10:\n",
      "Quelle est la complexité temporelle de l'algorithme de recherche linéaire ?\n",
      "A) O(log n)\n",
      "B) O(n)\n",
      "C) O(n log n)\n",
      "D) O(n^2)\n",
      "Réponse correcte: B\n",
      "\n",
      "Question 11:\n",
      "Quel est l'algorithme utilisé pour trouver un arbre couvrant minimal dans un graphe pondéré ?\n",
      "A) Algorithme de Prim\n",
      "B) Algorithme de Kruskal\n",
      "C) Algorithme de Dijkstra\n",
      "D) Algorithme de Bellman-Ford\n",
      "Réponse correcte: A\n",
      "\n",
      "Question 12:\n",
      "Quelle est la complexité temporelle de l'algorithme de Kruskal ?\n",
      "A) O(n log n)\n",
      "B) O(n)\n",
      "C) O(log n)\n",
      "D) O(n^2)\n",
      "Réponse correcte: A\n",
      "\n",
      "Question 13:\n",
      "Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe avec des arêtes de poids négatif ?\n",
      "A) Algorithme de Dijkstra\n",
      "B) Algorithme de Bellman-Ford\n",
      "C) Algorithme de Floyd-Warshall\n",
      "D) Algorithme de Kruskal\n",
      "Réponse correcte: B\n",
      "\n",
      "Question 14:\n",
      "Quelle est la complexité temporelle de l'algorithme de Floyd-Warshall ?\n",
      "A) O(n^3)\n",
      "B) O(n^2)\n",
      "C) O(n log n)\n",
      "D) O(n)\n",
      "Réponse correcte: A\n",
      "\n",
      "Question 15:\n",
      "Quel est l'algorithme utilisé pour effectuer une recherche en profondeur dans un graphe ?\n",
      "A) Parcours en profondeur d'abord (DFS)\n",
      "B) Parcours en largeur d'abord (BFS)\n",
      "C) Algorithme de Kruskal\n",
      "D) Algorithme de Prim\n",
      "Réponse correcte: A\n",
      "\n",
      "Question 16:\n",
      "Quelle est la complexité temporelle de l'algorithme de recherche en profondeur ?\n",
      "A) O(n)\n",
      "B) O(log n)\n",
      "C) O(n^2)\n",
      "D) O(n log n)\n",
      "Réponse correcte: A\n",
      "\n",
      "Question 17:\n",
      "Quel est l'algorithme utilisé pour effectuer une recherche en largeur dans un graphe ?\n",
      "A) Parcours en largeur d'abord (BFS)\n",
      "B) Parcours en profondeur d'abord (DFS)\n",
      "C) Algorithme de Kruskal\n",
      "D) Algorithme de Prim\n",
      "Réponse correcte: A\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Activation, Dense, LSTM\n",
    "\n",
    "data = [\n",
    "    (\"Quel est l'algorithme de tri le plus rapide ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri rapide\"),\n",
    "    (\"Quelle est la complexité temporelle du tri fusion ?\", \n",
    "     [\"O(n log n)\", \"O(n^2)\", \"O(n)\", \"O(log n)\"], \n",
    "     \"O(n log n)\"),\n",
    "    (\"Quel est l'algorithme de recherche le plus efficace ?\", \n",
    "     [\"Recherche séquentielle\", \"Recherche binaire\", \"Recherche exponentielle\", \"Recherche linéaire\"], \n",
    "     \"Recherche binaire\"),\n",
    "    (\"Quelle est la complexité temporelle de la recherche binaire ?\", \n",
    "     [\"O(log n)\", \"O(n)\", \"O(n log n)\", \"O(n^2)\"], \n",
    "     \"O(log n)\"),\n",
    "    (\"Quel est l'algorithme de tri adapté aux listes presque triées ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri par insertion\"),\n",
    "    (\"Quel est l'algorithme de tri adapté aux listes de petite taille ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri par insertion\"),\n",
    "    (\"Quelle est la complexité temporelle de la recherche séquentielle ?\", \n",
    "     [\"O(n log n)\", \"O(n)\", \"O(log n)\", \"O(n^2)\"], \n",
    "     \"O(n)\"),\n",
    "    (\"Quelle est la complexité spatiale de l'algorithme de tri rapide ?\", \n",
    "     [\"O(n)\", \"O(log n)\", \"O(n^2)\", \"O(n log n)\"], \n",
    "     \"O(log n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe pondéré ?\", \n",
    "     [\"Algorithme de Dijkstra\", \"Algorithme de Bellman-Ford\", \"Algorithme de Floyd-Warshall\", \"Algorithme de Kruskal\"], \n",
    "     \"Algorithme de Dijkstra\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de recherche linéaire ?\", \n",
    "     [\"O(log n)\", \"O(n)\", \"O(n log n)\", \"O(n^2)\"], \n",
    "     \"O(n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour trouver un arbre couvrant minimal dans un graphe pondéré ?\", \n",
    "     [\"Algorithme de Prim\", \"Algorithme de Kruskal\", \"Algorithme de Dijkstra\", \"Algorithme de Bellman-Ford\"], \n",
    "     \"Algorithme de Prim\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de Kruskal ?\", \n",
    "     [\"O(n log n)\", \"O(n)\", \"O(log n)\", \"O(n^2)\"], \n",
    "     \"O(n log n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe avec des arêtes de poids négatif ?\", \n",
    "     [\"Algorithme de Dijkstra\", \"Algorithme de Bellman-Ford\", \"Algorithme de Floyd-Warshall\", \"Algorithme de Kruskal\"], \n",
    "     \"Algorithme de Bellman-Ford\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de Floyd-Warshall ?\", \n",
    "     [\"O(n^3)\", \"O(n^2)\", \"O(n log n)\", \"O(n)\"], \n",
    "     \"O(n^3)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour effectuer une recherche en profondeur dans un graphe ?\", \n",
    "     [\"Parcours en profondeur d'abord (DFS)\", \"Parcours en largeur d'abord (BFS)\", \"Algorithme de Kruskal\", \"Algorithme de Prim\"], \n",
    "     \"Parcours en profondeur d'abord (DFS)\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de recherche en profondeur ?\", \n",
    "     [\"O(n)\", \"O(log n)\", \"O(n^2)\", \"O(n log n)\"], \n",
    "     \"O(n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour effectuer une recherche en largeur dans un graphe ?\", \n",
    "     [\"Parcours en largeur d'abord (BFS)\", \"Parcours en profondeur d'abord (DFS)\", \"Algorithme de Kruskal\", \"Algorithme de Prim\"], \n",
    "     \"Parcours en largeur d'abord (BFS)\")\n",
    "]\n",
    "\n",
    "def preprocess_data(data):\n",
    "    processed_data = []\n",
    "    for question, options, answer in data:\n",
    "        options_one_hot = [tf.keras.utils.to_categorical(i, num_classes=len(options)) for i in range(len(options))]\n",
    "        answer_index = options.index(answer)\n",
    "        answer_one_hot = tf.keras.utils.to_categorical(answer_index, num_classes=len(options))\n",
    "        processed_data.append((question, options_one_hot, answer_one_hot))\n",
    "    return processed_data\n",
    "\n",
    "processed_data = preprocess_data(data)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(None, len(processed_data[0][1]))))  # Input shape: (None, 4) pour les options\n",
    "model.add(Dense(len(processed_data[0][1]), activation='softmax'))  # 4 pour le nombre d'options\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01))  # Modifier 'lr' en 'learning_rate'\n",
    "\n",
    "# Entraînement du modèle\n",
    "x_train = np.array([options for _, options, _ in processed_data])\n",
    "y_train = np.array([answer for _, _, answer in processed_data])\n",
    "model.fit(x_train, y_train, batch_size=256, epochs=4)\n",
    "\n",
    "\n",
    "def generate_exam(model):\n",
    "    exam = \"\"\n",
    "    for i, (question, options, correct_answer) in enumerate(processed_data, start=1):  \n",
    "        exam += f\"Question {i}:\\n{question}\\n\"  \n",
    "        for j, option in enumerate(options, start=1):\n",
    "            option_index = np.argmax(option)\n",
    "            option_char = chr(65 + option_index)\n",
    "            exam += f\"{option_char}) {data[i-1][1][option_index]}\\n\"  \n",
    "        correct_answer_index = np.argmax(correct_answer)\n",
    "        correct_answer_char = chr(65 + correct_answer_index)\n",
    "        exam += f\"Réponse correcte: {correct_answer_char}\\n\\n\"  \n",
    "    return exam\n",
    "\n",
    "print(generate_exam(model))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.4016\n",
      "Epoch 2/4\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0549\n",
      "Epoch 3/4\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1182\n",
      "Epoch 4/4\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.1231\n",
      "1/1 [==============================] - 0s 437ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Question: Quelle est la complexité temporelle du tri fusion ?\n",
      "Options: [array([[0.31464076, 0.23870973, 0.24110721, 0.20554236]], dtype=float32), array([[0.32907745, 0.24333796, 0.23483215, 0.1927524 ]], dtype=float32), array([[0.3408757 , 0.2337325 , 0.23884836, 0.18654343]], dtype=float32), array([[0.35642144, 0.2350155 , 0.22970593, 0.17885712]], dtype=float32)]\n",
      "Réponse correcte: 0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "data = [\n",
    "    (\"Quel est l'algorithme de tri le plus rapide ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri rapide\"),\n",
    "    (\"Quelle est la complexité temporelle du tri fusion ?\", \n",
    "     [\"O(n log n)\", \"O(n^2)\", \"O(n)\", \"O(log n)\"], \n",
    "     \"O(n log n)\"),\n",
    "    (\"Quel est l'algorithme de recherche le plus efficace ?\", \n",
    "     [\"Recherche séquentielle\", \"Recherche binaire\", \"Recherche exponentielle\", \"Recherche linéaire\"], \n",
    "     \"Recherche binaire\"),\n",
    "    (\"Quelle est la complexité temporelle de la recherche binaire ?\", \n",
    "     [\"O(log n)\", \"O(n)\", \"O(n log n)\", \"O(n^2)\"], \n",
    "     \"O(log n)\"),\n",
    "    (\"Quel est l'algorithme de tri adapté aux listes presque triées ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri par insertion\"),\n",
    "    (\"Quel est l'algorithme de tri adapté aux listes de petite taille ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri par insertion\"),\n",
    "]\n",
    "\n",
    "def preprocess_data(data):\n",
    "    processed_data = []\n",
    "    for question, options, answer in data:\n",
    "        options_one_hot = [tf.keras.utils.to_categorical(i, num_classes=len(options)) for i in range(len(options))]\n",
    "        answer_index = options.index(answer)\n",
    "        answer_one_hot = tf.keras.utils.to_categorical(answer_index, num_classes=len(options))\n",
    "        processed_data.append((question, options_one_hot, answer_one_hot))\n",
    "    return processed_data\n",
    "\n",
    "processed_data = preprocess_data(data)\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(128, input_shape=(None, len(processed_data[0][1]))),\n",
    "    Dense(len(processed_data[0][1]), activation='softmax')\n",
    "])\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01))\n",
    "\n",
    "x_train = np.array([options for _, options, _ in processed_data])\n",
    "y_train = np.array([answer for _, _, answer in processed_data])\n",
    "model.fit(x_train, y_train, batch_size=256, epochs=4)\n",
    "\n",
    "def generate_question(model):\n",
    "    random_index = random.randint(0, len(processed_data) - 1)\n",
    "    question, options_one_hot, correct_answer_one_hot = processed_data[random_index]\n",
    "    \n",
    "    predictions = []\n",
    "\n",
    "    for option_one_hot in options_one_hot:\n",
    "        option_one_hot = np.expand_dims(option_one_hot, axis=0)  \n",
    "        option_one_hot = np.expand_dims(option_one_hot, axis=1)\n",
    "        \n",
    "        # Faire la prédiction et ajouter le résultat à la liste des prédictions\n",
    "        prediction = model.predict(option_one_hot)\n",
    "        predictions.append(prediction)\n",
    "\n",
    "    correct_answer_index = np.argmax(correct_answer_one_hot)\n",
    "    \n",
    "    return question, predictions, correct_answer_index\n",
    "\n",
    "question, options, correct_answer_index = generate_question(model)\n",
    "print(\"Question:\", question)\n",
    "print(\"Options:\", options)\n",
    "print(\"Réponse correcte:\", correct_answer_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.3725\n",
      "Epoch 2/4\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0202\n",
      "Epoch 3/4\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.1021\n",
      "Epoch 4/4\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1237\n",
      "1/1 [==============================] - 0s 432ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Question 1: Quelle est la complexité temporelle du tri fusion ?\n",
      "Options: [array([[0.31275326, 0.2472328 , 0.23692445, 0.20308952]], dtype=float32), array([[0.31857815, 0.24148715, 0.23828574, 0.201649  ]], dtype=float32), array([[0.34096515, 0.23874305, 0.24113461, 0.17915718]], dtype=float32), array([[0.3666095 , 0.23423356, 0.23054193, 0.1686149 ]], dtype=float32)]\n",
      "Réponse correcte: 0\n",
      "\n",
      "Question 2: Quel est l'algorithme de tri adapté aux listes presque triées ?\n",
      "Options: [array([[0.31275326, 0.2472328 , 0.23692445, 0.20308952]], dtype=float32), array([[0.31857815, 0.24148715, 0.23828574, 0.201649  ]], dtype=float32), array([[0.34096515, 0.23874305, 0.24113461, 0.17915718]], dtype=float32), array([[0.3666095 , 0.23423356, 0.23054193, 0.1686149 ]], dtype=float32)]\n",
      "Réponse correcte: 0\n",
      "\n",
      "Question 3: Quel est l'algorithme de tri le plus rapide ?\n",
      "Options: [array([[0.31275326, 0.2472328 , 0.23692445, 0.20308952]], dtype=float32), array([[0.31857815, 0.24148715, 0.23828574, 0.201649  ]], dtype=float32), array([[0.34096515, 0.23874305, 0.24113461, 0.17915718]], dtype=float32), array([[0.3666095 , 0.23423356, 0.23054193, 0.1686149 ]], dtype=float32)]\n",
      "Réponse correcte: 2\n",
      "\n",
      "Question 4: Quel est l'algorithme de tri adapté aux listes de petite taille ?\n",
      "Options: [array([[0.31275326, 0.2472328 , 0.23692445, 0.20308952]], dtype=float32), array([[0.31857815, 0.24148715, 0.23828574, 0.201649  ]], dtype=float32), array([[0.34096515, 0.23874305, 0.24113461, 0.17915718]], dtype=float32), array([[0.3666095 , 0.23423356, 0.23054193, 0.1686149 ]], dtype=float32)]\n",
      "Réponse correcte: 0\n",
      "\n",
      "Question 5: Quelle est la complexité temporelle de la recherche binaire ?\n",
      "Options: [array([[0.31275326, 0.2472328 , 0.23692445, 0.20308952]], dtype=float32), array([[0.31857815, 0.24148715, 0.23828574, 0.201649  ]], dtype=float32), array([[0.34096515, 0.23874305, 0.24113461, 0.17915718]], dtype=float32), array([[0.3666095 , 0.23423356, 0.23054193, 0.1686149 ]], dtype=float32)]\n",
      "Réponse correcte: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "data = [\n",
    "    (\"Quel est l'algorithme de tri le plus rapide ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri rapide\"),\n",
    "    (\"Quelle est la complexité temporelle du tri fusion ?\", \n",
    "     [\"O(n log n)\", \"O(n^2)\", \"O(n)\", \"O(log n)\"], \n",
    "     \"O(n log n)\"),\n",
    "    (\"Quel est l'algorithme de recherche le plus efficace ?\", \n",
    "     [\"Recherche séquentielle\", \"Recherche binaire\", \"Recherche exponentielle\", \"Recherche linéaire\"], \n",
    "     \"Recherche binaire\"),\n",
    "    (\"Quelle est la complexité temporelle de la recherche binaire ?\", \n",
    "     [\"O(log n)\", \"O(n)\", \"O(n log n)\", \"O(n^2)\"], \n",
    "     \"O(log n)\"),\n",
    "    (\"Quel est l'algorithme de tri adapté aux listes presque triées ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri par insertion\"),\n",
    "    (\"Quel est l'algorithme de tri adapté aux listes de petite taille ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri par insertion\"),\n",
    "]\n",
    "\n",
    "\n",
    "def preprocess_data(data):\n",
    "    processed_data = []\n",
    "    for question, options, answer in data:\n",
    "        options_one_hot = [tf.keras.utils.to_categorical(i, num_classes=len(options)) for i in range(len(options))]\n",
    "        answer_index = options.index(answer)\n",
    "        answer_one_hot = tf.keras.utils.to_categorical(answer_index, num_classes=len(options))\n",
    "        processed_data.append((question, options_one_hot, answer_one_hot))\n",
    "    return processed_data\n",
    "\n",
    "processed_data = preprocess_data(data)\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(128, input_shape=(None, len(processed_data[0][1]))),\n",
    "    Dense(len(processed_data[0][1]), activation='softmax')\n",
    "])\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01))\n",
    "\n",
    "x_train = np.array([options for _, options, _ in processed_data])\n",
    "y_train = np.array([answer for _, _, answer in processed_data])\n",
    "model.fit(x_train, y_train, batch_size=256, epochs=4)\n",
    "\n",
    "\n",
    "def generate_exam(model, num_questions):\n",
    "    available_indices = list(range(len(processed_data)))  \n",
    "    exam_questions = []\n",
    "    \n",
    "    for _ in range(num_questions):\n",
    "        if not available_indices:\n",
    "            break  \n",
    "        \n",
    "        random_index = random.choice(available_indices) \n",
    "        question, options_one_hot, correct_answer_one_hot = processed_data[random_index]\n",
    "        \n",
    "        available_indices.remove(random_index)\n",
    "\n",
    "        # Créer une liste pour stocker les prédictions\n",
    "        predictions = []\n",
    "\n",
    "        # Faire une prédiction pour chaque option\n",
    "        for option_one_hot in options_one_hot:\n",
    "            option_one_hot = np.expand_dims(option_one_hot, axis=0)  \n",
    "            option_one_hot = np.expand_dims(option_one_hot, axis=1)\n",
    "\n",
    "            prediction = model.predict(option_one_hot)\n",
    "            predictions.append(prediction)\n",
    "\n",
    "        correct_answer_index = np.argmax(correct_answer_one_hot)\n",
    "\n",
    "        exam_questions.append((question, predictions, correct_answer_index))\n",
    "    \n",
    "    return exam_questions\n",
    "\n",
    "\n",
    "exam_questions = generate_exam(model, num_questions=5)\n",
    "for i, (question, options, correct_answer_index) in enumerate(exam_questions, start=1):\n",
    "    print(f\"Question {i}: {question}\")\n",
    "    print(\"Options:\", options)\n",
    "    print(\"Réponse correcte:\", correct_answer_index)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1/1 [==============================] - 5s 5s/step - loss: 1.3554\n",
      "Epoch 2/4\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.9705\n",
      "Epoch 3/4\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9567\n",
      "Epoch 4/4\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.0835\n",
      "1/1 [==============================] - 1s 983ms/step\n",
      "Question: Quelle est la complexité temporelle du tri fusion ?\n",
      "A) O(n log n)\n",
      "B) O(n^2)\n",
      "C) O(n)\n",
      "D) O(log n)\n",
      "Réponse prédite: O(n log n)\n",
      "Réponse correcte: [1. 0. 0. 0.]\n",
      "\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Question: Quelle est la complexité temporelle de la recherche binaire ?\n",
      "A) O(log n)\n",
      "B) O(n)\n",
      "C) O(n log n)\n",
      "D) O(n^2)\n",
      "Réponse prédite: O(log n)\n",
      "Réponse correcte: [1. 0. 0. 0.]\n",
      "\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Question: Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe pondéré ?\n",
      "A) Algorithme de Dijkstra\n",
      "B) Algorithme de Bellman-Ford\n",
      "C) Algorithme de Floyd-Warshall\n",
      "D) Algorithme de Kruskal\n",
      "Réponse prédite: Algorithme de Dijkstra\n",
      "Réponse correcte: [1. 0. 0. 0.]\n",
      "\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "Question: Quelle est la complexité spatiale de l'algorithme de tri rapide ?\n",
      "A) O(n)\n",
      "B) O(log n)\n",
      "C) O(n^2)\n",
      "D) O(n log n)\n",
      "Réponse prédite: O(n)\n",
      "Réponse correcte: [0. 1. 0. 0.]\n",
      "\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Question: Quel est l'algorithme de tri adapté aux listes presque triées ?\n",
      "A) Tri par insertion\n",
      "B) Tri fusion\n",
      "C) Tri rapide\n",
      "D) Tri à bulles\n",
      "Réponse prédite: Tri par insertion\n",
      "Réponse correcte: [1. 0. 0. 0.]\n",
      "\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Question: Quel est l'algorithme de tri adapté aux listes presque triées ?\n",
      "A) Tri par insertion\n",
      "B) Tri fusion\n",
      "C) Tri rapide\n",
      "D) Tri à bulles\n",
      "Réponse prédite: Tri par insertion\n",
      "Réponse correcte: [1. 0. 0. 0.]\n",
      "\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Question: Quel est l'algorithme de tri adapté aux listes de petite taille ?\n",
      "A) Tri par insertion\n",
      "B) Tri fusion\n",
      "C) Tri rapide\n",
      "D) Tri à bulles\n",
      "Réponse prédite: Tri par insertion\n",
      "Réponse correcte: [1. 0. 0. 0.]\n",
      "\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Question: Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe pondéré ?\n",
      "A) Algorithme de Dijkstra\n",
      "B) Algorithme de Bellman-Ford\n",
      "C) Algorithme de Floyd-Warshall\n",
      "D) Algorithme de Kruskal\n",
      "Réponse prédite: Algorithme de Dijkstra\n",
      "Réponse correcte: [1. 0. 0. 0.]\n",
      "\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Question: Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe pondéré ?\n",
      "A) Algorithme de Dijkstra\n",
      "B) Algorithme de Bellman-Ford\n",
      "C) Algorithme de Floyd-Warshall\n",
      "D) Algorithme de Kruskal\n",
      "Réponse prédite: Algorithme de Dijkstra\n",
      "Réponse correcte: [1. 0. 0. 0.]\n",
      "\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Question: Quel est l'algorithme utilisé pour trouver un arbre couvrant minimal dans un graphe pondéré ?\n",
      "A) Algorithme de Prim\n",
      "B) Algorithme de Kruskal\n",
      "C) Algorithme de Dijkstra\n",
      "D) Algorithme de Bellman-Ford\n",
      "Réponse prédite: Algorithme de Prim\n",
      "Réponse correcte: [1. 0. 0. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Activation, Dense, LSTM\n",
    "\n",
    "data = [\n",
    "    (\"Quel est l'algorithme de tri le plus rapide ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri rapide\"),\n",
    "    (\"Quelle est la complexité temporelle du tri fusion ?\", \n",
    "     [\"O(n log n)\", \"O(n^2)\", \"O(n)\", \"O(log n)\"], \n",
    "     \"O(n log n)\"),\n",
    "    (\"Quel est l'algorithme de recherche le plus efficace ?\", \n",
    "     [\"Recherche séquentielle\", \"Recherche binaire\", \"Recherche exponentielle\", \"Recherche linéaire\"], \n",
    "     \"Recherche binaire\"),\n",
    "    (\"Quelle est la complexité temporelle de la recherche binaire ?\", \n",
    "     [\"O(log n)\", \"O(n)\", \"O(n log n)\", \"O(n^2)\"], \n",
    "     \"O(log n)\"),\n",
    "    (\"Quel est l'algorithme de tri adapté aux listes presque triées ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri par insertion\"),\n",
    "    (\"Quel est l'algorithme de tri adapté aux listes de petite taille ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri par insertion\"),\n",
    "    (\"Quelle est la complexité temporelle de la recherche séquentielle ?\", \n",
    "     [\"O(n log n)\", \"O(n)\", \"O(log n)\", \"O(n^2)\"], \n",
    "     \"O(n)\"),\n",
    "    (\"Quelle est la complexité spatiale de l'algorithme de tri rapide ?\", \n",
    "     [\"O(n)\", \"O(log n)\", \"O(n^2)\", \"O(n log n)\"], \n",
    "     \"O(log n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe pondéré ?\", \n",
    "     [\"Algorithme de Dijkstra\", \"Algorithme de Bellman-Ford\", \"Algorithme de Floyd-Warshall\", \"Algorithme de Kruskal\"], \n",
    "     \"Algorithme de Dijkstra\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de recherche linéaire ?\", \n",
    "     [\"O(log n)\", \"O(n)\", \"O(n log n)\", \"O(n^2)\"], \n",
    "     \"O(n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour trouver un arbre couvrant minimal dans un graphe pondéré ?\", \n",
    "     [\"Algorithme de Prim\", \"Algorithme de Kruskal\", \"Algorithme de Dijkstra\", \"Algorithme de Bellman-Ford\"], \n",
    "     \"Algorithme de Prim\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de Kruskal ?\", \n",
    "     [\"O(n log n)\", \"O(n)\", \"O(log n)\", \"O(n^2)\"], \n",
    "     \"O(n log n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe avec des arêtes de poids négatif ?\", \n",
    "     [\"Algorithme de Dijkstra\", \"Algorithme de Bellman-Ford\", \"Algorithme de Floyd-Warshall\", \"Algorithme de Kruskal\"], \n",
    "     \"Algorithme de Bellman-Ford\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de Floyd-Warshall ?\", \n",
    "     [\"O(n^3)\", \"O(n^2)\", \"O(n log n)\", \"O(n)\"], \n",
    "     \"O(n^3)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour effectuer une recherche en profondeur dans un graphe ?\", \n",
    "     [\"Parcours en profondeur d'abord (DFS)\", \"Parcours en largeur d'abord (BFS)\", \"Algorithme de Kruskal\", \"Algorithme de Prim\"], \n",
    "     \"Parcours en profondeur d'abord (DFS)\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de recherche en profondeur ?\", \n",
    "     [\"O(n)\", \"O(log n)\", \"O(n^2)\", \"O(n log n)\"], \n",
    "     \"O(n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour effectuer une recherche en largeur dans un graphe ?\", \n",
    "     [\"Parcours en largeur d'abord (BFS)\", \"Parcours en profondeur d'abord (DFS)\", \"Algorithme de Kruskal\", \"Algorithme de Prim\"], \n",
    "     \"Parcours en largeur d'abord (BFS)\")\n",
    "]\n",
    "\n",
    "\n",
    "def preprocess_data(data):\n",
    "    processed_data = []\n",
    "    for question, options, answer in data:\n",
    "        options_one_hot = [tf.keras.utils.to_categorical(i, num_classes=len(options)) for i in range(len(options))]\n",
    "        answer_index = options.index(answer)\n",
    "        answer_one_hot = tf.keras.utils.to_categorical(answer_index, num_classes=len(options))\n",
    "        processed_data.append((question, options_one_hot, answer_one_hot))\n",
    "    return processed_data\n",
    "\n",
    "processed_data = preprocess_data(data)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(None, len(processed_data[0][1]))))  \n",
    "model.add(Dense(len(processed_data[0][1]), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01))\n",
    "\n",
    "x_train = np.array([options for _, options, _ in processed_data])\n",
    "y_train = np.array([answer for _, _, answer in processed_data])\n",
    "model.fit(x_train, y_train, batch_size=256, epochs=4)\n",
    "\n",
    "def generate_question(model):\n",
    "    \n",
    "    question_idx = random.randint(0, len(data) - 1)\n",
    "    question_text, options, correct_answer = processed_data[question_idx]\n",
    "    \n",
    "    predicted_answer = model.predict(np.array([options]))\n",
    "    predicted_answer_index = np.argmax(predicted_answer)\n",
    "    predicted_answer_text = data[question_idx][1][predicted_answer_index]\n",
    "    \n",
    "    print(\"Question:\", question_text)\n",
    "    for i, option in enumerate(options):\n",
    "        print(f\"{chr(65 + i)}) {data[question_idx][1][i]}\")\n",
    "    \n",
    "    print(\"Réponse prédite:\", predicted_answer_text)\n",
    "    print(\"Réponse correcte:\", correct_answer)\n",
    "    print()\n",
    "\n",
    "for _ in range(10):\n",
    "    generate_question(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.3814\n",
      "Epoch 2/4\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.0316\n",
      "Epoch 3/4\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.9085\n",
      "Epoch 4/4\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.1497\n",
      "1/1 [==============================] - 0s 483ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Activation, Dense, LSTM\n",
    "\n",
    "\n",
    "data = [\n",
    "    (\"Quel est l'algorithme de tri le plus rapide ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri rapide\"),\n",
    "    (\"Quelle est la complexité temporelle du tri fusion ?\", \n",
    "     [\"O(n log n)\", \"O(n^2)\", \"O(n)\", \"O(log n)\"], \n",
    "     \"O(n log n)\"),\n",
    "    (\"Quel est l'algorithme de recherche le plus efficace ?\", \n",
    "     [\"Recherche séquentielle\", \"Recherche binaire\", \"Recherche exponentielle\", \"Recherche linéaire\"], \n",
    "     \"Recherche binaire\"),\n",
    "    (\"Quelle est la complexité temporelle de la recherche binaire ?\", \n",
    "     [\"O(log n)\", \"O(n)\", \"O(n log n)\", \"O(n^2)\"], \n",
    "     \"O(log n)\"),\n",
    "    (\"Quel est l'algorithme de tri adapté aux listes presque triées ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri par insertion\"),\n",
    "    (\"Quel est l'algorithme de tri adapté aux listes de petite taille ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri par insertion\"),\n",
    "    (\"Quelle est la complexité temporelle de la recherche séquentielle ?\", \n",
    "     [\"O(n log n)\", \"O(n)\", \"O(log n)\", \"O(n^2)\"], \n",
    "     \"O(n)\"),\n",
    "    (\"Quelle est la complexité spatiale de l'algorithme de tri rapide ?\", \n",
    "     [\"O(n)\", \"O(log n)\", \"O(n^2)\", \"O(n log n)\"], \n",
    "     \"O(log n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe pondéré ?\", \n",
    "     [\"Algorithme de Dijkstra\", \"Algorithme de Bellman-Ford\", \"Algorithme de Floyd-Warshall\", \"Algorithme de Kruskal\"], \n",
    "     \"Algorithme de Dijkstra\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de recherche linéaire ?\", \n",
    "     [\"O(log n)\", \"O(n)\", \"O(n log n)\", \"O(n^2)\"], \n",
    "     \"O(n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour trouver un arbre couvrant minimal dans un graphe pondéré ?\", \n",
    "     [\"Algorithme de Prim\", \"Algorithme de Kruskal\", \"Algorithme de Dijkstra\", \"Algorithme de Bellman-Ford\"], \n",
    "     \"Algorithme de Prim\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de Kruskal ?\", \n",
    "     [\"O(n log n)\", \"O(n)\", \"O(log n)\", \"O(n^2)\"], \n",
    "     \"O(n log n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe avec des arêtes de poids négatif ?\", \n",
    "     [\"Algorithme de Dijkstra\", \"Algorithme de Bellman-Ford\", \"Algorithme de Floyd-Warshall\", \"Algorithme de Kruskal\"], \n",
    "     \"Algorithme de Bellman-Ford\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de Floyd-Warshall ?\", \n",
    "     [\"O(n^3)\", \"O(n^2)\", \"O(n log n)\", \"O(n)\"], \n",
    "     \"O(n^3)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour effectuer une recherche en profondeur dans un graphe ?\", \n",
    "     [\"Parcours en profondeur d'abord (DFS)\", \"Parcours en largeur d'abord (BFS)\", \"Algorithme de Kruskal\", \"Algorithme de Prim\"], \n",
    "     \"Parcours en profondeur d'abord (DFS)\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de recherche en profondeur ?\", \n",
    "     [\"O(n)\", \"O(log n)\", \"O(n^2)\", \"O(n log n)\"], \n",
    "     \"O(n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour effectuer une recherche en largeur dans un graphe ?\", \n",
    "     [\"Parcours en largeur d'abord (BFS)\", \"Parcours en profondeur d'abord (DFS)\", \"Algorithme de Kruskal\", \"Algorithme de Prim\"], \n",
    "     \"Parcours en largeur d'abord (BFS)\")\n",
    "]\n",
    "\n",
    "def preprocess_data(data):\n",
    "    processed_data = []\n",
    "    for question, options, answer in data:\n",
    "        options_one_hot = [tf.keras.utils.to_categorical(i, num_classes=len(options)) for i in range(len(options))]\n",
    "        answer_index = options.index(answer)\n",
    "        answer_one_hot = tf.keras.utils.to_categorical(answer_index, num_classes=len(options))\n",
    "        processed_data.append((question, options_one_hot, answer_one_hot))\n",
    "    return processed_data\n",
    "\n",
    "processed_data = preprocess_data(data)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(None, len(processed_data[0][1])))) \n",
    "model.add(Dense(len(processed_data[0][1]), activation='softmax')) \n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01)) \n",
    "\n",
    "x_train = np.array([options for _, options, _ in processed_data])\n",
    "y_train = np.array([answer for _, _, answer in processed_data])\n",
    "model.fit(x_train, y_train, batch_size=256, epochs=4)\n",
    "\n",
    "def generate_question(model):\n",
    "    # question aléatoire\n",
    "    question_idx = random.randint(0, len(data) - 1)\n",
    "    question_text, options, correct_answer = processed_data[question_idx]\n",
    "    \n",
    "    # Prédire la réponse\n",
    "    predicted_answer = model.predict(np.array([options]))\n",
    "    predicted_answer_index = np.argmax(predicted_answer)\n",
    "    predicted_answer_text = data[question_idx][1][predicted_answer_index]\n",
    "    \n",
    "    # Pas besoin de décoder les options et la réponse correcte\n",
    "    options_text = [str(i) for i in range(len(options))]\n",
    "    correct_answer_text = str(np.argmax(correct_answer))\n",
    "    \n",
    "    return {\"question\": question_text, \"options\": options_text, \"correct_answer\": correct_answer_text}\n",
    "\n",
    "# je Génére et afficher 10 QCM\n",
    "generated_questions = [generate_question(model) for _ in range(10)]\n",
    "\n",
    "# le fichier XML pour Moodle creation brute\n",
    "root = ET.Element(\"quiz\")\n",
    "for i, qcm in enumerate(generated_questions, start=1):\n",
    "    question = ET.SubElement(root, \"question\", type=\"multichoice\")\n",
    "    name = ET.SubElement(question, \"name\")\n",
    "    text = ET.SubElement(name, \"text\")\n",
    "    text.text = f\"Question {i}\"\n",
    "    questiontext = ET.SubElement(question, \"questiontext\", format=\"html\")\n",
    "    text = ET.SubElement(questiontext, \"text\")\n",
    "    text.text = f\"<![CDATA[<p></p><div><div><div>{qcm['question']}</div></div><br></div><br><p></p>]]>\"\n",
    "    generalfeedback = ET.SubElement(question, \"generalfeedback\", format=\"html\")\n",
    "    text = ET.SubElement(generalfeedback, \"text\")\n",
    "    text.text = \"<![CDATA[<p>none</p>]]>\"\n",
    "    defaultgrade = ET.SubElement(question, \"defaultgrade\")\n",
    "    defaultgrade.text = \"1.0000000\"\n",
    "    penalty = ET.SubElement(question, \"penalty\")\n",
    "    penalty.text = \"0.3333333\"\n",
    "    hidden = ET.SubElement(question, \"hidden\")\n",
    "    hidden.text = \"0\"\n",
    "    single = ET.SubElement(question, \"single\")\n",
    "    single.text = \"true\"\n",
    "    shuffleanswers = ET.SubElement(question, \"shuffleanswers\")\n",
    "    shuffleanswers.text = \"true\"\n",
    "    answernumbering = ET.SubElement(question, \"answernumbering\")\n",
    "    answernumbering.text = \"abc\"\n",
    "    for j, option in enumerate(qcm[\"options\"], start=1):\n",
    "        answer = ET.SubElement(question, \"answer\", fraction=\"100\" if option == qcm[\"correct_answer\"] else \"0\", format=\"html\")\n",
    "        text = ET.SubElement(answer, \"text\")\n",
    "        text.text = f\"<![CDATA[<p></p><div><div><div>{option}</div></div><br></div><br><p></p>]]>\"\n",
    "        feedback = ET.SubElement(answer, \"feedback\", format=\"html\")\n",
    "        text = ET.SubElement(feedback, \"text\")\n",
    "        text.text = \"<![CDATA[<p>none</p>]]>\"\n",
    "\n",
    "tree = ET.ElementTree(root)\n",
    "tree.write(\"BANK_QUESTIONS_1.xml\", encoding=\"utf-8\", xml_declaration=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.3828\n",
      "Epoch 2/4\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0318\n",
      "Epoch 3/4\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8918\n",
      "Epoch 4/4\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.1918\n",
      "1/1 [==============================] - 1s 537ms/step\n",
      "{'question': \"Quel est l'algorithme utilisé pour effectuer une recherche en profondeur dans un graphe ?\", 'options': ['0', '1', '2', '3'], 'correct_answer': '0'}\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "{'question': \"Quel est l'algorithme de tri adapté aux listes de petite taille ?\", 'options': ['0', '1', '2', '3'], 'correct_answer': '0'}\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "{'question': \"Quel est l'algorithme utilisé pour trouver un arbre couvrant minimal dans un graphe pondéré ?\", 'options': ['0', '1', '2', '3'], 'correct_answer': '0'}\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "{'question': \"Quelle est la complexité spatiale de l'algorithme de tri rapide ?\", 'options': ['0', '1', '2', '3'], 'correct_answer': '1'}\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "{'question': 'Quelle est la complexité temporelle de la recherche binaire ?', 'options': ['0', '1', '2', '3'], 'correct_answer': '0'}\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "{'question': \"Quelle est la complexité temporelle de l'algorithme de Kruskal ?\", 'options': ['0', '1', '2', '3'], 'correct_answer': '0'}\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "{'question': \"Quelle est la complexité temporelle de l'algorithme de recherche en profondeur ?\", 'options': ['0', '1', '2', '3'], 'correct_answer': '0'}\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "{'question': \"Quel est l'algorithme de tri adapté aux listes presque triées ?\", 'options': ['0', '1', '2', '3'], 'correct_answer': '0'}\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "{'question': \"Quel est l'algorithme utilisé pour effectuer une recherche en largeur dans un graphe ?\", 'options': ['0', '1', '2', '3'], 'correct_answer': '0'}\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "{'question': \"Quelle est la complexité temporelle de l'algorithme de recherche linéaire ?\", 'options': ['0', '1', '2', '3'], 'correct_answer': '1'}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Activation, Dense, LSTM\n",
    "\n",
    "data = [\n",
    "    (\"Quel est l'algorithme de tri le plus rapide ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri rapide\"),\n",
    "    (\"Quelle est la complexité temporelle du tri fusion ?\", \n",
    "     [\"O(n log n)\", \"O(n^2)\", \"O(n)\", \"O(log n)\"], \n",
    "     \"O(n log n)\"),\n",
    "    (\"Quel est l'algorithme de recherche le plus efficace ?\", \n",
    "     [\"Recherche séquentielle\", \"Recherche binaire\", \"Recherche exponentielle\", \"Recherche linéaire\"], \n",
    "     \"Recherche binaire\"),\n",
    "    (\"Quelle est la complexité temporelle de la recherche binaire ?\", \n",
    "     [\"O(log n)\", \"O(n)\", \"O(n log n)\", \"O(n^2)\"], \n",
    "     \"O(log n)\"),\n",
    "    (\"Quel est l'algorithme de tri adapté aux listes presque triées ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri par insertion\"),\n",
    "    (\"Quel est l'algorithme de tri adapté aux listes de petite taille ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri par insertion\"),\n",
    "    (\"Quelle est la complexité temporelle de la recherche séquentielle ?\", \n",
    "     [\"O(n log n)\", \"O(n)\", \"O(log n)\", \"O(n^2)\"], \n",
    "     \"O(n)\"),\n",
    "    (\"Quelle est la complexité spatiale de l'algorithme de tri rapide ?\", \n",
    "     [\"O(n)\", \"O(log n)\", \"O(n^2)\", \"O(n log n)\"], \n",
    "     \"O(log n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe pondéré ?\", \n",
    "     [\"Algorithme de Dijkstra\", \"Algorithme de Bellman-Ford\", \"Algorithme de Floyd-Warshall\", \"Algorithme de Kruskal\"], \n",
    "     \"Algorithme de Dijkstra\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de recherche linéaire ?\", \n",
    "     [\"O(log n)\", \"O(n)\", \"O(n log n)\", \"O(n^2)\"], \n",
    "     \"O(n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour trouver un arbre couvrant minimal dans un graphe pondéré ?\", \n",
    "     [\"Algorithme de Prim\", \"Algorithme de Kruskal\", \"Algorithme de Dijkstra\", \"Algorithme de Bellman-Ford\"], \n",
    "     \"Algorithme de Prim\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de Kruskal ?\", \n",
    "     [\"O(n log n)\", \"O(n)\", \"O(log n)\", \"O(n^2)\"], \n",
    "     \"O(n log n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe avec des arêtes de poids négatif ?\", \n",
    "     [\"Algorithme de Dijkstra\", \"Algorithme de Bellman-Ford\", \"Algorithme de Floyd-Warshall\", \"Algorithme de Kruskal\"], \n",
    "     \"Algorithme de Bellman-Ford\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de Floyd-Warshall ?\", \n",
    "     [\"O(n^3)\", \"O(n^2)\", \"O(n log n)\", \"O(n)\"], \n",
    "     \"O(n^3)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour effectuer une recherche en profondeur dans un graphe ?\", \n",
    "     [\"Parcours en profondeur d'abord (DFS)\", \"Parcours en largeur d'abord (BFS)\", \"Algorithme de Kruskal\", \"Algorithme de Prim\"], \n",
    "     \"Parcours en profondeur d'abord (DFS)\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de recherche en profondeur ?\", \n",
    "     [\"O(n)\", \"O(log n)\", \"O(n^2)\", \"O(n log n)\"], \n",
    "     \"O(n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour effectuer une recherche en largeur dans un graphe ?\", \n",
    "     [\"Parcours en largeur d'abord (BFS)\", \"Parcours en profondeur d'abord (DFS)\", \"Algorithme de Kruskal\", \"Algorithme de Prim\"], \n",
    "     \"Parcours en largeur d'abord (BFS)\")\n",
    "]\n",
    "\n",
    "def preprocess_data(data):\n",
    "    processed_data = []\n",
    "    for question, options, answer in data:\n",
    "        options_one_hot = [tf.keras.utils.to_categorical(i, num_classes=len(options)) for i in range(len(options))]\n",
    "        answer_index = options.index(answer)\n",
    "        answer_one_hot = tf.keras.utils.to_categorical(answer_index, num_classes=len(options))\n",
    "        processed_data.append((question, options_one_hot, answer_one_hot))\n",
    "    return processed_data\n",
    "\n",
    "processed_data = preprocess_data(data)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(None, len(processed_data[0][1])))) \n",
    "model.add(Dense(len(processed_data[0][1]), activation='softmax')) \n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01)) \n",
    "\n",
    "x_train = np.array([options for _, options, _ in processed_data])\n",
    "y_train = np.array([answer for _, _, answer in processed_data])\n",
    "model.fit(x_train, y_train, batch_size=256, epochs=4)\n",
    "\n",
    "def generate_question(model, generated_questions):\n",
    "    unused_questions = [idx for idx in range(len(data)) if idx not in generated_questions]\n",
    "    question_idx = random.choice(unused_questions)\n",
    "    \n",
    "    generated_questions.add(question_idx)\n",
    "    question_text, options, correct_answer = processed_data[question_idx]\n",
    "    \n",
    "    predicted_answer = model.predict(np.array([options]))\n",
    "    predicted_answer_index = np.argmax(predicted_answer)\n",
    "    predicted_answer_text = options[predicted_answer_index]\n",
    "   \n",
    "    options_text = [str(i) for i in range(len(options))]\n",
    "    correct_answer_text = str(np.argmax(correct_answer))\n",
    "    \n",
    "    return {\"question\": question_text, \"options\": options_text, \"correct_answer\": correct_answer_text}\n",
    "\n",
    "# je genere et afficher 10 QCM\n",
    "generated_questions = set()  # Pour garder une trace des questions déjà générées\n",
    "for _ in range(10):\n",
    "    question = generate_question(model, generated_questions)\n",
    "    print(question)\n",
    "\n",
    "\n",
    "# je Génére le fichier XML pour Moodle\n",
    "root = ET.Element(\"quiz\")\n",
    "for i, question_idx in enumerate(generated_questions, start=1):\n",
    "    qcm = processed_data[question_idx]\n",
    "    question = ET.SubElement(root, \"question\", type=\"multichoice\")\n",
    "    name = ET.SubElement(question, \"name\")\n",
    "    text = ET.SubElement(name, \"text\")\n",
    "    text.text = f\"Question {i}\"\n",
    "    questiontext = ET.SubElement(question, \"questiontext\", format=\"html\")\n",
    "    text = ET.SubElement(questiontext, \"text\")\n",
    "    text.text = f\"<![CDATA[<p></p><div><div><div>{qcm[0]}</div></div><br></div><br><p></p>]]>\"  # Utiliser qcm[0] pour la question\n",
    "    generalfeedback = ET.SubElement(question, \"generalfeedback\", format=\"html\")\n",
    "    text = ET.SubElement(generalfeedback, \"text\")\n",
    "    text.text = \"<![CDATA[<p>none</p>]]>\"\n",
    "    defaultgrade = ET.SubElement(question, \"defaultgrade\")\n",
    "    defaultgrade.text = \"1.0000000\"\n",
    "    penalty = ET.SubElement(question, \"penalty\")\n",
    "    penalty.text = \"0.3333333\"\n",
    "    hidden = ET.SubElement(question, \"hidden\")\n",
    "    hidden.text = \"0\"\n",
    "    single = ET.SubElement(question, \"single\")\n",
    "    single.text = \"true\"\n",
    "    shuffleanswers = ET.SubElement(question, \"shuffleanswers\")\n",
    "    shuffleanswers.text = \"true\"\n",
    "    answernumbering = ET.SubElement(question, \"answernumbering\")\n",
    "    answernumbering.text = \"abc\"\n",
    "    for j, option in enumerate(qcm[1], start=1): \n",
    "        answer = ET.SubElement(question, \"answer\", fraction=\"100\" if np.argmax(qcm[2]) == j - 1 else \"0\", format=\"html\")\n",
    "        text = ET.SubElement(answer, \"text\")\n",
    "        text.text = f\"<![CDATA[<p></p><div><div><div>{option}</div></div><br></div><br><p></p>]]>\"\n",
    "        feedback = ET.SubElement(answer, \"feedback\", format=\"html\")\n",
    "        text = ET.SubElement(feedback, \"text\")\n",
    "        text.text = \"<![CDATA[<p>none</p>]]>\"\n",
    "\n",
    "tree = ET.ElementTree(root)\n",
    "tree.write(\"BANK_QUESTIONS_2.xml\", encoding=\"utf-8\", xml_declaration=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.3747\n",
      "Epoch 2/4\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0307\n",
      "Epoch 3/4\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8956\n",
      "Epoch 4/4\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.0941\n",
      "1/1 [==============================] - 1s 639ms/step\n",
      "{'question': \"Quel est l'algorithme de tri adapté aux listes presque triées ?\", 'options': ['Tri par insertion', 'Tri fusion', 'Tri rapide', 'Tri à bulles'], 'correct_answer': 'Tri par insertion'}\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "{'question': 'Quelle est la complexité temporelle de la recherche binaire ?', 'options': ['O(log n)', 'O(n)', 'O(n log n)', 'O(n^2)'], 'correct_answer': 'O(log n)'}\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "{'question': \"Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe avec des arêtes de poids négatif ?\", 'options': ['Algorithme de Dijkstra', 'Algorithme de Bellman-Ford', 'Algorithme de Floyd-Warshall', 'Algorithme de Kruskal'], 'correct_answer': 'Algorithme de Bellman-Ford'}\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "{'question': \"Quelle est la complexité temporelle de l'algorithme de Kruskal ?\", 'options': ['O(n log n)', 'O(n)', 'O(log n)', 'O(n^2)'], 'correct_answer': 'O(n log n)'}\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "{'question': \"Quel est l'algorithme utilisé pour trouver un arbre couvrant minimal dans un graphe pondéré ?\", 'options': ['Algorithme de Prim', 'Algorithme de Kruskal', 'Algorithme de Dijkstra', 'Algorithme de Bellman-Ford'], 'correct_answer': 'Algorithme de Prim'}\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "{'question': \"Quel est l'algorithme de tri adapté aux listes de petite taille ?\", 'options': ['Tri par insertion', 'Tri fusion', 'Tri rapide', 'Tri à bulles'], 'correct_answer': 'Tri par insertion'}\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "{'question': \"Quel est l'algorithme de tri le plus rapide ?\", 'options': ['Tri par insertion', 'Tri fusion', 'Tri rapide', 'Tri à bulles'], 'correct_answer': 'Tri rapide'}\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "{'question': 'Quelle est la complexité temporelle de la recherche séquentielle ?', 'options': ['O(n log n)', 'O(n)', 'O(log n)', 'O(n^2)'], 'correct_answer': 'O(n)'}\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "{'question': \"Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe pondéré ?\", 'options': ['Algorithme de Dijkstra', 'Algorithme de Bellman-Ford', 'Algorithme de Floyd-Warshall', 'Algorithme de Kruskal'], 'correct_answer': 'Algorithme de Dijkstra'}\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "{'question': \"Quel est l'algorithme utilisé pour effectuer une recherche en largeur dans un graphe ?\", 'options': [\"Parcours en largeur d'abord (BFS)\", \"Parcours en profondeur d'abord (DFS)\", 'Algorithme de Kruskal', 'Algorithme de Prim'], 'correct_answer': \"Parcours en largeur d'abord (BFS)\"}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Activation, Dense, LSTM\n",
    "\n",
    "data = [\n",
    "    (\"Quel est l'algorithme de tri le plus rapide ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri rapide\"),\n",
    "    (\"Quelle est la complexité temporelle du tri fusion ?\", \n",
    "     [\"O(n log n)\", \"O(n^2)\", \"O(n)\", \"O(log n)\"], \n",
    "     \"O(n log n)\"),\n",
    "    (\"Quel est l'algorithme de recherche le plus efficace ?\", \n",
    "     [\"Recherche séquentielle\", \"Recherche binaire\", \"Recherche exponentielle\", \"Recherche linéaire\"], \n",
    "     \"Recherche binaire\"),\n",
    "    (\"Quelle est la complexité temporelle de la recherche binaire ?\", \n",
    "     [\"O(log n)\", \"O(n)\", \"O(n log n)\", \"O(n^2)\"], \n",
    "     \"O(log n)\"),\n",
    "    (\"Quel est l'algorithme de tri adapté aux listes presque triées ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri par insertion\"),\n",
    "    (\"Quel est l'algorithme de tri adapté aux listes de petite taille ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri par insertion\"),\n",
    "    (\"Quelle est la complexité temporelle de la recherche séquentielle ?\", \n",
    "     [\"O(n log n)\", \"O(n)\", \"O(log n)\", \"O(n^2)\"], \n",
    "     \"O(n)\"),\n",
    "    (\"Quelle est la complexité spatiale de l'algorithme de tri rapide ?\", \n",
    "     [\"O(n)\", \"O(log n)\", \"O(n^2)\", \"O(n log n)\"], \n",
    "     \"O(log n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe pondéré ?\", \n",
    "     [\"Algorithme de Dijkstra\", \"Algorithme de Bellman-Ford\", \"Algorithme de Floyd-Warshall\", \"Algorithme de Kruskal\"], \n",
    "     \"Algorithme de Dijkstra\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de recherche linéaire ?\", \n",
    "     [\"O(log n)\", \"O(n)\", \"O(n log n)\", \"O(n^2)\"], \n",
    "     \"O(n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour trouver un arbre couvrant minimal dans un graphe pondéré ?\", \n",
    "     [\"Algorithme de Prim\", \"Algorithme de Kruskal\", \"Algorithme de Dijkstra\", \"Algorithme de Bellman-Ford\"], \n",
    "     \"Algorithme de Prim\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de Kruskal ?\", \n",
    "     [\"O(n log n)\", \"O(n)\", \"O(log n)\", \"O(n^2)\"], \n",
    "     \"O(n log n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe avec des arêtes de poids négatif ?\", \n",
    "     [\"Algorithme de Dijkstra\", \"Algorithme de Bellman-Ford\", \"Algorithme de Floyd-Warshall\", \"Algorithme de Kruskal\"], \n",
    "     \"Algorithme de Bellman-Ford\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de Floyd-Warshall ?\", \n",
    "     [\"O(n^3)\", \"O(n^2)\", \"O(n log n)\", \"O(n)\"], \n",
    "     \"O(n^3)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour effectuer une recherche en profondeur dans un graphe ?\", \n",
    "     [\"Parcours en profondeur d'abord (DFS)\", \"Parcours en largeur d'abord (BFS)\", \"Algorithme de Kruskal\", \"Algorithme de Prim\"], \n",
    "     \"Parcours en profondeur d'abord (DFS)\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de recherche en profondeur ?\", \n",
    "     [\"O(n)\", \"O(log n)\", \"O(n^2)\", \"O(n log n)\"], \n",
    "     \"O(n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour effectuer une recherche en largeur dans un graphe ?\", \n",
    "     [\"Parcours en largeur d'abord (BFS)\", \"Parcours en profondeur d'abord (DFS)\", \"Algorithme de Kruskal\", \"Algorithme de Prim\"], \n",
    "     \"Parcours en largeur d'abord (BFS)\")\n",
    "]\n",
    "\n",
    "def preprocess_data(data):\n",
    "    processed_data = []\n",
    "    for question, options, answer in data:\n",
    "        options_one_hot = [tf.keras.utils.to_categorical(i, num_classes=len(options)) for i in range(len(options))]\n",
    "        answer_index = options.index(answer)\n",
    "        answer_one_hot = tf.keras.utils.to_categorical(answer_index, num_classes=len(options))\n",
    "        processed_data.append((question, options_one_hot, answer_one_hot))\n",
    "    return processed_data\n",
    "\n",
    "processed_data = preprocess_data(data)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(None, len(processed_data[0][1])))) \n",
    "model.add(Dense(len(processed_data[0][1]), activation='softmax'))  \n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01)) \n",
    "\n",
    "x_train = np.array([options for _, options, _ in processed_data])\n",
    "y_train = np.array([answer for _, _, answer in processed_data])\n",
    "model.fit(x_train, y_train, batch_size=256, epochs=4)\n",
    "\n",
    "def generate_question(model, generated_questions):\n",
    "    unused_questions = [idx for idx in range(len(data)) if idx not in generated_questions]\n",
    "    question_idx = random.choice(unused_questions)\n",
    "    generated_questions.add(question_idx)\n",
    "    question_text, options, correct_answer = processed_data[question_idx]\n",
    "    \n",
    "    # Prédire la réponse\n",
    "    predicted_answer = model.predict(np.array([options]))\n",
    "    predicted_answer_index = np.argmax(predicted_answer)\n",
    "    predicted_answer_text = options[predicted_answer_index]\n",
    "    \n",
    "    # Convertir les options en textes\n",
    "    options_text = [option for option in data[question_idx][1]]\n",
    "    correct_answer_text = data[question_idx][2]\n",
    "    \n",
    "    return {\"question\": question_text, \"options\": options_text, \"correct_answer\": correct_answer_text}\n",
    "\n",
    "generated_questions = set()  \n",
    "for _ in range(10):\n",
    "    question = generate_question(model, generated_questions)\n",
    "    print(question)\n",
    "\n",
    "# Générer le fichier XML pour Moodle\n",
    "root = ET.Element(\"quiz\")\n",
    "for i, question_idx in enumerate(generated_questions, start=1):\n",
    "    qcm = processed_data[question_idx] \n",
    "    question = ET.SubElement(root, \"question\", type=\"multichoice\")\n",
    "    name = ET.SubElement(question, \"name\")\n",
    "    text = ET.SubElement(name, \"text\")\n",
    "    text.text = f\"Question {i}\"\n",
    "    questiontext = ET.SubElement(question, \"questiontext\", format=\"html\")\n",
    "    text = ET.SubElement(questiontext, \"text\")\n",
    "    text.text = f\"<![CDATA[<p></p><div><div><div>{qcm[0]}</div></div><br></div><br><p></p>]]>\"\n",
    "    generalfeedback = ET.SubElement(question, \"generalfeedback\", format=\"html\")\n",
    "    text = ET.SubElement(generalfeedback, \"text\")\n",
    "    text.text = \"<![CDATA[<p>none</p>]]>\"\n",
    "    defaultgrade = ET.SubElement(question, \"defaultgrade\")\n",
    "    defaultgrade.text = \"1.0000000\"\n",
    "    penalty = ET.SubElement(question, \"penalty\")\n",
    "    penalty.text = \"0.3333333\"\n",
    "    hidden = ET.SubElement(question, \"hidden\")\n",
    "    hidden.text = \"0\"\n",
    "    single = ET.SubElement(question, \"single\")\n",
    "    single.text = \"true\"\n",
    "    shuffleanswers = ET.SubElement(question, \"shuffleanswers\")\n",
    "    shuffleanswers.text = \"true\"\n",
    "    answernumbering = ET.SubElement(question, \"answernumbering\")\n",
    "    answernumbering.text = \"abc\"\n",
    "    for j, option in enumerate(qcm[1], start=1): \n",
    "        answer = ET.SubElement(question, \"answer\", fraction=\"100\" if np.argmax(qcm[2]) == j - 1 else \"0\", format=\"html\")\n",
    "        text = ET.SubElement(answer, \"text\")\n",
    "        text.text = f\"<![CDATA[<p></p><div><div><div>{option}</div></div><br></div><br><p></p>]]>\"\n",
    "        feedback = ET.SubElement(answer, \"feedback\", format=\"html\")\n",
    "        text = ET.SubElement(feedback, \"text\")\n",
    "        text.text = \"<![CDATA[<p>none</p>]]>\"\n",
    "\n",
    "tree = ET.ElementTree(root)\n",
    "tree.write(\"BANK_QUESTIONS_3.xml\", encoding=\"utf-8\", xml_declaration=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.3891\n",
      "Epoch 2/4\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0130\n",
      "Epoch 3/4\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9066\n",
      "Epoch 4/4\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.2070\n",
      "1/1 [==============================] - 1s 743ms/step\n",
      "{'question': \"Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe pondéré ?\", 'options': ['Algorithme de Dijkstra', 'Algorithme de Bellman-Ford', 'Algorithme de Floyd-Warshall', 'Algorithme de Kruskal'], 'correct_answer': 'Algorithme de Dijkstra'}\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "{'question': \"Quelle est la complexité temporelle de l'algorithme de Floyd-Warshall ?\", 'options': ['O(n^3)', 'O(n^2)', 'O(n log n)', 'O(n)'], 'correct_answer': 'O(n^3)'}\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "{'question': \"Quelle est la complexité temporelle de l'algorithme de Kruskal ?\", 'options': ['O(n log n)', 'O(n)', 'O(log n)', 'O(n^2)'], 'correct_answer': 'O(n log n)'}\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "{'question': \"Quel est l'algorithme de tri le plus rapide ?\", 'options': ['Tri par insertion', 'Tri fusion', 'Tri rapide', 'Tri à bulles'], 'correct_answer': 'Tri rapide'}\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "{'question': \"Quel est l'algorithme de tri adapté aux listes presque triées ?\", 'options': ['Tri par insertion', 'Tri fusion', 'Tri rapide', 'Tri à bulles'], 'correct_answer': 'Tri par insertion'}\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "{'question': \"Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe avec des arêtes de poids négatif ?\", 'options': ['Algorithme de Dijkstra', 'Algorithme de Bellman-Ford', 'Algorithme de Floyd-Warshall', 'Algorithme de Kruskal'], 'correct_answer': 'Algorithme de Bellman-Ford'}\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "{'question': \"Quel est l'algorithme utilisé pour effectuer une recherche en largeur dans un graphe ?\", 'options': [\"Parcours en largeur d'abord (BFS)\", \"Parcours en profondeur d'abord (DFS)\", 'Algorithme de Kruskal', 'Algorithme de Prim'], 'correct_answer': \"Parcours en largeur d'abord (BFS)\"}\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "{'question': 'Quelle est la complexité temporelle du tri fusion ?', 'options': ['O(n log n)', 'O(n^2)', 'O(n)', 'O(log n)'], 'correct_answer': 'O(n log n)'}\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "{'question': \"Quelle est la complexité spatiale de l'algorithme de tri rapide ?\", 'options': ['O(n)', 'O(log n)', 'O(n^2)', 'O(n log n)'], 'correct_answer': 'O(log n)'}\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "{'question': \"Quelle est la complexité temporelle de l'algorithme de recherche en profondeur ?\", 'options': ['O(n)', 'O(log n)', 'O(n^2)', 'O(n log n)'], 'correct_answer': 'O(n)'}\n"
     ]
    }
   ],
   "source": [
    "##########  Proposition en tableau Numpy  dans le fichier .xml ##########\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Activation, Dense, LSTM\n",
    "\n",
    "data = [\n",
    "    (\"Quel est l'algorithme de tri le plus rapide ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri rapide\"),\n",
    "    (\"Quelle est la complexité temporelle du tri fusion ?\", \n",
    "     [\"O(n log n)\", \"O(n^2)\", \"O(n)\", \"O(log n)\"], \n",
    "     \"O(n log n)\"),\n",
    "    (\"Quel est l'algorithme de recherche le plus efficace ?\", \n",
    "     [\"Recherche séquentielle\", \"Recherche binaire\", \"Recherche exponentielle\", \"Recherche linéaire\"], \n",
    "     \"Recherche binaire\"),\n",
    "    (\"Quelle est la complexité temporelle de la recherche binaire ?\", \n",
    "     [\"O(log n)\", \"O(n)\", \"O(n log n)\", \"O(n^2)\"], \n",
    "     \"O(log n)\"),\n",
    "    (\"Quel est l'algorithme de tri adapté aux listes presque triées ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri par insertion\"),\n",
    "    (\"Quel est l'algorithme de tri adapté aux listes de petite taille ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri par insertion\"),\n",
    "    (\"Quelle est la complexité temporelle de la recherche séquentielle ?\", \n",
    "     [\"O(n log n)\", \"O(n)\", \"O(log n)\", \"O(n^2)\"], \n",
    "     \"O(n)\"),\n",
    "    (\"Quelle est la complexité spatiale de l'algorithme de tri rapide ?\", \n",
    "     [\"O(n)\", \"O(log n)\", \"O(n^2)\", \"O(n log n)\"], \n",
    "     \"O(log n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe pondéré ?\", \n",
    "     [\"Algorithme de Dijkstra\", \"Algorithme de Bellman-Ford\", \"Algorithme de Floyd-Warshall\", \"Algorithme de Kruskal\"], \n",
    "     \"Algorithme de Dijkstra\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de recherche linéaire ?\", \n",
    "     [\"O(log n)\", \"O(n)\", \"O(n log n)\", \"O(n^2)\"], \n",
    "     \"O(n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour trouver un arbre couvrant minimal dans un graphe pondéré ?\", \n",
    "     [\"Algorithme de Prim\", \"Algorithme de Kruskal\", \"Algorithme de Dijkstra\", \"Algorithme de Bellman-Ford\"], \n",
    "     \"Algorithme de Prim\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de Kruskal ?\", \n",
    "     [\"O(n log n)\", \"O(n)\", \"O(log n)\", \"O(n^2)\"], \n",
    "     \"O(n log n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe avec des arêtes de poids négatif ?\", \n",
    "     [\"Algorithme de Dijkstra\", \"Algorithme de Bellman-Ford\", \"Algorithme de Floyd-Warshall\", \"Algorithme de Kruskal\"], \n",
    "     \"Algorithme de Bellman-Ford\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de Floyd-Warshall ?\", \n",
    "     [\"O(n^3)\", \"O(n^2)\", \"O(n log n)\", \"O(n)\"], \n",
    "     \"O(n^3)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour effectuer une recherche en profondeur dans un graphe ?\", \n",
    "     [\"Parcours en profondeur d'abord (DFS)\", \"Parcours en largeur d'abord (BFS)\", \"Algorithme de Kruskal\", \"Algorithme de Prim\"], \n",
    "     \"Parcours en profondeur d'abord (DFS)\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de recherche en profondeur ?\", \n",
    "     [\"O(n)\", \"O(log n)\", \"O(n^2)\", \"O(n log n)\"], \n",
    "     \"O(n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour effectuer une recherche en largeur dans un graphe ?\", \n",
    "     [\"Parcours en largeur d'abord (BFS)\", \"Parcours en profondeur d'abord (DFS)\", \"Algorithme de Kruskal\", \"Algorithme de Prim\"], \n",
    "     \"Parcours en largeur d'abord (BFS)\")\n",
    "]\n",
    "\n",
    "\n",
    "def preprocess_data(data):\n",
    "    processed_data = []\n",
    "    for question, options, answer in data:\n",
    "        options_one_hot = [tf.keras.utils.to_categorical(i, num_classes=len(options)) for i in range(len(options))]\n",
    "        answer_index = options.index(answer)\n",
    "        answer_one_hot = tf.keras.utils.to_categorical(answer_index, num_classes=len(options))\n",
    "        processed_data.append((question, options_one_hot, answer_one_hot))\n",
    "    return processed_data\n",
    "\n",
    "processed_data = preprocess_data(data)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(None, len(processed_data[0][1]))))  \n",
    "model.add(Dense(len(processed_data[0][1]), activation='softmax'))  \n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01)) \n",
    "\n",
    "x_train = np.array([options for _, options, _ in processed_data])\n",
    "y_train = np.array([answer for _, _, answer in processed_data])\n",
    "model.fit(x_train, y_train, batch_size=256, epochs=4)\n",
    "\n",
    "def generate_question(model, generated_questions):\n",
    "    unused_questions = [idx for idx in range(len(data)) if idx not in generated_questions]\n",
    "    question_idx = random.choice(unused_questions)\n",
    "    generated_questions.add(question_idx)\n",
    "    question_text, options, correct_answer = processed_data[question_idx]\n",
    "    \n",
    "    predicted_answer = model.predict(np.array([options]))\n",
    "    predicted_answer_index = np.argmax(predicted_answer)\n",
    "    predicted_answer_text = options[predicted_answer_index]\n",
    "    \n",
    "   \n",
    "    options_text = [option for option in data[question_idx][1]]\n",
    "    correct_answer_text = data[question_idx][2]\n",
    "    \n",
    "    return {\"question\": question_text, \"options\": options_text, \"correct_answer\": correct_answer_text}\n",
    "\n",
    "generated_questions = set() \n",
    "for _ in range(10):\n",
    "    question = generate_question(model, generated_questions)\n",
    "    print(question)\n",
    "\n",
    "\n",
    "with open(\"BANK_QUESTIONS_4.xml\", \"w\") as f:\n",
    "    f.write(\"<quiz>\\n\")\n",
    "    for i, question_idx in enumerate(generated_questions, start=1):\n",
    "        qcm = processed_data[question_idx]  \n",
    "        f.write(f\"  <!-- question: {i} -->\\n\")\n",
    "        f.write(f\"  <question type=\\\"multichoice\\\">\\n\")\n",
    "        f.write(f\"    <name>\\n\")\n",
    "        f.write(f\"      <text>Question {i}</text>\\n\")\n",
    "        f.write(f\"    </name>\\n\")\n",
    "        f.write(f\"    <questiontext format=\\\"html\\\">\\n\")\n",
    "        f.write(f\"      <text><![CDATA[<pre>{qcm[0]}</pre>]]></text>\\n\")\n",
    "        f.write(f\"    </questiontext>\\n\")\n",
    "        f.write(f\"    <generalfeedback format=\\\"html\\\">\\n\")\n",
    "        f.write(f\"      <text><![CDATA[<p>none</p>]]></text>\\n\")\n",
    "        f.write(f\"    </generalfeedback>\\n\")\n",
    "        f.write(f\"    <defaultgrade>1.0000000</defaultgrade>\\n\")\n",
    "        f.write(f\"    <penalty>0.3333333</penalty>\\n\")\n",
    "        f.write(f\"    <hidden>0</hidden>\\n\")\n",
    "        f.write(f\"    <single>true</single>\\n\")\n",
    "        f.write(f\"    <shuffleanswers>true</shuffleanswers>\\n\")\n",
    "        f.write(f\"    <answernumbering>abc</answernumbering>\\n\")\n",
    "        for j, option in enumerate(qcm[1], start=1):\n",
    "            f.write(f\"    <answer fraction=\\\"{'100' if np.argmax(qcm[2]) == j - 1 else '0'}\\\" format=\\\"html\\\">\\n\")\n",
    "            f.write(f\"      <text><![CDATA[<pre>{option}</pre>]]></text>\\n\")\n",
    "            f.write(f\"      <feedback format=\\\"html\\\">\\n\")\n",
    "            f.write(f\"        <text><![CDATA[<p>none</p>]]></text>\\n\")\n",
    "            f.write(f\"      </feedback>\\n\")\n",
    "            f.write(f\"    </answer>\\n\")\n",
    "        f.write(f\"  </question>\\n\")\n",
    "    f.write(\"</quiz>\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.3605\n",
      "Epoch 2/4\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9855\n",
      "Epoch 3/4\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9363\n",
      "Epoch 4/4\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.1045\n",
      "1/1 [==============================] - 0s 463ms/step\n",
      "{'question': \"Quel est l'algorithme utilisé pour effectuer une recherche en profondeur dans un graphe ?\", 'options': [\"Parcours en profondeur d'abord (DFS)\", \"Parcours en largeur d'abord (BFS)\", 'Algorithme de Kruskal', 'Algorithme de Prim'], 'correct_answer': \"Parcours en profondeur d'abord (DFS)\"}\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "{'question': 'Quelle est la complexité temporelle du tri fusion ?', 'options': ['O(n log n)', 'O(n^2)', 'O(n)', 'O(log n)'], 'correct_answer': 'O(n log n)'}\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "{'question': \"Quel est l'algorithme de recherche le plus efficace ?\", 'options': ['Recherche séquentielle', 'Recherche binaire', 'Recherche exponentielle', 'Recherche linéaire'], 'correct_answer': 'Recherche binaire'}\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "{'question': \"Quelle est la complexité temporelle de l'algorithme de recherche linéaire ?\", 'options': ['O(log n)', 'O(n)', 'O(n log n)', 'O(n^2)'], 'correct_answer': 'O(n)'}\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "{'question': \"Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe avec des arêtes de poids négatif ?\", 'options': ['Algorithme de Dijkstra', 'Algorithme de Bellman-Ford', 'Algorithme de Floyd-Warshall', 'Algorithme de Kruskal'], 'correct_answer': 'Algorithme de Bellman-Ford'}\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "{'question': \"Quelle est la complexité spatiale de l'algorithme de tri rapide ?\", 'options': ['O(n)', 'O(log n)', 'O(n^2)', 'O(n log n)'], 'correct_answer': 'O(log n)'}\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "{'question': 'Quelle est la complexité temporelle de la recherche séquentielle ?', 'options': ['O(n log n)', 'O(n)', 'O(log n)', 'O(n^2)'], 'correct_answer': 'O(n)'}\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "{'question': 'Quelle est la complexité temporelle de la recherche binaire ?', 'options': ['O(log n)', 'O(n)', 'O(n log n)', 'O(n^2)'], 'correct_answer': 'O(log n)'}\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "{'question': \"Quel est l'algorithme de tri le plus rapide ?\", 'options': ['Tri par insertion', 'Tri fusion', 'Tri rapide', 'Tri à bulles'], 'correct_answer': 'Tri rapide'}\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "{'question': \"Quel est l'algorithme de tri adapté aux listes de petite taille ?\", 'options': ['Tri par insertion', 'Tri fusion', 'Tri rapide', 'Tri à bulles'], 'correct_answer': 'Tri par insertion'}\n"
     ]
    }
   ],
   "source": [
    "########## Proposition en texte dans le .xml et retour a la ligne pour chque nouvelle question ##########\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Activation, Dense, LSTM\n",
    "\n",
    "data = [\n",
    "    (\"Quel est l'algorithme de tri le plus rapide ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri rapide\"),\n",
    "    (\"Quelle est la complexité temporelle du tri fusion ?\", \n",
    "     [\"O(n log n)\", \"O(n^2)\", \"O(n)\", \"O(log n)\"], \n",
    "     \"O(n log n)\"),\n",
    "    (\"Quel est l'algorithme de recherche le plus efficace ?\", \n",
    "     [\"Recherche séquentielle\", \"Recherche binaire\", \"Recherche exponentielle\", \"Recherche linéaire\"], \n",
    "     \"Recherche binaire\"),\n",
    "    (\"Quelle est la complexité temporelle de la recherche binaire ?\", \n",
    "     [\"O(log n)\", \"O(n)\", \"O(n log n)\", \"O(n^2)\"], \n",
    "     \"O(log n)\"),\n",
    "    (\"Quel est l'algorithme de tri adapté aux listes presque triées ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri par insertion\"),\n",
    "    (\"Quel est l'algorithme de tri adapté aux listes de petite taille ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri par insertion\"),\n",
    "    (\"Quelle est la complexité temporelle de la recherche séquentielle ?\", \n",
    "     [\"O(n log n)\", \"O(n)\", \"O(log n)\", \"O(n^2)\"], \n",
    "     \"O(n)\"),\n",
    "    (\"Quelle est la complexité spatiale de l'algorithme de tri rapide ?\", \n",
    "     [\"O(n)\", \"O(log n)\", \"O(n^2)\", \"O(n log n)\"], \n",
    "     \"O(log n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe pondéré ?\", \n",
    "     [\"Algorithme de Dijkstra\", \"Algorithme de Bellman-Ford\", \"Algorithme de Floyd-Warshall\", \"Algorithme de Kruskal\"], \n",
    "     \"Algorithme de Dijkstra\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de recherche linéaire ?\", \n",
    "     [\"O(log n)\", \"O(n)\", \"O(n log n)\", \"O(n^2)\"], \n",
    "     \"O(n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour trouver un arbre couvrant minimal dans un graphe pondéré ?\", \n",
    "     [\"Algorithme de Prim\", \"Algorithme de Kruskal\", \"Algorithme de Dijkstra\", \"Algorithme de Bellman-Ford\"], \n",
    "     \"Algorithme de Prim\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de Kruskal ?\", \n",
    "     [\"O(n log n)\", \"O(n)\", \"O(log n)\", \"O(n^2)\"], \n",
    "     \"O(n log n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe avec des arêtes de poids négatif ?\", \n",
    "     [\"Algorithme de Dijkstra\", \"Algorithme de Bellman-Ford\", \"Algorithme de Floyd-Warshall\", \"Algorithme de Kruskal\"], \n",
    "     \"Algorithme de Bellman-Ford\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de Floyd-Warshall ?\", \n",
    "     [\"O(n^3)\", \"O(n^2)\", \"O(n log n)\", \"O(n)\"], \n",
    "     \"O(n^3)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour effectuer une recherche en profondeur dans un graphe ?\", \n",
    "     [\"Parcours en profondeur d'abord (DFS)\", \"Parcours en largeur d'abord (BFS)\", \"Algorithme de Kruskal\", \"Algorithme de Prim\"], \n",
    "     \"Parcours en profondeur d'abord (DFS)\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de recherche en profondeur ?\", \n",
    "     [\"O(n)\", \"O(log n)\", \"O(n^2)\", \"O(n log n)\"], \n",
    "     \"O(n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour effectuer une recherche en largeur dans un graphe ?\", \n",
    "     [\"Parcours en largeur d'abord (BFS)\", \"Parcours en profondeur d'abord (DFS)\", \"Algorithme de Kruskal\", \"Algorithme de Prim\"], \n",
    "     \"Parcours en largeur d'abord (BFS)\")\n",
    "]\n",
    "\n",
    "def preprocess_data(data):\n",
    "    processed_data = []\n",
    "    for question, options, answer in data:\n",
    "        options_one_hot = [tf.keras.utils.to_categorical(i, num_classes=len(options)) for i in range(len(options))]\n",
    "        answer_index = options.index(answer)\n",
    "        answer_one_hot = tf.keras.utils.to_categorical(answer_index, num_classes=len(options))\n",
    "        processed_data.append((question, options_one_hot, answer_one_hot))\n",
    "    return processed_data\n",
    "\n",
    "processed_data = preprocess_data(data)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(None, len(processed_data[0][1])))) \n",
    "model.add(Dense(len(processed_data[0][1]), activation='softmax')) \n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01))\n",
    "\n",
    "x_train = np.array([options for _, options, _ in processed_data])\n",
    "y_train = np.array([answer for _, _, answer in processed_data])\n",
    "model.fit(x_train, y_train, batch_size=256, epochs=4)\n",
    "\n",
    "def generate_question(model, generated_questions):\n",
    "    unused_questions = [idx for idx in range(len(data)) if idx not in generated_questions]\n",
    "    question_idx = random.choice(unused_questions)\n",
    "    generated_questions.add(question_idx)\n",
    "    question_text, options, correct_answer = processed_data[question_idx]\n",
    "    \n",
    "    predicted_answer = model.predict(np.array([options]))\n",
    "    predicted_answer_index = np.argmax(predicted_answer)\n",
    "    predicted_answer_text = options[predicted_answer_index]\n",
    "    \n",
    "    options_text = [option for option in data[question_idx][1]]\n",
    "    correct_answer_text = data[question_idx][2]\n",
    "    \n",
    "    return {\"question\": question_text, \"options\": options_text, \"correct_answer\": correct_answer_text}\n",
    "\n",
    "generated_questions = set() \n",
    "for _ in range(10):\n",
    "    question = generate_question(model, generated_questions)\n",
    "    print(question)\n",
    "\n",
    "with open(\"BANK_QUESTIONS_5.xml\", \"w\") as f:\n",
    "    f.write(\"<quiz>\\n\")\n",
    "    for i, question_idx in enumerate(generated_questions, start=1):\n",
    "        qcm = processed_data[question_idx] \n",
    "        f.write(f\"  <!-- question: {i} -->\\n\")\n",
    "        f.write(f\"  <question type=\\\"multichoice\\\">\\n\")\n",
    "        f.write(f\"    <name>\\n\")\n",
    "        f.write(f\"      <text>Question {i}</text>\\n\")\n",
    "        f.write(f\"    </name>\\n\")\n",
    "        f.write(f\"    <questiontext format=\\\"html\\\">\\n\")\n",
    "        f.write(f\"      <text><![CDATA[<pre>{qcm[0]}</pre>]]></text>\\n\")\n",
    "        f.write(f\"    </questiontext>\\n\")\n",
    "        f.write(f\"    <generalfeedback format=\\\"html\\\">\\n\")\n",
    "        f.write(f\"      <text><![CDATA[<p>none</p>]]></text>\\n\")\n",
    "        f.write(f\"    </generalfeedback>\\n\")\n",
    "        f.write(f\"    <defaultgrade>1.0000000</defaultgrade>\\n\")\n",
    "        f.write(f\"    <penalty>0.3333333</penalty>\\n\")\n",
    "        f.write(f\"    <hidden>0</hidden>\\n\")\n",
    "        f.write(f\"    <single>true</single>\\n\")\n",
    "        f.write(f\"    <shuffleanswers>true</shuffleanswers>\\n\")\n",
    "        f.write(f\"    <answernumbering>abc</answernumbering>\\n\")\n",
    "        for j, option in enumerate(qcm[1], start=1):\n",
    "            option_text = option.argmax() + 1 \n",
    "            f.write(f\"    <answer fraction=\\\"{'100' if np.argmax(qcm[2]) == j - 1 else '0'}\\\" format=\\\"html\\\">\\n\")\n",
    "            f.write(f\"      <text><![CDATA[{option_text}. {qcm[1][j-1]}]]></text>\\n\")\n",
    "            f.write(f\"      <feedback format=\\\"html\\\">\\n\")\n",
    "            f.write(f\"        <text><![CDATA[<p>none</p>]]></text>\\n\")\n",
    "            f.write(f\"      </feedback>\\n\")\n",
    "            f.write(f\"    </answer>\\n\")\n",
    "        f.write(f\"  </question>\\n\")\n",
    "        f.write(f\"\\n\") #je retourne a la ligne pour chaque nouvelle question\n",
    "    f.write(\"</quiz>\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.3853\n",
      "Epoch 2/4\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0506\n",
      "Epoch 3/4\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8851\n",
      "Epoch 4/4\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.0824\n",
      "1/1 [==============================] - 1s 508ms/step\n",
      "{'question': \"Quelle est la complexité temporelle de l'algorithme de Kruskal ?\", 'options': ['O(n log n)', 'O(n)', 'O(log n)', 'O(n^2)'], 'correct_answer': 'O(n log n)'}\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "{'question': \"Quel est l'algorithme de tri adapté aux listes de petite taille ?\", 'options': ['Tri par insertion', 'Tri fusion', 'Tri rapide', 'Tri à bulles'], 'correct_answer': 'Tri par insertion'}\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "{'question': 'Quelle est la complexité temporelle de la recherche séquentielle ?', 'options': ['O(n log n)', 'O(n)', 'O(log n)', 'O(n^2)'], 'correct_answer': 'O(n)'}\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "{'question': \"Quel est l'algorithme de tri le plus rapide ?\", 'options': ['Tri par insertion', 'Tri fusion', 'Tri rapide', 'Tri à bulles'], 'correct_answer': 'Tri rapide'}\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "{'question': \"Quelle est la complexité temporelle de l'algorithme de recherche linéaire ?\", 'options': ['O(log n)', 'O(n)', 'O(n log n)', 'O(n^2)'], 'correct_answer': 'O(n)'}\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "{'question': 'Quelle est la complexité temporelle du tri fusion ?', 'options': ['O(n log n)', 'O(n^2)', 'O(n)', 'O(log n)'], 'correct_answer': 'O(n log n)'}\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "{'question': \"Quel est l'algorithme utilisé pour effectuer une recherche en profondeur dans un graphe ?\", 'options': [\"Parcours en profondeur d'abord (DFS)\", \"Parcours en largeur d'abord (BFS)\", 'Algorithme de Kruskal', 'Algorithme de Prim'], 'correct_answer': \"Parcours en profondeur d'abord (DFS)\"}\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "{'question': 'Quelle est la complexité temporelle de la recherche binaire ?', 'options': ['O(log n)', 'O(n)', 'O(n log n)', 'O(n^2)'], 'correct_answer': 'O(log n)'}\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "{'question': \"Quel est l'algorithme utilisé pour effectuer une recherche en largeur dans un graphe ?\", 'options': [\"Parcours en largeur d'abord (BFS)\", \"Parcours en profondeur d'abord (DFS)\", 'Algorithme de Kruskal', 'Algorithme de Prim'], 'correct_answer': \"Parcours en largeur d'abord (BFS)\"}\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "{'question': \"Quelle est la complexité spatiale de l'algorithme de tri rapide ?\", 'options': ['O(n)', 'O(log n)', 'O(n^2)', 'O(n log n)'], 'correct_answer': 'O(log n)'}\n"
     ]
    }
   ],
   "source": [
    "########## Good mais pour le  moment le formatage dans le fichier .xml se fait avec les donneés d'origine ##########\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Activation, Dense, LSTM\n",
    "\n",
    "data = [\n",
    "    (\"Quel est l'algorithme de tri le plus rapide ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri rapide\"),\n",
    "    (\"Quelle est la complexité temporelle du tri fusion ?\", \n",
    "     [\"O(n log n)\", \"O(n^2)\", \"O(n)\", \"O(log n)\"], \n",
    "     \"O(n log n)\"),\n",
    "    (\"Quel est l'algorithme de recherche le plus efficace ?\", \n",
    "     [\"Recherche séquentielle\", \"Recherche binaire\", \"Recherche exponentielle\", \"Recherche linéaire\"], \n",
    "     \"Recherche binaire\"),\n",
    "    (\"Quelle est la complexité temporelle de la recherche binaire ?\", \n",
    "     [\"O(log n)\", \"O(n)\", \"O(n log n)\", \"O(n^2)\"], \n",
    "     \"O(log n)\"),\n",
    "    (\"Quel est l'algorithme de tri adapté aux listes presque triées ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri par insertion\"),\n",
    "    (\"Quel est l'algorithme de tri adapté aux listes de petite taille ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri par insertion\"),\n",
    "    (\"Quelle est la complexité temporelle de la recherche séquentielle ?\", \n",
    "     [\"O(n log n)\", \"O(n)\", \"O(log n)\", \"O(n^2)\"], \n",
    "     \"O(n)\"),\n",
    "    (\"Quelle est la complexité spatiale de l'algorithme de tri rapide ?\", \n",
    "     [\"O(n)\", \"O(log n)\", \"O(n^2)\", \"O(n log n)\"], \n",
    "     \"O(log n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe pondéré ?\", \n",
    "     [\"Algorithme de Dijkstra\", \"Algorithme de Bellman-Ford\", \"Algorithme de Floyd-Warshall\", \"Algorithme de Kruskal\"], \n",
    "     \"Algorithme de Dijkstra\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de recherche linéaire ?\", \n",
    "     [\"O(log n)\", \"O(n)\", \"O(n log n)\", \"O(n^2)\"], \n",
    "     \"O(n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour trouver un arbre couvrant minimal dans un graphe pondéré ?\", \n",
    "     [\"Algorithme de Prim\", \"Algorithme de Kruskal\", \"Algorithme de Dijkstra\", \"Algorithme de Bellman-Ford\"], \n",
    "     \"Algorithme de Prim\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de Kruskal ?\", \n",
    "     [\"O(n log n)\", \"O(n)\", \"O(log n)\", \"O(n^2)\"], \n",
    "     \"O(n log n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe avec des arêtes de poids négatif ?\", \n",
    "     [\"Algorithme de Dijkstra\", \"Algorithme de Bellman-Ford\", \"Algorithme de Floyd-Warshall\", \"Algorithme de Kruskal\"], \n",
    "     \"Algorithme de Bellman-Ford\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de Floyd-Warshall ?\", \n",
    "     [\"O(n^3)\", \"O(n^2)\", \"O(n log n)\", \"O(n)\"], \n",
    "     \"O(n^3)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour effectuer une recherche en profondeur dans un graphe ?\", \n",
    "     [\"Parcours en profondeur d'abord (DFS)\", \"Parcours en largeur d'abord (BFS)\", \"Algorithme de Kruskal\", \"Algorithme de Prim\"], \n",
    "     \"Parcours en profondeur d'abord (DFS)\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de recherche en profondeur ?\", \n",
    "     [\"O(n)\", \"O(log n)\", \"O(n^2)\", \"O(n log n)\"], \n",
    "     \"O(n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour effectuer une recherche en largeur dans un graphe ?\", \n",
    "     [\"Parcours en largeur d'abord (BFS)\", \"Parcours en profondeur d'abord (DFS)\", \"Algorithme de Kruskal\", \"Algorithme de Prim\"], \n",
    "     \"Parcours en largeur d'abord (BFS)\")\n",
    "]\n",
    "\n",
    "def preprocess_data(data):\n",
    "    processed_data = []\n",
    "    for question, options, answer in data:\n",
    "        options_one_hot = [tf.keras.utils.to_categorical(i, num_classes=len(options)) for i in range(len(options))]\n",
    "        answer_index = options.index(answer)\n",
    "        answer_one_hot = tf.keras.utils.to_categorical(answer_index, num_classes=len(options))\n",
    "        processed_data.append((question, options_one_hot, answer_one_hot))\n",
    "    return processed_data\n",
    "\n",
    "processed_data = preprocess_data(data)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(None, len(processed_data[0][1])))) \n",
    "model.add(Dense(len(processed_data[0][1]), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01))\n",
    "\n",
    "x_train = np.array([options for _, options, _ in processed_data])\n",
    "y_train = np.array([answer for _, _, answer in processed_data])\n",
    "model.fit(x_train, y_train, batch_size=256, epochs=4)\n",
    "\n",
    "def generate_question(model, generated_questions):\n",
    "    unused_questions = [idx for idx in range(len(data)) if idx not in generated_questions]\n",
    "    question_idx = random.choice(unused_questions)\n",
    "    generated_questions.add(question_idx)\n",
    "    question_text, options, correct_answer = processed_data[question_idx]\n",
    "    \n",
    "    predicted_answer = model.predict(np.array([options]))\n",
    "    predicted_answer_index = np.argmax(predicted_answer)\n",
    "    predicted_answer_text = options[predicted_answer_index]\n",
    "    \n",
    "    options_text = [option for option in data[question_idx][1]]\n",
    "    correct_answer_text = data[question_idx][2]\n",
    "    \n",
    "    return {\"question\": question_text, \"options\": options_text, \"correct_answer\": correct_answer_text}\n",
    "\n",
    "generated_questions = set() \n",
    "for _ in range(10):\n",
    "    question = generate_question(model, generated_questions)\n",
    "    print(question)\n",
    "\n",
    "with open(\"BANK_QUESTIONS_6.xml\", \"w\") as f:\n",
    "    f.write(\"<quiz>\\n\")\n",
    "    for i, question_idx in enumerate(generated_questions, start=1):\n",
    "        qcm = processed_data[question_idx]\n",
    "        f.write(f\"  <!-- question: {i} -->\\n\")\n",
    "        f.write(f\"  <question type=\\\"multichoice\\\">\\n\")\n",
    "        f.write(f\"    <name>\\n\")\n",
    "        f.write(f\"      <text>Question {i}</text>\\n\")\n",
    "        f.write(f\"    </name>\\n\")\n",
    "        f.write(f\"    <questiontext format=\\\"html\\\">\\n\")\n",
    "        f.write(f\"      <text><![CDATA[<pre>{qcm[0]}</pre>]]></text>\\n\")\n",
    "        f.write(f\"    </questiontext>\\n\")\n",
    "        f.write(f\"    <generalfeedback format=\\\"html\\\">\\n\")\n",
    "        f.write(f\"      <text><![CDATA[<p>none</p>]]></text>\\n\")\n",
    "        f.write(f\"    </generalfeedback>\\n\")\n",
    "        f.write(f\"    <defaultgrade>1.0000000</defaultgrade>\\n\")\n",
    "        f.write(f\"    <penalty>0.3333333</penalty>\\n\")\n",
    "        f.write(f\"    <hidden>0</hidden>\\n\")\n",
    "        f.write(f\"    <single>true</single>\\n\")\n",
    "        f.write(f\"    <shuffleanswers>true</shuffleanswers>\\n\")\n",
    "        f.write(f\"    <answernumbering>abc</answernumbering>\\n\")\n",
    "        for j, option in enumerate(qcm[1], start=1):\n",
    "            option_text = chr(96 + j)  # je Convertis l'indice en lettre (a, b, c, d, ...)\n",
    "            f.write(f\"    <answer fraction=\\\"{'100' if np.argmax(qcm[2]) == j - 1 else '0'}\\\" format=\\\"html\\\">\\n\")\n",
    "            f.write(f\"      <text><![CDATA[{option_text}. {data[question_idx][1][j-1]}]]></text>\\n\")  # Utiliser les données d'origine\n",
    "            f.write(f\"      <feedback format=\\\"html\\\">\\n\")\n",
    "            f.write(f\"        <text><![CDATA[<p>none</p>]]></text>\\n\")\n",
    "            f.write(f\"      </feedback>\\n\")\n",
    "            f.write(f\"    </answer>\\n\")\n",
    "        f.write(f\"  </question>\\n\")\n",
    "        f.write(f\"\\n\")\n",
    "    f.write(\"</quiz>\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.3973\n",
      "Epoch 2/4\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0102\n",
      "Epoch 3/4\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9030\n",
      "Epoch 4/4\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1049\n",
      "1/1 [==============================] - 1s 568ms/step\n",
      "{'question': \"Quel est l'algorithme de recherche le plus efficace ?\", 'options': ['Recherche séquentielle', 'Recherche binaire', 'Recherche exponentielle', 'Recherche linéaire'], 'correct_answer': 'Recherche binaire'}\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "{'question': \"Quel est l'algorithme utilisé pour effectuer une recherche en largeur dans un graphe ?\", 'options': [\"Parcours en largeur d'abord (BFS)\", \"Parcours en profondeur d'abord (DFS)\", 'Algorithme de Kruskal', 'Algorithme de Prim'], 'correct_answer': \"Parcours en largeur d'abord (BFS)\"}\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "{'question': \"Quelle est la complexité temporelle de l'algorithme de recherche en profondeur ?\", 'options': ['O(n)', 'O(log n)', 'O(n^2)', 'O(n log n)'], 'correct_answer': 'O(n)'}\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "{'question': \"Quel est l'algorithme de tri le plus rapide ?\", 'options': ['Tri par insertion', 'Tri fusion', 'Tri rapide', 'Tri à bulles'], 'correct_answer': 'Tri rapide'}\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "{'question': \"Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe avec des arêtes de poids négatif ?\", 'options': ['Algorithme de Dijkstra', 'Algorithme de Bellman-Ford', 'Algorithme de Floyd-Warshall', 'Algorithme de Kruskal'], 'correct_answer': 'Algorithme de Bellman-Ford'}\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "{'question': \"Quel est l'algorithme utilisé pour trouver un arbre couvrant minimal dans un graphe pondéré ?\", 'options': ['Algorithme de Prim', 'Algorithme de Kruskal', 'Algorithme de Dijkstra', 'Algorithme de Bellman-Ford'], 'correct_answer': 'Algorithme de Prim'}\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "{'question': \"Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe pondéré ?\", 'options': ['Algorithme de Dijkstra', 'Algorithme de Bellman-Ford', 'Algorithme de Floyd-Warshall', 'Algorithme de Kruskal'], 'correct_answer': 'Algorithme de Dijkstra'}\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "{'question': \"Quelle est la complexité spatiale de l'algorithme de tri rapide ?\", 'options': ['O(n)', 'O(log n)', 'O(n^2)', 'O(n log n)'], 'correct_answer': 'O(log n)'}\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "{'question': \"Quel est l'algorithme de tri adapté aux listes de petite taille ?\", 'options': ['Tri par insertion', 'Tri fusion', 'Tri rapide', 'Tri à bulles'], 'correct_answer': 'Tri par insertion'}\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "{'question': 'Quelle est la complexité temporelle de la recherche binaire ?', 'options': ['O(log n)', 'O(n)', 'O(n log n)', 'O(n^2)'], 'correct_answer': 'O(log n)'}\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Toutes les questions ont été utilisées.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#############  Final ####################\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Activation, Dense, LSTM\n",
    "\n",
    "data = [\n",
    "    (\"Quel est l'algorithme de tri le plus rapide ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri rapide\"),\n",
    "    (\"Quelle est la complexité temporelle du tri fusion ?\", \n",
    "     [\"O(n log n)\", \"O(n^2)\", \"O(n)\", \"O(log n)\"], \n",
    "     \"O(n log n)\"),\n",
    "    (\"Quel est l'algorithme de recherche le plus efficace ?\", \n",
    "     [\"Recherche séquentielle\", \"Recherche binaire\", \"Recherche exponentielle\", \"Recherche linéaire\"], \n",
    "     \"Recherche binaire\"),\n",
    "    (\"Quelle est la complexité temporelle de la recherche binaire ?\", \n",
    "     [\"O(log n)\", \"O(n)\", \"O(n log n)\", \"O(n^2)\"], \n",
    "     \"O(log n)\"),\n",
    "    (\"Quel est l'algorithme de tri adapté aux listes presque triées ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri par insertion\"),\n",
    "    (\"Quel est l'algorithme de tri adapté aux listes de petite taille ?\", \n",
    "     [\"Tri par insertion\", \"Tri fusion\", \"Tri rapide\", \"Tri à bulles\"], \n",
    "     \"Tri par insertion\"),\n",
    "    (\"Quelle est la complexité temporelle de la recherche séquentielle ?\", \n",
    "     [\"O(n log n)\", \"O(n)\", \"O(log n)\", \"O(n^2)\"], \n",
    "     \"O(n)\"),\n",
    "    (\"Quelle est la complexité spatiale de l'algorithme de tri rapide ?\", \n",
    "     [\"O(n)\", \"O(log n)\", \"O(n^2)\", \"O(n log n)\"], \n",
    "     \"O(log n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe pondéré ?\", \n",
    "     [\"Algorithme de Dijkstra\", \"Algorithme de Bellman-Ford\", \"Algorithme de Floyd-Warshall\", \"Algorithme de Kruskal\"], \n",
    "     \"Algorithme de Dijkstra\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de recherche linéaire ?\", \n",
    "     [\"O(log n)\", \"O(n)\", \"O(n log n)\", \"O(n^2)\"], \n",
    "     \"O(n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour trouver un arbre couvrant minimal dans un graphe pondéré ?\", \n",
    "     [\"Algorithme de Prim\", \"Algorithme de Kruskal\", \"Algorithme de Dijkstra\", \"Algorithme de Bellman-Ford\"], \n",
    "     \"Algorithme de Prim\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de Kruskal ?\", \n",
    "     [\"O(n log n)\", \"O(n)\", \"O(log n)\", \"O(n^2)\"], \n",
    "     \"O(n log n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour trouver le plus court chemin dans un graphe avec des arêtes de poids négatif ?\", \n",
    "     [\"Algorithme de Dijkstra\", \"Algorithme de Bellman-Ford\", \"Algorithme de Floyd-Warshall\", \"Algorithme de Kruskal\"], \n",
    "     \"Algorithme de Bellman-Ford\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de Floyd-Warshall ?\", \n",
    "     [\"O(n^3)\", \"O(n^2)\", \"O(n log n)\", \"O(n)\"], \n",
    "     \"O(n^3)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour effectuer une recherche en profondeur dans un graphe ?\", \n",
    "     [\"Parcours en profondeur d'abord (DFS)\", \"Parcours en largeur d'abord (BFS)\", \"Algorithme de Kruskal\", \"Algorithme de Prim\"], \n",
    "     \"Parcours en profondeur d'abord (DFS)\"),\n",
    "    (\"Quelle est la complexité temporelle de l'algorithme de recherche en profondeur ?\", \n",
    "     [\"O(n)\", \"O(log n)\", \"O(n^2)\", \"O(n log n)\"], \n",
    "     \"O(n)\"),\n",
    "    (\"Quel est l'algorithme utilisé pour effectuer une recherche en largeur dans un graphe ?\", \n",
    "     [\"Parcours en largeur d'abord (BFS)\", \"Parcours en profondeur d'abord (DFS)\", \"Algorithme de Kruskal\", \"Algorithme de Prim\"], \n",
    "     \"Parcours en largeur d'abord (BFS)\")\n",
    "]\n",
    "\n",
    "def preprocess_data(data):\n",
    "    processed_data = []\n",
    "    for question, options, answer in data:\n",
    "        options_one_hot = [tf.keras.utils.to_categorical(i, num_classes=len(options)) for i in range(len(options))]\n",
    "        answer_index = options.index(answer)\n",
    "        answer_one_hot = tf.keras.utils.to_categorical(answer_index, num_classes=len(options))\n",
    "        processed_data.append((question, options_one_hot, answer_one_hot))\n",
    "    return processed_data\n",
    "\n",
    "processed_data = preprocess_data(data)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(None, len(processed_data[0][1]))))\n",
    "model.add(Dense(len(processed_data[0][1]), activation='softmax')) \n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01)) \n",
    "\n",
    "x_train = np.array([options for _, options, _ in processed_data])\n",
    "y_train = np.array([answer for _, _, answer in processed_data])\n",
    "model.fit(x_train, y_train, batch_size=256, epochs=4)\n",
    "\n",
    "def generate_question(model, generated_questions):\n",
    "    # Générer une question aléatoire non utilisée\n",
    "    unused_questions = [idx for idx in range(len(data)) if idx not in generated_questions]\n",
    "    if not unused_questions:  # Vérifier si la liste est vide\n",
    "        return None  # Retourner None pour indiquer que toutes les questions ont été utilisées\n",
    "    \n",
    "    question_idx = random.choice(unused_questions)\n",
    "    generated_questions.add(question_idx)\n",
    "    question_text, options, correct_answer = processed_data[question_idx]\n",
    "    \n",
    "    predicted_answer = model.predict(np.array([options]))\n",
    "    predicted_answer_index = np.argmax(predicted_answer)\n",
    "    predicted_answer_text = options[predicted_answer_index]\n",
    "    \n",
    "    options_text = [option for option in data[question_idx][1]]\n",
    "    correct_answer_text = data[question_idx][2]\n",
    "    \n",
    "    return {\"question\": question_text, \"options\": options_text, \"correct_answer\": correct_answer_text}\n",
    "\n",
    "generated_questions = set() \n",
    "for _ in range(10):\n",
    "    question = generate_question(model, generated_questions)\n",
    "    if question:  # Vérifier si la question est None\n",
    "        print(question)\n",
    "    else:\n",
    "        print(\"Toutes les questions ont été utilisées.\")\n",
    "        break  # Arrêter la génération de questions\n",
    "\n",
    "\n",
    "with open(\"BANK_QUESTIONS_7.xml\", \"w\") as f:\n",
    "    f.write(\"<quiz>\\n\")\n",
    "    generated_questions_copy = generated_questions.copy()  # Faire une copie de l'ensemble\n",
    "    for i, question_idx in enumerate(generated_questions_copy, start=1):\n",
    "        qcm = generate_question(model, generated_questions)  # Utiliser le modèle pour générer une question\n",
    "        if qcm is None:  # Vérifier si aucune question n'a été générée\n",
    "            print(\"Toutes les questions ont été utilisées.\")\n",
    "            break  # Sortir de la boucle\n",
    "        f.write(f\"  <!-- question: {i} -->\\n\")\n",
    "        f.write(f\"  <question type=\\\"multichoice\\\">\\n\")\n",
    "        f.write(f\"    <name>\\n\")\n",
    "        f.write(f\"      <text>Question {i}</text>\\n\")\n",
    "        f.write(f\"    </name>\\n\")\n",
    "        f.write(f\"    <questiontext format=\\\"html\\\">\\n\")\n",
    "        f.write(f\"      <text><![CDATA[<pre>{qcm['question']}</pre>]]></text>\\n\")\n",
    "        f.write(f\"    </questiontext>\\n\")\n",
    "        f.write(f\"    <generalfeedback format=\\\"html\\\">\\n\")\n",
    "        f.write(f\"      <text><![CDATA[<p>none</p>]]></text>\\n\")\n",
    "        f.write(f\"    </generalfeedback>\\n\")\n",
    "        f.write(f\"    <defaultgrade>1.0000000</defaultgrade>\\n\")\n",
    "        f.write(f\"    <penalty>0.3333333</penalty>\\n\")\n",
    "        f.write(f\"    <hidden>0</hidden>\\n\")\n",
    "        f.write(f\"    <single>true</single>\\n\")\n",
    "        f.write(f\"    <shuffleanswers>true</shuffleanswers>\\n\")\n",
    "        f.write(f\"    <answernumbering>abc</answernumbering>\\n\")\n",
    "        for j, option in enumerate(qcm['options'], start=1):\n",
    "            is_correct = (option == qcm['correct_answer'])  # Vérifier si l'option est la bonne réponse\n",
    "            fraction = '100' if is_correct else '0'\n",
    "            f.write(f\"    <answer fraction=\\\"{fraction}\\\" format=\\\"html\\\">\\n\")\n",
    "            f.write(f\"      <text><![CDATA[{j}. {option}]]></text>\\n\")\n",
    "            f.write(f\"      <feedback format=\\\"html\\\">\\n\")\n",
    "            f.write(f\"        <text><![CDATA[<p>none</p>]]></text>\\n\")\n",
    "            f.write(f\"      </feedback>\\n\")\n",
    "            f.write(f\"    </answer>\\n\")\n",
    "        f.write(f\"  </question>\\n\")\n",
    "    f.write(\"</quiz>\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.3965\n",
      "Epoch 2/4\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.2577\n",
      "Epoch 3/4\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2702\n",
      "Epoch 4/4\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.2912\n",
      "1/1 [==============================] - 0s 451ms/step\n",
      "{'question': \"Quel est l'algorithme de tri adaptÃ© aux listes de petite taille ?\", 'options': ['Tri par insertion', 'Tri fusion', 'Tri rapide', 'Tri Ã\\xa0 bulles'], 'correct_answer': 'Tri par insertion'}\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "{'question': \"RÃ‰PÃ‰TER <traitement> JUSQU'Ã€ <condition> est une ______?\", 'options': ['Boucle positive', 'Les deux', 'Boucle nÃ©gative', 'Aucun'], 'correct_answer': 'Boucle positive'}\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "{'question': \"Combien de comparaisons effectuera l'algorithme de tri par insertion si on l'applique Ã\\xa0 un tableau de n Ã©lÃ©ments dÃ©jÃ\\xa0 triÃ© ?\", 'options': ['(nÂ²+n)/2', 'n-1', 'n.(n+1)', 'log(n)'], 'correct_answer': 'n-1'}\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "{'question': 'Quelle est la diffÃ©rence entre un organigramme et un pseudocode?', 'options': ['Un organigramme est schÃ©matique tandis que le pseudocode est Ã©crit dans un langage de programmation (par exemple, Pascal ou Java)', 'Un organigramme est textuel mais le pseudocode est schÃ©matique', \"Un organigramme est une description schÃ©matique d'un algorithme, tandis que le pseudocode est une description textuelle d'un algorithme.\", 'Un organigramme et un pseudocode sont pareils'], 'correct_answer': \"Un organigramme est une description schÃ©matique d'un algorithme, tandis que le pseudocode est une description textuelle d'un algorithme.\"}\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'question': \"Quel est l'algorithme de recherche le plus efficace ?\", 'options': ['Recherche sÃ©quentielle', 'Recherche binaire', 'Recherche exponentielle', 'Recherche linÃ©aire'], 'correct_answer': 'Recherche binaire'}\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "{'question': \"Quel est l'algorithme utilisÃ© pour trouver le plus court chemin dans un graphe avec des arÃªtes de poids nÃ©gatif ?\", 'options': ['Algorithme de Dijkstra', 'Algorithme de Bellman-Ford', 'Algorithme de Floyd-Warshall', 'Algorithme de Kruskal'], 'correct_answer': 'Algorithme de Bellman-Ford'}\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "{'question': \"Quelle est la complexitÃ© temporelle de l'algorithme de recherche linÃ©aire ?\", 'options': ['O(log n)', 'O(n)', 'O(n log n)', 'O(n^2)'], 'correct_answer': 'O(n)'}\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "{'question': \"Quelle est la complexitÃ© temporelle de l'algorithme de Kruskal ?\", 'options': ['O(n log n)', 'O(n)', 'O(log n)', 'O(n^2)'], 'correct_answer': 'O(n log n)'}\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "{'question': \"Quelle est la complexitÃ© temporelle de l'algorithme de Floyd-Warshall ?\", 'options': ['O(n^3)', 'O(n^2)', 'O(n log n)', 'O(n)'], 'correct_answer': 'O(n^3)'}\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "{'question': 'Pour rÃ©pÃ©ter une tÃ¢che, nous utilisons une ____?', 'options': ['EntrÃ©e', 'Condition', 'Boucle', 'Sortie'], 'correct_answer': 'Boucle'}\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    }
   ],
   "source": [
    "############### Final with data in my .JSON file #############\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Charger les données depuis le fichier JSON\n",
    "with open(\"data.json\", \"r\") as json_file:\n",
    "    data = json.load(json_file)[\"questions\"]\n",
    "\n",
    "# Prétraitement des données\n",
    "def preprocess_data(data):\n",
    "    processed_data = []\n",
    "    for question_data in data:\n",
    "        question = question_data[\"question\"]\n",
    "        options = question_data[\"options\"]\n",
    "        answer = question_data[\"answer\"]\n",
    "        options_one_hot = [tf.keras.utils.to_categorical(i, num_classes=len(options)) for i in range(len(options))]\n",
    "        answer_index = options.index(answer)\n",
    "        answer_one_hot = tf.keras.utils.to_categorical(answer_index, num_classes=len(options))\n",
    "        processed_data.append((question, options_one_hot, answer_one_hot))\n",
    "    return processed_data\n",
    "\n",
    "processed_data = preprocess_data(data)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(None, len(processed_data[0][1])))) \n",
    "model.add(Dense(len(processed_data[0][1]), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01))\n",
    "\n",
    "x_train = np.array([options for _, options, _ in processed_data])\n",
    "y_train = np.array([answer for _, _, answer in processed_data])\n",
    "model.fit(x_train, y_train, batch_size=256, epochs=4)\n",
    "\n",
    "def generate_question(model, generated_questions):\n",
    "    unused_questions = [idx for idx in range(len(data)) if idx not in generated_questions]\n",
    "    if not unused_questions:  \n",
    "        return None  \n",
    "    \n",
    "    question_idx = random.choice(unused_questions)\n",
    "    generated_questions.add(question_idx)\n",
    "    question_text, options, correct_answer = processed_data[question_idx]\n",
    "    \n",
    "    predicted_answer = model.predict(np.array([options]))\n",
    "    predicted_answer_index = np.argmax(predicted_answer)\n",
    "    predicted_answer_text = options[predicted_answer_index]\n",
    "    \n",
    "    options_text = [option for option in data[question_idx][\"options\"]]\n",
    "    correct_answer_text = data[question_idx][\"answer\"]\n",
    "    \n",
    "    return {\"question\": question_text, \"options\": options_text, \"correct_answer\": correct_answer_text}\n",
    "\n",
    "generated_questions = set()\n",
    "for _ in range(10):\n",
    "    question = generate_question(model, generated_questions)\n",
    "    if question: \n",
    "        print(question)\n",
    "    else:\n",
    "        print(\"Toutes les questions ont été utilisées.\")\n",
    "        break  \n",
    "\n",
    "\n",
    "with open(\"BANK_QUESTIONS_8.xml\", \"w\") as f:\n",
    "    f.write(\"<quiz>\\n\")\n",
    "    generated_questions_copy = generated_questions.copy() \n",
    "    for i, question_idx in enumerate(generated_questions_copy, start=1):\n",
    "        qcm = generate_question(model, generated_questions) \n",
    "        if qcm is None:  # Vérifier si aucune question n'a été générée\n",
    "            print(\"Toutes les questions ont été utilisées.\")\n",
    "            break  # Sortir de la boucle\n",
    "        f.write(f\"  <!-- question: {i} -->\\n\")\n",
    "        f.write(f\"  <question type=\\\"multichoice\\\">\\n\")\n",
    "        f.write(f\"    <name>\\n\")\n",
    "        f.write(f\"      <text>Question {i}</text>\\n\")\n",
    "        f.write(f\"    </name>\\n\")\n",
    "        f.write(f\"    <questiontext format=\\\"html\\\">\\n\")\n",
    "        f.write(f\"      <text><![CDATA[<pre>{qcm['question']}</pre>]]></text>\\n\")\n",
    "        f.write(f\"    </questiontext>\\n\")\n",
    "        f.write(f\"    <generalfeedback format=\\\"html\\\">\\n\")\n",
    "        f.write(f\"      <text><![CDATA[<p>none</p>]]></text>\\n\")\n",
    "        f.write(f\"    </generalfeedback>\\n\")\n",
    "        f.write(f\"    <defaultgrade>1.0000000</defaultgrade>\\n\")\n",
    "        f.write(f\"    <penalty>0.3333333</penalty>\\n\")\n",
    "        f.write(f\"    <hidden>0</hidden>\\n\")\n",
    "        f.write(f\"    <single>true</single>\\n\")\n",
    "        f.write(f\"    <shuffleanswers>true</shuffleanswers>\\n\")\n",
    "        f.write(f\"    <answernumbering>abc</answernumbering>\\n\")\n",
    "        for j, option in enumerate(qcm['options'], start=1):\n",
    "            is_correct = (option == qcm['correct_answer'])  # Vérifier si l'option est la bonne réponse\n",
    "            fraction = '100' if is_correct else '0'\n",
    "            f.write(f\"    <answer fraction=\\\"{fraction}\\\" format=\\\"html\\\">\\n\")\n",
    "            f.write(f\"      <text><![CDATA[{j}. {option}]]></text>\\n\")\n",
    "            f.write(f\"      <feedback format=\\\"html\\\">\\n\")\n",
    "            f.write(f\"        <text><![CDATA[<p>none</p>]]></text>\\n\")\n",
    "            f.write(f\"      </feedback>\\n\")\n",
    "            f.write(f\"    </answer>\\n\")\n",
    "        f.write(f\"  </question>\\n\")\n",
    "    f.write(\"</quiz>\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train before: (37, 4, 137)\n",
      "Shape of x_train after: (37, 4, 81)\n",
      "Epoch 1/4\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.4302\n",
      "Epoch 2/4\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.2805\n",
      "Epoch 3/4\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.2686\n",
      "Epoch 4/4\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0818\n",
      "1/1 [==============================] - 1s 633ms/step\n",
      "{'question': 'Un arbre binaire est :', 'options': ['un algorithme de tri', 'un algorithme de parcourt de graphe', 'un algorithme de recherche', 'Aucune de ces propositions'], 'correct_answer': 'Aucune de ces propositions'}\n",
      "1/1 [==============================] - 0s 471ms/step\n",
      "{'question': 'Quelle est la complexitÃ© temporelle de la recherche sÃ©quentielle ?', 'options': ['O(n log n)', 'O(n)', 'O(log n)', 'O(n^2)'], 'correct_answer': 'O(n)'}\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "{'question': \"Dans un organigramme, une instruction d'entrÃ©e ou de sortie est reprÃ©sentÃ©e par _____?\", 'options': ['Un losange', 'Un rectangle', 'Un parallÃ©logramme', 'Un cercle'], 'correct_answer': 'Un parallÃ©logramme'}\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "{'question': \"Qu'est-ce qu'un organigramme?\", 'options': ['Un moyen de concevoir un algorithme basÃ© sur du texte', 'Un langage de programmation spÃ©cifique', \" Un diagramme qui reprÃ©sente un ensemble d'instructions\", \"Un schÃ©ma d'instructions\"], 'correct_answer': \" Un diagramme qui reprÃ©sente un ensemble d'instructions\"}\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "{'question': \"Quel est l'algorithme utilisÃ© pour trouver le plus court chemin dans un graphe pondÃ©rÃ© ?\", 'options': ['Algorithme de Dijkstra', 'Algorithme de Bellman-Ford', 'Algorithme de Floyd-Warshall', 'Algorithme de Kruskal'], 'correct_answer': 'Algorithme de Dijkstra'}\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "{'question': \"Quel est l'avantage du tri Ã\\xa0 bulles par rapport au tri par insertion ?\", 'options': ['il ne possÃ¨de aucun de ces deux avantages', \"il effectue moins d'Ã©changes en moyenne\", 'il effectue moins de comparaisons en moyenne', 'Aucun'], 'correct_answer': 'il ne possÃ¨de aucun de ces deux avantages'}\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "{'question': \"Combien de comparaisons effectuera l'algorithme de tri Ã\\xa0 bulles si on l'applique Ã\\xa0 un tableau de 20 Ã©lÃ©ments dÃ©jÃ\\xa0 triÃ© ?\", 'options': ['0', '400', '190', '19'], 'correct_answer': '19'}\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "{'question': \"Quelles sont les trois constructions d'algorithme?\", 'options': ['EntrÃ©e, Sortie, Processus', 'SÃ©quence, SÃ©lection, RÃ©pÃ©tition', 'EntrÃ©e / Sortie, DÃ©cision, RÃ©pÃ©tition', 'Boucle, EntrÃ©e/Sortie, Processus'], 'correct_answer': 'SÃ©quence, SÃ©lection, RÃ©pÃ©tition'}\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "{'question': 'Dans un organigramme, un calcul (processus) est reprÃ©sentÃ© par _____?', 'options': ['Un losange', 'Un rectangle', 'Un parallÃ©logramme', 'Un cercle'], 'correct_answer': 'Un rectangle'}\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "{'question': \"Quel est l'algorithme de recherche le plus efficace ?\", 'options': ['Recherche sÃ©quentielle', 'Recherche binaire', 'Recherche exponentielle', 'Recherche linÃ©aire'], 'correct_answer': 'Recherche binaire'}\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    }
   ],
   "source": [
    "################# Final : Approche Supervisé Encodage - One -Hot aussi de la question pas seulement des propositions et du label ########################\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "with open(\"data.json\", \"r\") as json_file:\n",
    "    data = json.load(json_file)[\"questions\"]\n",
    "\n",
    "def preprocess_data(data):\n",
    "    processed_data = []\n",
    "    vocab = set()  # Créer un ensemble pour stocker toutes les lettres ou mots uniques\n",
    "    \n",
    "    # Parcourir les données pour construire le vocabulaire\n",
    "    for question_data in data:\n",
    "        question = question_data[\"question\"]\n",
    "        options = question_data[\"options\"]\n",
    "        answer = question_data[\"answer\"]\n",
    "        vocab.update(question)  # Ajouter toutes les lettres ou mots de la question au vocabulaire\n",
    "        for option in options:\n",
    "            vocab.update(option)  # Ajouter toutes les lettres ou mots des options au vocabulaire\n",
    "    \n",
    "    # Convertir le vocabulaire en une liste triée\n",
    "    vocab = sorted(vocab)\n",
    "    \n",
    "    # Créer un dictionnaire pour mapper chaque caractère ou mot à un index\n",
    "    vocab_mapping = {char: idx for idx, char in enumerate(vocab)}\n",
    "    \n",
    "    # Encoder les données\n",
    "    for question_data in data:\n",
    "        question = question_data[\"question\"]\n",
    "        options = question_data[\"options\"]\n",
    "        answer = question_data[\"answer\"]\n",
    "        \n",
    "        # Encoder la question avec one-hot encoding\n",
    "        question_one_hot = [vocab_mapping[char] for char in question]\n",
    "        question_one_hot = tf.keras.utils.to_categorical(question_one_hot, num_classes=len(vocab))\n",
    "        \n",
    "        # Padding des options pour avoir la même longueur\n",
    "        max_option_length = max(len(option) for option in options)\n",
    "        padded_options = [[vocab_mapping[char] for char in option] + [0] * (max_option_length - len(option)) for option in options]\n",
    "        options_one_hot = np.array(padded_options)  # Convertir en tableau NumPy\n",
    "        \n",
    "        # Encoder la réponse avec one-hot encoding\n",
    "        answer_index = options.index(answer)\n",
    "        answer_one_hot = tf.keras.utils.to_categorical(answer_index, num_classes=len(options))\n",
    "        \n",
    "        processed_data.append((question_one_hot, options_one_hot, answer_one_hot))\n",
    "    \n",
    "    return processed_data, vocab_mapping\n",
    "\n",
    "processed_data, vocab_mapping = preprocess_data(data)\n",
    "\n",
    "# Modifier le modèle pour traiter les données encodées avec one-hot encoding\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(128, input_shape=(None, len(vocab_mapping))))  # Utiliser la longueur du vocabulaire comme entrée\n",
    "model.add(tf.keras.layers.Dense(len(processed_data[0][1]), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.01))\n",
    "\n",
    "# Entraînement du modèle\n",
    "max_option_length = max(options.shape[1] for _, options, _ in processed_data)\n",
    "x_train = np.array([np.pad(options, ((0, 0), (0, max_option_length - options.shape[1])), 'constant', constant_values=0) for _, options, _ in processed_data])\n",
    "# Vérifier les dimensions des données d'entrée\n",
    "print(\"Shape of x_train before:\", x_train.shape)\n",
    "\n",
    "# Supprimer la dimension inutile\n",
    "x_train = x_train[:, :, :81]  # Prendre uniquement les 81 premières colonnes\n",
    "print(\"Shape of x_train after:\", x_train.shape)\n",
    "\n",
    "y_train = np.array([answer for _, _, answer in processed_data])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=256, epochs=4)\n",
    "\n",
    "\n",
    "# Fonction pour générer une question\n",
    "def generate_question(model, generated_questions):\n",
    "    unused_questions = [idx for idx in range(len(data)) if idx not in generated_questions]\n",
    "    if not unused_questions:\n",
    "        return None\n",
    "\n",
    "    question_idx = random.choice(unused_questions)\n",
    "    generated_questions.add(question_idx)\n",
    "    question_one_hot, options, correct_answer = processed_data[question_idx]\n",
    "\n",
    "    predicted_answer = model.predict(np.array([question_one_hot]))  # Utiliser la question encodée avec one-hot encoding\n",
    "    predicted_answer_index = np.argmax(predicted_answer)\n",
    "    predicted_answer_text = options[predicted_answer_index]\n",
    "\n",
    "    options_text = [option for option in data[question_idx][\"options\"]]\n",
    "    correct_answer_text = data[question_idx][\"answer\"]\n",
    "\n",
    "    return {\"question\": data[question_idx][\"question\"], \"options\": options_text, \"correct_answer\": correct_answer_text}\n",
    "\n",
    "# Générerons des questions\n",
    "generated_questions = set()\n",
    "for _ in range(10):\n",
    "    question = generate_question(model, generated_questions)\n",
    "    if question:\n",
    "        print(question)\n",
    "    else:\n",
    "        print(\"Toutes les questions ont été utilisées.\")\n",
    "        break\n",
    "\n",
    "# Put dans un fichier XML\n",
    "with open(\"BANK_QUESTIONS_10_FIN.xml\", \"w\") as f:\n",
    "    f.write(\"<quiz>\\n\")\n",
    "    generated_questions_copy = generated_questions.copy()\n",
    "    for i, question_idx in enumerate(generated_questions_copy, start=1):\n",
    "        qcm = generate_question(model, generated_questions)\n",
    "        if qcm is None:  # Vérifier si aucune question n'a été générée\n",
    "            print(\"Toutes les questions ont été utilisées.\")\n",
    "            break  # Sortir de la boucle\n",
    "        f.write(f\"  <!-- question: {i} -->\\n\")\n",
    "        f.write(f\"  <question type=\\\"multichoice\\\">\\n\")\n",
    "        f.write(f\"    <name>\\n\")\n",
    "        f.write(f\"      <text>Question {i}</text>\\n\")\n",
    "        f.write(f\"    </name>\\n\")\n",
    "        f.write(f\"    <questiontext format=\\\"html\\\">\\n\")\n",
    "        f.write(f\"      <text><![CDATA[<pre>{qcm['question']}</pre>]]></text>\\n\")\n",
    "        f.write(f\"    </questiontext>\\n\")\n",
    "        f.write(f\"    <generalfeedback format=\\\"html\\\">\\n\")\n",
    "        f.write(f\"      <text><![CDATA[<p>none</p>]]></text>\\n\")\n",
    "        f.write(f\"    </generalfeedback>\\n\")\n",
    "        f.write(f\"    <defaultgrade>1.0000000</defaultgrade>\\n\")\n",
    "        f.write(f\"    <penalty>0.3333333</penalty>\\n\")\n",
    "        f.write(f\"    <hidden>0</hidden>\\n\")\n",
    "        f.write(f\"    <single>true</single>\\n\")\n",
    "        f.write(f\"    <shuffleanswers>true</shuffleanswers>\\n\")\n",
    "        f.write(f\"    <answernumbering>abc</answernumbering>\\n\")\n",
    "        for j, option in enumerate(qcm['options'], start=1):\n",
    "            is_correct = (option == qcm['correct_answer'])  # je verifie si l'option est la bonne réponse\n",
    "            fraction = '100' if is_correct else '0'\n",
    "            f.write(f\"    <answer fraction=\\\"{fraction}\\\" format=\\\"html\\\">\\n\")\n",
    "            f.write(f\"      <text><![CDATA[{j}. {option}]]></text>\\n\")\n",
    "            f.write(f\"      <feedback format=\\\"html\\\">\\n\")\n",
    "            f.write(f\"        <text><![CDATA[<p>none</p>]]></text>\\n\")\n",
    "            f.write(f\"      </feedback>\\n\")\n",
    "            f.write(f\"    </answer>\\n\")\n",
    "        f.write(f\"  </question>\\n\")\n",
    "    f.write(\"</quiz>\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train before: (37, 4, 137)\n",
      "Shape of x_train after: (37, 4, 81)\n",
      "Epoch 1/4\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.3936\n",
      "Epoch 2/4\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2180\n",
      "Epoch 3/4\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.5195\n",
      "Epoch 4/4\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.9559\n",
      "1/1 [==============================] - 0s 445ms/step\n",
      "1/1 [==============================] - 0s 459ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "############ Test Sans Encodage du Marks ##########################################\n",
    "############################ Question One Marks ############\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "# Charger les données depuis le fichier JSON\n",
    "with open(\"data_marks.json\", \"r\") as json_file:\n",
    "    data = json.load(json_file)[\"questions\"]\n",
    "\n",
    "def preprocess_data(data):\n",
    "    processed_data = []\n",
    "    vocab = set()  # Créer un ensemble pour stocker toutes les lettres ou mots uniques\n",
    "    \n",
    "    # Parcourir les données pour construire le vocabulaire\n",
    "    for question_data in data:\n",
    "        question = question_data[\"question\"]\n",
    "        options = question_data[\"options\"]\n",
    "        answer = question_data[\"answer\"]\n",
    "        vocab.update(question)  # Ajouter toutes les lettres ou mots de la question au vocabulaire\n",
    "        for option in options:\n",
    "            vocab.update(option)  # Ajouter toutes les lettres ou mots des options au vocabulaire\n",
    "    \n",
    "    # Convertir le vocabulaire en une liste triée\n",
    "    vocab = sorted(vocab)\n",
    "    \n",
    "    # Créer un dictionnaire pour mapper chaque caractère ou mot à un index\n",
    "    vocab_mapping = {char: idx for idx, char in enumerate(vocab)}\n",
    "    \n",
    "    # Encoder les données\n",
    "    for question_data in data:\n",
    "        question = question_data[\"question\"]\n",
    "        options = question_data[\"options\"]\n",
    "        answer = question_data[\"answer\"]\n",
    "        \n",
    "        # Encoder la question avec one-hot encoding\n",
    "        question_one_hot = [vocab_mapping[char] for char in question]\n",
    "        question_one_hot = tf.keras.utils.to_categorical(question_one_hot, num_classes=len(vocab))\n",
    "        \n",
    "        # Padding des options pour avoir la même longueur\n",
    "        max_option_length = max(len(option) for option in options)\n",
    "        padded_options = [[vocab_mapping[char] for char in option] + [0] * (max_option_length - len(option)) for option in options]\n",
    "        options_one_hot = np.array(padded_options)  # Convertir en tableau NumPy\n",
    "        \n",
    "        # Encoder la réponse avec one-hot encoding\n",
    "        answer_index = options.index(answer)\n",
    "        answer_one_hot = tf.keras.utils.to_categorical(answer_index, num_classes=len(options))\n",
    "        \n",
    "        processed_data.append((question_one_hot, options_one_hot, answer_one_hot))\n",
    "    \n",
    "    return processed_data, vocab_mapping\n",
    "\n",
    "processed_data, vocab_mapping = preprocess_data(data)\n",
    "\n",
    "# Modifier le modèle pour traiter les données encodées avec one-hot encoding\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(128, input_shape=(None, len(vocab_mapping))))  # Utiliser la longueur du vocabulaire comme entrée\n",
    "model.add(tf.keras.layers.Dense(len(processed_data[0][1]), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.01))\n",
    "\n",
    "# Entraînement du modèle\n",
    "max_option_length = max(options.shape[1] for _, options, _ in processed_data)\n",
    "x_train = np.array([np.pad(options, ((0, 0), (0, max_option_length - options.shape[1])), 'constant', constant_values=0) for _, options, _ in processed_data])\n",
    "# Vérifier les dimensions des données d'entrée\n",
    "print(\"Shape of x_train before:\", x_train.shape)\n",
    "\n",
    "# Supprimer la dimension inutile\n",
    "x_train = x_train[:, :, :81]  # Prendre uniquement les 81 premières colonnes\n",
    "print(\"Shape of x_train after:\", x_train.shape)\n",
    "\n",
    "y_train = np.array([answer for _, _, answer in processed_data])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=256, epochs=4)\n",
    "\n",
    "\n",
    "# Fonction pour générer une question\n",
    "def generate_question(model, generated_questions, marks, max_questions):\n",
    "    unused_questions = [idx for idx in range(len(data)) if idx not in generated_questions and data[idx][\"marks\"] == marks]\n",
    "    if not unused_questions:\n",
    "        return None\n",
    "\n",
    "    if len(unused_questions) > max_questions - len(generated_questions):\n",
    "        unused_questions = random.sample(unused_questions, max_questions - len(generated_questions))\n",
    "\n",
    "    for question_idx in unused_questions:\n",
    "        generated_questions.add(question_idx)\n",
    "        question_one_hot, options, correct_answer = processed_data[question_idx]\n",
    "\n",
    "        predicted_answer = model.predict(np.array([question_one_hot]))  # Utiliser la question encodée avec one-hot encoding\n",
    "        predicted_answer_index = np.argmax(predicted_answer)\n",
    "        predicted_answer_text = options[predicted_answer_index]\n",
    "\n",
    "        options_text = [option for option in data[question_idx][\"options\"]]\n",
    "        correct_answer_text = data[question_idx][\"answer\"]\n",
    "\n",
    "        yield {\"question\": data[question_idx][\"question\"], \"options\": options_text, \"correct_answer\": correct_answer_text, \"marks\": marks}\n",
    "\n",
    "\n",
    "# Générer des questions avec les paramètres spécifiés\n",
    "def generate_questions_to_xml(model, marks, nbre_questions, output_file):\n",
    "    generated_questions = set()\n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.write(\"<quiz>\\n\")\n",
    "        for i, qcm in enumerate(generate_question(model, generated_questions, marks, nbre_questions), start=1):\n",
    "            f.write(f\"  <!-- question: {i} -->\\n\")\n",
    "            f.write(f\"  <question type=\\\"multichoice\\\">\\n\")\n",
    "            f.write(f\"    <name>\\n\")\n",
    "            f.write(f\"      <text>Question {i}</text>\\n\")\n",
    "            f.write(f\"    </name>\\n\")\n",
    "            f.write(f\"    <questiontext format=\\\"html\\\">\\n\")\n",
    "            f.write(f\"      <text><![CDATA[<pre>{qcm['question']}</pre>]]></text>\\n\")\n",
    "            f.write(f\"    </questiontext>\\n\")\n",
    "            f.write(f\"    <generalfeedback format=\\\"html\\\">\\n\")\n",
    "            f.write(f\"      <text><![CDATA[<p>none</p>]]></text>\\n\")\n",
    "            f.write(f\"    </generalfeedback>\\n\")\n",
    "            f.write(f\"    <defaultgrade>{qcm['marks']}.0000000</defaultgrade>\\n\")\n",
    "            f.write(f\"    <penalty>0.3333333</penalty>\\n\")\n",
    "            f.write(f\"    <hidden>0</hidden>\\n\")\n",
    "            f.write(f\"    <single>true</single>\\n\")\n",
    "            f.write(f\"    <shuffleanswers>true</shuffleanswers>\\n\")\n",
    "            f.write(f\"    <answernumbering>abc</answernumbering>\\n\")\n",
    "            for j, option in enumerate(qcm['options'], start=1):\n",
    "                is_correct = (option == qcm['correct_answer'])  # je verifie si l'option est la bonne réponse\n",
    "                fraction = '100' if is_correct else '0'\n",
    "                f.write(f\"    <answer fraction=\\\"{fraction}\\\" format=\\\"html\\\">\\n\")\n",
    "                f.write(f\"      <text><![CDATA[{j}. {option}]]></text>\\n\")\n",
    "                f.write(f\"      <feedback format=\\\"html\\\">\\n\")\n",
    "                f.write(f\"        <text><![CDATA[<p>none</p>]]></text>\\n\")\n",
    "                f.write(f\"      </feedback>\\n\")\n",
    "                f.write(f\"    </answer>\\n\")\n",
    "            f.write(f\"  </question>\\n\")\n",
    "        f.write(\"</quiz>\\n\")\n",
    "\n",
    "# Exemple d'utilisation\n",
    "generate_questions_to_xml(model, marks=1, nbre_questions=3, output_file=\"marks_1.xml\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train before: (37, 4, 137)\n",
      "Shape of x_train after: (37, 4, 81)\n",
      "Epoch 1/4\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.3494\n",
      "Epoch 2/4\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1113\n",
      "Epoch 3/4\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4775\n",
      "Epoch 4/4\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9430\n",
      "1/1 [==============================] - 1s 537ms/step\n",
      "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000025AD2354700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 535ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n"
     ]
    }
   ],
   "source": [
    "############################ Question Two Marks ############\n",
    "\n",
    "\n",
    "############ Test ##########################################\n",
    "############################ Question One Marks ############\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "# Charger les données depuis le fichier JSON\n",
    "with open(\"data_marks.json\", \"r\") as json_file:\n",
    "    data = json.load(json_file)[\"questions\"]\n",
    "\n",
    "def preprocess_data(data):\n",
    "    processed_data = []\n",
    "    vocab = set()  # Créer un ensemble pour stocker toutes les lettres ou mots uniques\n",
    "    \n",
    "    # Parcourir les données pour construire le vocabulaire\n",
    "    for question_data in data:\n",
    "        question = question_data[\"question\"]\n",
    "        options = question_data[\"options\"]\n",
    "        answer = question_data[\"answer\"]\n",
    "        vocab.update(question)  # Ajouter toutes les lettres ou mots de la question au vocabulaire\n",
    "        for option in options:\n",
    "            vocab.update(option)  # Ajouter toutes les lettres ou mots des options au vocabulaire\n",
    "    \n",
    "    # Convertir le vocabulaire en une liste triée\n",
    "    vocab = sorted(vocab)\n",
    "    \n",
    "    # Créer un dictionnaire pour mapper chaque caractère ou mot à un index\n",
    "    vocab_mapping = {char: idx for idx, char in enumerate(vocab)}\n",
    "    \n",
    "    # Encoder les données\n",
    "    for question_data in data:\n",
    "        question = question_data[\"question\"]\n",
    "        options = question_data[\"options\"]\n",
    "        answer = question_data[\"answer\"]\n",
    "        \n",
    "        # Encoder la question avec one-hot encoding\n",
    "        question_one_hot = [vocab_mapping[char] for char in question]\n",
    "        question_one_hot = tf.keras.utils.to_categorical(question_one_hot, num_classes=len(vocab))\n",
    "        \n",
    "        # Padding des options pour avoir la même longueur\n",
    "        max_option_length = max(len(option) for option in options)\n",
    "        padded_options = [[vocab_mapping[char] for char in option] + [0] * (max_option_length - len(option)) for option in options]\n",
    "        options_one_hot = np.array(padded_options)  # Convertir en tableau NumPy\n",
    "        \n",
    "        # Encoder la réponse avec one-hot encoding\n",
    "        answer_index = options.index(answer)\n",
    "        answer_one_hot = tf.keras.utils.to_categorical(answer_index, num_classes=len(options))\n",
    "        \n",
    "        processed_data.append((question_one_hot, options_one_hot, answer_one_hot))\n",
    "    \n",
    "    return processed_data, vocab_mapping\n",
    "\n",
    "processed_data, vocab_mapping = preprocess_data(data)\n",
    "\n",
    "# Modifier le modèle pour traiter les données encodées avec one-hot encoding\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(128, input_shape=(None, len(vocab_mapping))))  # Utiliser la longueur du vocabulaire comme entrée\n",
    "model.add(tf.keras.layers.Dense(len(processed_data[0][1]), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.01))\n",
    "\n",
    "# Entraînement du modèle\n",
    "max_option_length = max(options.shape[1] for _, options, _ in processed_data)\n",
    "x_train = np.array([np.pad(options, ((0, 0), (0, max_option_length - options.shape[1])), 'constant', constant_values=0) for _, options, _ in processed_data])\n",
    "# Vérifier les dimensions des données d'entrée\n",
    "print(\"Shape of x_train before:\", x_train.shape)\n",
    "\n",
    "# Supprimer la dimension inutile\n",
    "x_train = x_train[:, :, :81]  # Prendre uniquement les 81 premières colonnes\n",
    "print(\"Shape of x_train after:\", x_train.shape)\n",
    "\n",
    "y_train = np.array([answer for _, _, answer in processed_data])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=256, epochs=4)\n",
    "\n",
    "\n",
    "# Fonction pour générer une question\n",
    "def generate_question(model, generated_questions, marks, max_questions):\n",
    "    unused_questions = [idx for idx in range(len(data)) if idx not in generated_questions and data[idx][\"marks\"] == marks]\n",
    "    if not unused_questions:\n",
    "        return None\n",
    "\n",
    "    if len(unused_questions) > max_questions - len(generated_questions):\n",
    "        unused_questions = random.sample(unused_questions, max_questions - len(generated_questions))\n",
    "\n",
    "    for question_idx in unused_questions:\n",
    "        generated_questions.add(question_idx)\n",
    "        question_one_hot, options, correct_answer = processed_data[question_idx]\n",
    "\n",
    "        predicted_answer = model.predict(np.array([question_one_hot]))  # Utiliser la question encodée avec one-hot encoding\n",
    "        predicted_answer_index = np.argmax(predicted_answer)\n",
    "        predicted_answer_text = options[predicted_answer_index]\n",
    "\n",
    "        options_text = [option for option in data[question_idx][\"options\"]]\n",
    "        correct_answer_text = data[question_idx][\"answer\"]\n",
    "\n",
    "        yield {\"question\": data[question_idx][\"question\"], \"options\": options_text, \"correct_answer\": correct_answer_text, \"marks\": marks}\n",
    "\n",
    "\n",
    "# Générer des questions avec les paramètres spécifiés\n",
    "def generate_questions_to_xml(model, marks, nbre_questions, output_file):\n",
    "    generated_questions = set()\n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.write(\"<quiz>\\n\")\n",
    "        for i, qcm in enumerate(generate_question(model, generated_questions, marks, nbre_questions), start=1):\n",
    "            f.write(f\"  <!-- question: {i} -->\\n\")\n",
    "            f.write(f\"  <question type=\\\"multichoice\\\">\\n\")\n",
    "            f.write(f\"    <name>\\n\")\n",
    "            f.write(f\"      <text>Question {i}</text>\\n\")\n",
    "            f.write(f\"    </name>\\n\")\n",
    "            f.write(f\"    <questiontext format=\\\"html\\\">\\n\")\n",
    "            f.write(f\"      <text><![CDATA[<pre>{qcm['question']}</pre>]]></text>\\n\")\n",
    "            f.write(f\"    </questiontext>\\n\")\n",
    "            f.write(f\"    <generalfeedback format=\\\"html\\\">\\n\")\n",
    "            f.write(f\"      <text><![CDATA[<p>none</p>]]></text>\\n\")\n",
    "            f.write(f\"    </generalfeedback>\\n\")\n",
    "            f.write(f\"    <defaultgrade>{qcm['marks']}.0000000</defaultgrade>\\n\")\n",
    "            f.write(f\"    <penalty>0.3333333</penalty>\\n\")\n",
    "            f.write(f\"    <hidden>0</hidden>\\n\")\n",
    "            f.write(f\"    <single>true</single>\\n\")\n",
    "            f.write(f\"    <shuffleanswers>true</shuffleanswers>\\n\")\n",
    "            f.write(f\"    <answernumbering>abc</answernumbering>\\n\")\n",
    "            for j, option in enumerate(qcm['options'], start=1):\n",
    "                is_correct = (option == qcm['correct_answer'])  # je verifie si l'option est la bonne réponse\n",
    "                fraction = '100' if is_correct else '0'\n",
    "                f.write(f\"    <answer fraction=\\\"{fraction}\\\" format=\\\"html\\\">\\n\")\n",
    "                f.write(f\"      <text><![CDATA[{j}. {option}]]></text>\\n\")\n",
    "                f.write(f\"      <feedback format=\\\"html\\\">\\n\")\n",
    "                f.write(f\"        <text><![CDATA[<p>none</p>]]></text>\\n\")\n",
    "                f.write(f\"      </feedback>\\n\")\n",
    "                f.write(f\"    </answer>\\n\")\n",
    "            f.write(f\"  </question>\\n\")\n",
    "        f.write(\"</quiz>\\n\")\n",
    "\n",
    "# Exemple d'utilisation\n",
    "generate_questions_to_xml(model, marks=2, nbre_questions=3, output_file=\"marks_2.xml\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train before: (37, 4, 137)\n",
      "Shape of x_train after: (37, 4, 81)\n",
      "Epoch 1/4\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.3485\n",
      "Epoch 2/4\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.4009\n",
      "Epoch 3/4\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.1216\n",
      "Epoch 4/4\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.9667\n",
      "WARNING:tensorflow:6 out of the last 16 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000025ACCBF5240> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 525ms/step\n",
      "1/1 [==============================] - 1s 536ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "############################ Question Three Marks ############\n",
    "\n",
    "############ Test ##########################################\n",
    "############################ Question One Marks ############\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "# Charger les données depuis le fichier JSON\n",
    "with open(\"data_marks.json\", \"r\") as json_file:\n",
    "    data = json.load(json_file)[\"questions\"]\n",
    "\n",
    "def preprocess_data(data):\n",
    "    processed_data = []\n",
    "    vocab = set()  # Créer un ensemble pour stocker toutes les lettres ou mots uniques\n",
    "    \n",
    "    # Parcourir les données pour construire le vocabulaire\n",
    "    for question_data in data:\n",
    "        question = question_data[\"question\"]\n",
    "        options = question_data[\"options\"]\n",
    "        answer = question_data[\"answer\"]\n",
    "        vocab.update(question)  # Ajouter toutes les lettres ou mots de la question au vocabulaire\n",
    "        for option in options:\n",
    "            vocab.update(option)  # Ajouter toutes les lettres ou mots des options au vocabulaire\n",
    "    \n",
    "    # Convertir le vocabulaire en une liste triée\n",
    "    vocab = sorted(vocab)\n",
    "    \n",
    "    # Créer un dictionnaire pour mapper chaque caractère ou mot à un index\n",
    "    vocab_mapping = {char: idx for idx, char in enumerate(vocab)}\n",
    "    \n",
    "    # Encoder les données\n",
    "    for question_data in data:\n",
    "        question = question_data[\"question\"]\n",
    "        options = question_data[\"options\"]\n",
    "        answer = question_data[\"answer\"]\n",
    "        \n",
    "        # Encoder la question avec one-hot encoding\n",
    "        question_one_hot = [vocab_mapping[char] for char in question]\n",
    "        question_one_hot = tf.keras.utils.to_categorical(question_one_hot, num_classes=len(vocab))\n",
    "        \n",
    "        # Padding des options pour avoir la même longueur\n",
    "        max_option_length = max(len(option) for option in options)\n",
    "        padded_options = [[vocab_mapping[char] for char in option] + [0] * (max_option_length - len(option)) for option in options]\n",
    "        options_one_hot = np.array(padded_options)  # Convertir en tableau NumPy\n",
    "        \n",
    "        # Encoder la réponse avec one-hot encoding\n",
    "        answer_index = options.index(answer)\n",
    "        answer_one_hot = tf.keras.utils.to_categorical(answer_index, num_classes=len(options))\n",
    "        \n",
    "        processed_data.append((question_one_hot, options_one_hot, answer_one_hot))\n",
    "    \n",
    "    return processed_data, vocab_mapping\n",
    "\n",
    "processed_data, vocab_mapping = preprocess_data(data)\n",
    "\n",
    "# Modifier le modèle pour traiter les données encodées avec one-hot encoding\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(128, input_shape=(None, len(vocab_mapping))))  # Utiliser la longueur du vocabulaire comme entrée\n",
    "model.add(tf.keras.layers.Dense(len(processed_data[0][1]), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.01))\n",
    "\n",
    "# Entraînement du modèle\n",
    "max_option_length = max(options.shape[1] for _, options, _ in processed_data)\n",
    "x_train = np.array([np.pad(options, ((0, 0), (0, max_option_length - options.shape[1])), 'constant', constant_values=0) for _, options, _ in processed_data])\n",
    "# Vérifier les dimensions des données d'entrée\n",
    "print(\"Shape of x_train before:\", x_train.shape)\n",
    "\n",
    "# Supprimer la dimension inutile\n",
    "x_train = x_train[:, :, :81]  # Prendre uniquement les 81 premières colonnes\n",
    "print(\"Shape of x_train after:\", x_train.shape)\n",
    "\n",
    "y_train = np.array([answer for _, _, answer in processed_data])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=256, epochs=4)\n",
    "\n",
    "\n",
    "# Fonction pour générer une question\n",
    "def generate_question(model, generated_questions, marks, max_questions):\n",
    "    unused_questions = [idx for idx in range(len(data)) if idx not in generated_questions and data[idx][\"marks\"] == marks]\n",
    "    if not unused_questions:\n",
    "        return None\n",
    "\n",
    "    if len(unused_questions) > max_questions - len(generated_questions):\n",
    "        unused_questions = random.sample(unused_questions, max_questions - len(generated_questions))\n",
    "\n",
    "    for question_idx in unused_questions:\n",
    "        generated_questions.add(question_idx)\n",
    "        question_one_hot, options, correct_answer = processed_data[question_idx]\n",
    "\n",
    "        predicted_answer = model.predict(np.array([question_one_hot]))  # Utiliser la question encodée avec one-hot encoding\n",
    "        predicted_answer_index = np.argmax(predicted_answer)\n",
    "        predicted_answer_text = options[predicted_answer_index]\n",
    "\n",
    "        options_text = [option for option in data[question_idx][\"options\"]]\n",
    "        correct_answer_text = data[question_idx][\"answer\"]\n",
    "\n",
    "        yield {\"question\": data[question_idx][\"question\"], \"options\": options_text, \"correct_answer\": correct_answer_text, \"marks\": marks}\n",
    "\n",
    "\n",
    "# Générer des questions avec les paramètres spécifiés\n",
    "def generate_questions_to_xml(model, marks, nbre_questions, output_file):\n",
    "    generated_questions = set()\n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.write(\"<quiz>\\n\")\n",
    "        for i, qcm in enumerate(generate_question(model, generated_questions, marks, nbre_questions), start=1):\n",
    "            f.write(f\"  <!-- question: {i} -->\\n\")\n",
    "            f.write(f\"  <question type=\\\"multichoice\\\">\\n\")\n",
    "            f.write(f\"    <name>\\n\")\n",
    "            f.write(f\"      <text>Question {i}</text>\\n\")\n",
    "            f.write(f\"    </name>\\n\")\n",
    "            f.write(f\"    <questiontext format=\\\"html\\\">\\n\")\n",
    "            f.write(f\"      <text><![CDATA[<pre>{qcm['question']}</pre>]]></text>\\n\")\n",
    "            f.write(f\"    </questiontext>\\n\")\n",
    "            f.write(f\"    <generalfeedback format=\\\"html\\\">\\n\")\n",
    "            f.write(f\"      <text><![CDATA[<p>none</p>]]></text>\\n\")\n",
    "            f.write(f\"    </generalfeedback>\\n\")\n",
    "            f.write(f\"    <defaultgrade>{qcm['marks']}.0000000</defaultgrade>\\n\")\n",
    "            f.write(f\"    <penalty>0.3333333</penalty>\\n\")\n",
    "            f.write(f\"    <hidden>0</hidden>\\n\")\n",
    "            f.write(f\"    <single>true</single>\\n\")\n",
    "            f.write(f\"    <shuffleanswers>true</shuffleanswers>\\n\")\n",
    "            f.write(f\"    <answernumbering>abc</answernumbering>\\n\")\n",
    "            for j, option in enumerate(qcm['options'], start=1):\n",
    "                is_correct = (option == qcm['correct_answer'])  # je verifie si l'option est la bonne réponse\n",
    "                fraction = '100' if is_correct else '0'\n",
    "                f.write(f\"    <answer fraction=\\\"{fraction}\\\" format=\\\"html\\\">\\n\")\n",
    "                f.write(f\"      <text><![CDATA[{j}. {option}]]></text>\\n\")\n",
    "                f.write(f\"      <feedback format=\\\"html\\\">\\n\")\n",
    "                f.write(f\"        <text><![CDATA[<p>none</p>]]></text>\\n\")\n",
    "                f.write(f\"      </feedback>\\n\")\n",
    "                f.write(f\"    </answer>\\n\")\n",
    "            f.write(f\"  </question>\\n\")\n",
    "        f.write(\"</quiz>\\n\")\n",
    "\n",
    "# Exemple d'utilisation\n",
    "generate_questions_to_xml(model, marks=3, nbre_questions=3, output_file=\"marks_3.xml\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train before: (37, 4, 137)\n",
      "Shape of x_train after: (37, 4, 81)\n",
      "Epoch 1/4\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.5715\n",
      "Epoch 2/4\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1785\n",
      "Epoch 3/4\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.1905\n",
      "Epoch 4/4\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.1005\n",
      "1/1 [==============================] - 1s 799ms/step\n",
      "1/1 [==============================] - 1s 636ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    }
   ],
   "source": [
    "################## Avec encodage du Makrs ###################\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "# Charger les données depuis le fichier JSON\n",
    "with open(\"data_marks.json\", \"r\") as json_file:\n",
    "    data = json.load(json_file)[\"questions\"]\n",
    "\n",
    "def preprocess_data(data):\n",
    "    processed_data = []\n",
    "    vocab = set()  # Créer un ensemble pour stocker toutes les lettres ou mots uniques\n",
    "    \n",
    "    # Parcourir les données pour construire le vocabulaire\n",
    "    for question_data in data:\n",
    "        question = question_data[\"question\"]\n",
    "        options = question_data[\"options\"]\n",
    "        answer = question_data[\"answer\"]\n",
    "        marks = question_data.get(\"marks\", 1)  # Utiliser 1 comme valeur par défaut si \"marks\" n'est pas présent\n",
    "        vocab.update(question)  # Ajouter toutes les lettres ou mots de la question au vocabulaire\n",
    "        for option in options:\n",
    "            vocab.update(option)  # Ajouter toutes les lettres ou mots des options au vocabulaire\n",
    "    \n",
    "    # Convertir le vocabulaire en une liste triée\n",
    "    vocab = sorted(vocab)\n",
    "    \n",
    "    # Créer un dictionnaire pour mapper chaque caractère ou mot à un index\n",
    "    vocab_mapping = {char: idx for idx, char in enumerate(vocab)}\n",
    "    \n",
    "    # Encoder les données\n",
    "    for question_data in data:\n",
    "        question = question_data[\"question\"]\n",
    "        options = question_data[\"options\"]\n",
    "        answer = question_data[\"answer\"]\n",
    "        marks = question_data.get(\"marks\", 1)  # Utiliser 1 comme valeur par défaut si \"marks\" n'est pas présent\n",
    "        \n",
    "        # Encoder la question avec one-hot encoding\n",
    "        question_one_hot = [vocab_mapping[char] for char in question]\n",
    "        question_one_hot = tf.keras.utils.to_categorical(question_one_hot, num_classes=len(vocab))\n",
    "        \n",
    "        # Padding des options pour avoir la même longueur\n",
    "        max_option_length = max(len(option) for option in options)\n",
    "        padded_options = [[vocab_mapping[char] for char in option] + [0] * (max_option_length - len(option)) for option in options]\n",
    "        options_one_hot = np.array(padded_options)  # Convertir en tableau NumPy\n",
    "        \n",
    "        # Encoder la réponse avec one-hot encoding\n",
    "        answer_index = options.index(answer)\n",
    "        answer_one_hot = tf.keras.utils.to_categorical(answer_index, num_classes=len(options))\n",
    "        \n",
    "        processed_data.append((question_one_hot, options_one_hot, answer_one_hot, marks))\n",
    "    \n",
    "    return processed_data, vocab_mapping\n",
    "\n",
    "\n",
    "processed_data, vocab_mapping = preprocess_data(data)\n",
    "\n",
    "# Modifier le modèle pour traiter les données encodées avec one-hot encoding\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(128, input_shape=(None, len(vocab_mapping))))  # Utiliser la longueur du vocabulaire comme entrée\n",
    "model.add(tf.keras.layers.Dense(len(processed_data[0][1]), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.01))\n",
    "\n",
    "# Entraînement du modèle\n",
    "max_option_length = max(options.shape[1] for _, options, _,_ in processed_data)\n",
    "x_train = np.array([np.pad(options, ((0, 0), (0, max_option_length - options.shape[1])), 'constant', constant_values=0) for _, options, _, _ in processed_data])\n",
    "# Vérifier les dimensions des données d'entrée\n",
    "print(\"Shape of x_train before:\", x_train.shape)\n",
    "\n",
    "# Supprimer la dimension inutile\n",
    "x_train = x_train[:, :, :81]  # Prendre uniquement les 81 premières colonnes\n",
    "print(\"Shape of x_train after:\", x_train.shape)\n",
    "\n",
    "y_train = np.array([answer for _, _, answer, _ in processed_data])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=256, epochs=4)\n",
    "\n",
    "\n",
    "# Fonction pour générer une question\n",
    "def generate_question(model, generated_questions, marks, max_questions):\n",
    "    unused_questions = [idx for idx in range(len(data)) if idx not in generated_questions and data[idx][\"marks\"] == marks]\n",
    "    if not unused_questions:\n",
    "        return None\n",
    "\n",
    "    if len(unused_questions) > max_questions - len(generated_questions):\n",
    "        unused_questions = random.sample(unused_questions, max_questions - len(generated_questions))\n",
    "\n",
    "    for question_idx in unused_questions:\n",
    "        generated_questions.add(question_idx)\n",
    "        question_one_hot, options, correct_answer, _ = processed_data[question_idx]\n",
    "\n",
    "        predicted_answer = model.predict(np.array([question_one_hot]))  # Utiliser la question encodée avec one-hot encoding\n",
    "        predicted_answer_index = np.argmax(predicted_answer)\n",
    "        predicted_answer_text = options[predicted_answer_index]\n",
    "\n",
    "        options_text = [option for option in data[question_idx][\"options\"]]\n",
    "        correct_answer_text = data[question_idx][\"answer\"]\n",
    "\n",
    "        yield {\"question\": data[question_idx][\"question\"], \"options\": options_text, \"correct_answer\": correct_answer_text, \"marks\": marks}\n",
    "\n",
    "\n",
    "# Générer des questions avec les paramètres spécifiés\n",
    "def generate_questions_to_xml(model, marks, nbre_questions, output_file):\n",
    "    generated_questions = set()\n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.write(\"<quiz>\\n\")\n",
    "        for i, qcm in enumerate(generate_question(model, generated_questions, marks, nbre_questions), start=1):\n",
    "            f.write(f\"  <!-- question: {i} -->\\n\")\n",
    "            f.write(f\"  <question type=\\\"multichoice\\\">\\n\")\n",
    "            f.write(f\"    <name>\\n\")\n",
    "            f.write(f\"      <text>Question {i}</text>\\n\")\n",
    "            f.write(f\"    </name>\\n\")\n",
    "            f.write(f\"    <questiontext format=\\\"html\\\">\\n\")\n",
    "            f.write(f\"      <text><![CDATA[<pre>{qcm['question']}</pre>]]></text>\\n\")\n",
    "            f.write(f\"    </questiontext>\\n\")\n",
    "            f.write(f\"    <generalfeedback format=\\\"html\\\">\\n\")\n",
    "            f.write(f\"      <text><![CDATA[<p>none</p>]]></text>\\n\")\n",
    "            f.write(f\"    </generalfeedback>\\n\")\n",
    "            f.write(f\"    <defaultgrade>{qcm['marks']}.0000000</defaultgrade>\\n\")\n",
    "            f.write(f\"    <penalty>0.3333333</penalty>\\n\")\n",
    "            f.write(f\"    <hidden>0</hidden>\\n\")\n",
    "            f.write(f\"    <single>true</single>\\n\")\n",
    "            f.write(f\"    <shuffleanswers>true</shuffleanswers>\\n\")\n",
    "            f.write(f\"    <answernumbering>abc</answernumbering>\\n\")\n",
    "            for j, option in enumerate(qcm['options'], start=1):\n",
    "                is_correct = (option == qcm['correct_answer'])  # je verifie si l'option est la bonne réponse\n",
    "                fraction = '100' if is_correct else '0'\n",
    "                f.write(f\"    <answer fraction=\\\"{fraction}\\\" format=\\\"html\\\">\\n\")\n",
    "                f.write(f\"      <text><![CDATA[{j}. {option}]]></text>\\n\")\n",
    "                f.write(f\"      <feedback format=\\\"html\\\">\\n\")\n",
    "                f.write(f\"        <text><![CDATA[<p>none</p>]]></text>\\n\")\n",
    "                f.write(f\"      </feedback>\\n\")\n",
    "                f.write(f\"    </answer>\\n\")\n",
    "            f.write(f\"  </question>\\n\")\n",
    "        f.write(\"</quiz>\\n\")\n",
    "\n",
    "# Exemple d'utilisation\n",
    "generate_questions_to_xml(model, marks=3, nbre_questions=3, output_file=\"marks__encode.xml\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
