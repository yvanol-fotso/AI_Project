{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wJhQAQlk-RWF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, classification_report\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Input, Embedding, GlobalAveragePooling1D, Dropout, Dense\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "# from TransformerComplet import *\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Dropout, Embedding, Input, Concatenate, MultiHeadAttention\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "class Encodeur(tf.keras.layers.Layer):\n",
        "    def __init__(self, n_layers, d_model, num_heads, middle_units,\n",
        "                 max_seq_len, epsilon=1e-6, dropout_rate=0.1, training=False, **kwargs):\n",
        "        super(Encodeur, self).__init__(**kwargs)\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.embedding_position = EncodagePosition(sequence_len=max_seq_len, embedding_dim=d_model)\n",
        "        self.couche_encode = [CoucheEncodeur(d_model=d_model, num_heads=num_heads, max_seq_len=max_seq_len,\n",
        "                                            middle_units=middle_units, epsilon=epsilon, \n",
        "                                            dropout_rate=dropout_rate, training=training)\n",
        "                             for _ in range(n_layers)]\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        emb, masque = inputs\n",
        "        emb = self.embedding_position(emb)\n",
        "        for i in range(self.n_layers):\n",
        "            emb = self.couche_encode[i](emb, masque)\n",
        "        return emb\n",
        "\n",
        "class CoucheEncodeur(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, max_seq_len, middle_units, epsilon=1e-6, dropout_rate=0.1, training=False, **kwargs):\n",
        "        super(CoucheEncodeur, self).__init__(**kwargs)\n",
        "\n",
        "        self.mha = AttentionMultiTete(num_heads)\n",
        "        self.ffn = reseau_transformation_point_a_point(d_model, middle_units)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=epsilon)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=epsilon)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "        self.training = training\n",
        "\n",
        "    def call(self, inputs, masque, **kwargs):\n",
        "        # Réseau d'attention multi-tête\n",
        "        sortie_att = self.mha([inputs, inputs, inputs, masque])\n",
        "        sortie_att = self.dropout1(sortie_att, training=self.training)\n",
        "        out1 = self.layernorm1(inputs + sortie_att)\n",
        "\n",
        "        # Réseau de transformation point à point\n",
        "        sortie_ffn = self.ffn(out1)\n",
        "        sortie_ffn = self.dropout2(sortie_ffn, training=self.training)\n",
        "        out2 = self.layernorm2(out1 + sortie_ffn)\n",
        "\n",
        "        return out2\n",
        "\n",
        "def reseau_transformation_point_a_point(numUnits, middle_units):\n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(middle_units, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.1),\n",
        "        tf.keras.layers.Dense(numUnits, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.1),\n",
        "        tf.keras.layers.LayerNormalization()\n",
        "    ])\n",
        "\n",
        "def attention_produit_scalaire_equilibre(q, k, v, masque):\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
        "    dim_k = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    attention_logits_mis_a_echelle = matmul_qk / tf.math.sqrt(dim_k)\n",
        "    if masque is not None:\n",
        "        attention_logits_mis_a_echelle += (masque * -1e9)\n",
        "    poids_attention = tf.nn.softmax(attention_logits_mis_a_echelle, axis=-1)\n",
        "    sortie = tf.matmul(poids_attention, v)\n",
        "    return sortie\n",
        "\n",
        "class AttentionMultiTete(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_heads, **kwargs):\n",
        "        super(AttentionMultiTete, self).__init__(**kwargs)\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_produit_scalaire = attention_produit_scalaire_equilibre\n",
        "\n",
        "    def separation_tetes(self, x, batch_size, profondeur):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, profondeur))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        q, k, v, masque = inputs\n",
        "        batch_size = tf.shape(q)[0]\n",
        "        numUnits = q.get_shape().as_list()[-1]\n",
        "        profondeur = numUnits // self.num_heads\n",
        "\n",
        "        wq = tf.keras.layers.Dense(numUnits)\n",
        "        wk = tf.keras.layers.Dense(numUnits)\n",
        "        wv = tf.keras.layers.Dense(numUnits)\n",
        "        q = wq(q)\n",
        "        k = wk(k)\n",
        "        v = wv(v)\n",
        "\n",
        "        q = self.separation_tetes(q, batch_size, profondeur)\n",
        "        k = self.separation_tetes(k, batch_size, profondeur)\n",
        "        v = self.separation_tetes(v, batch_size, profondeur)\n",
        "\n",
        "        attention_mise_a_echelle = self.attention_produit_scalaire(q, k, v, masque)\n",
        "\n",
        "        attention_mise_a_echelle = tf.transpose(attention_mise_a_echelle, [0, 2, 1, 3])\n",
        "\n",
        "        attention_concatenee = tf.reshape(attention_mise_a_echelle, (batch_size, -1, numUnits))\n",
        "\n",
        "        dense = tf.keras.layers.Dense(numUnits)\n",
        "        sortie = dense(attention_concatenee)\n",
        "\n",
        "        return sortie\n",
        "\n",
        "def masque_remplissage(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "    return seq[:, np.newaxis, np.newaxis, :]\n",
        "\n",
        "class EncodagePosition(tf.keras.layers.Layer):\n",
        "    def __init__(self, sequence_len=None, embedding_dim=None, **kwargs):\n",
        "        super(EncodagePosition, self).__init__(**kwargs)\n",
        "        self.sequence_len = sequence_len\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        seq_len = tf.shape(inputs)[1]\n",
        "        if self.embedding_dim is None:\n",
        "            self.embedding_dim = int(inputs.shape[-1])\n",
        "\n",
        "        position_indices = tf.range(seq_len, dtype=tf.float32)[:, tf.newaxis]\n",
        "        dimension_indices = tf.range(self.embedding_dim, dtype=tf.float32)[tf.newaxis, :]\n",
        "\n",
        "        angle_rads = position_indices / tf.math.pow(10000.0, (2.0 * (dimension_indices // 2)) / tf.cast(self.embedding_dim, tf.float32))\n",
        "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "        position_encoding = tf.concat([sines, cosines], axis=-1)[tf.newaxis, ...]\n",
        "\n",
        "        position_encoding = tf.cast(position_encoding, dtype=tf.float32)\n",
        "        return inputs + position_encoding\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JGOsfkW9_p0u"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import tensorflow as tf\n",
        "# tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "# class Encodeur(tf.keras.layers.Layer):\n",
        "#     def __init__(self, n_layers, d_model, num_heads, middle_units,\n",
        "#                  max_seq_len, epsilon=1e-6, dropout_rate=0.1, training=False, **kwargs):\n",
        "#         super(Encodeur, self).__init__(**kwargs)\n",
        "#         self.n_layers = n_layers\n",
        "\n",
        "#         self.embedding_position = EncodagePosition(sequence_len=max_seq_len, embedding_dim=d_model)\n",
        "#         self.couche_encode = [CoucheEncodeur(d_model=d_model, num_heads=num_heads,max_seq_len=max_seq_len,\n",
        "#                                             middle_units=middle_units,\n",
        "#                                             epsilon=epsilon, dropout_rate=dropout_rate,\n",
        "#                                             training=training)\n",
        "#                              for _ in range(n_layers)]\n",
        "\n",
        "#     def call(self, inputs, **kwargs):\n",
        "#         emb, masque = inputs\n",
        "#         emb = self.embedding_position(emb)\n",
        "#         for i in range(self.n_layers):\n",
        "#             emb = self.couche_encode[i](emb, masque)\n",
        "\n",
        "#         return emb\n",
        "\n",
        "\n",
        "# # Couche d'encodage\n",
        "# class CoucheEncodeur(tf.keras.layers.Layer):\n",
        "#     def __init__(self, d_model, num_heads, max_seq_len, middle_units, epsilon=1e-6, dropout_rate=0.1, training=False, **kwargs):\n",
        "#         super(CoucheEncodeur, self).__init__(**kwargs)\n",
        "\n",
        "#         self.mha = AttentionMultiTete(num_heads)\n",
        "#         # self.ffn = reseau_transformation_point_a_point(d_model + max_seq_len, middle_units) ## Erreur de Dimension\n",
        "#         self.ffn = reseau_transformation_point_a_point(d_model, middle_units)\n",
        "\n",
        "#         self.layernorm1 = NormalisationCouche()\n",
        "#         self.layernorm2 = NormalisationCouche()\n",
        "\n",
        "#         self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n",
        "#         self.dropout2 = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "#         self.training = training\n",
        "\n",
        "#     def call(self, inputs, masque, **kwargs):\n",
        "#         # Réseau d'attention multi-tête\n",
        "#         sortie_att = self.mha([inputs, inputs, inputs, masque])\n",
        "#         sortie_att = self.dropout1(sortie_att, training=self.training)\n",
        "#         out1 = self.layernorm1(inputs + sortie_att)\n",
        "\n",
        "#         # Réseau de transformation point à point\n",
        "#         sortie_ffn = self.ffn(out1)\n",
        "#         sortie_ffn = self.dropout2(sortie_ffn, training=self.training)\n",
        "#         out2 = self.layernorm2(out1 + sortie_ffn)  # Problème de dimension ici\n",
        "\n",
        "#         return out2\n",
        "\n",
        "# # Normalisation de couche\n",
        "# class NormalisationCouche(tf.keras.layers.Layer):\n",
        "#     def __init__(self, epsilon=1e-6, **kwargs):\n",
        "#         self.eps = epsilon\n",
        "#         super(NormalisationCouche, self).__init__(**kwargs)\n",
        "\n",
        "#     def build(self, input_shape):\n",
        "#         self.gamma = self.add_weight(name='gamma', shape=input_shape[-1:],\n",
        "#                                      initializer=tf.ones_initializer(), trainable=True)\n",
        "#         self.beta = self.add_weight(name='beta', shape=input_shape[-1:],\n",
        "#                                     initializer=tf.zeros_initializer(), trainable=True)\n",
        "#         super(NormalisationCouche, self).build(input_shape)\n",
        "\n",
        "#     def call(self, x):\n",
        "#         moyenne = tf.keras.backend.mean(x, axis=-1, keepdims=True)\n",
        "#         ecart_type = tf.keras.backend.std(x, axis=-1, keepdims=True)\n",
        "#         return self.gamma * (x - moyenne) / (ecart_type + self.eps) + self.beta\n",
        "\n",
        "#     def compute_output_shape(self, input_shape):\n",
        "#         return input_shape\n",
        "\n",
        "\n",
        "# # Réseau de transformation point à point\n",
        "# def reseau_transformation_point_a_point(numUnits, middle_units):\n",
        "#     return tf.keras.Sequential([\n",
        "#         tf.keras.layers.Dense(middle_units, activation='relu'),\n",
        "#         tf.keras.layers.Dense(numUnits, activation='relu')])\n",
        "\n",
        "\n",
        "# # Attention à produit scalaire équilibrée\n",
        "# def attention_produit_scalaire_equilibre(q, k, v, masque):\n",
        "#     matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
        "#     dim_k = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "#     attention_logits_mis_a_echelle = matmul_qk / tf.math.sqrt(dim_k)\n",
        "#     if masque is not None:\n",
        "#         attention_logits_mis_a_echelle += (masque * -1e9)\n",
        "\n",
        "#     poids_attention = tf.nn.softmax(attention_logits_mis_a_echelle, axis=-1)\n",
        "#     sortie = tf.matmul(poids_attention, v)\n",
        "#     return sortie\n",
        "\n",
        "\n",
        "# # Construction de la couche d'attention multi-tête\n",
        "# class AttentionMultiTete(tf.keras.layers.Layer):\n",
        "#     def __init__(self, num_heads, **kwargs):\n",
        "#         super(AttentionMultiTete, self).__init__(**kwargs)\n",
        "#         self.num_heads = num_heads\n",
        "#         self.attention_produit_scalaire = attention_produit_scalaire_equilibre\n",
        "\n",
        "#     def separation_tetes(self, x, batch_size, profondeur):\n",
        "#         # Séparation des têtes, déplace la dimension du nombre de têtes avant la séquence\n",
        "#         x = tf.reshape(x, (batch_size, -1, self.num_heads, profondeur))\n",
        "#         return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "#     def call(self, inputs, **kwargs):\n",
        "#         q, k, v, masque = inputs\n",
        "#         batch_size = tf.shape(q)[0]\n",
        "#         numUnits = q.get_shape().as_list()[-1]\n",
        "#         profondeur = numUnits // self.num_heads\n",
        "\n",
        "#         # Avant la séparation des têtes, réseau avant la séparation\n",
        "#         wq = tf.keras.layers.Dense(numUnits)\n",
        "#         wk = tf.keras.layers.Dense(numUnits)\n",
        "#         wv = tf.keras.layers.Dense(numUnits)\n",
        "#         q = wq(q)\n",
        "#         k = wk(k)\n",
        "#         v = wv(v)\n",
        "\n",
        "#         # Séparation des têtes\n",
        "#         q = self.separation_tetes(q, batch_size, profondeur)\n",
        "#         k = self.separation_tetes(k, batch_size, profondeur)\n",
        "#         v = self.separation_tetes(v, batch_size, profondeur)\n",
        "\n",
        "#         # À travers la couche d'attention à produit scalaire équilibré\n",
        "#         attention_mise_a_echelle = self.attention_produit_scalaire(q, k, v, masque)\n",
        "\n",
        "#         # Déplacement de la dimension \"têtes multiples\"\n",
        "#         attention_mise_a_echelle = tf.transpose(attention_mise_a_echelle, [0, 2, 1, 3])\n",
        "\n",
        "#         # Fusion de la dimension \"têtes multiples\"\n",
        "#         attention_concatenee = tf.reshape(attention_mise_a_echelle, (batch_size, -1, numUnits))\n",
        "\n",
        "#         # Couche entièrement connectée\n",
        "#         dense = tf.keras.layers.Dense(numUnits)\n",
        "#         sortie = dense(attention_concatenee)\n",
        "\n",
        "#         return sortie\n",
        "\n",
        "# # Fonction de masquage\n",
        "# def masque_remplissage(seq):\n",
        "#     # Obtenir les éléments de remplissage (paddings) égaux à 0\n",
        "#     seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "\n",
        "#     # Élargir les dimensions pour la matrice d'attention\n",
        "#     return seq[:, np.newaxis, np.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
        "\n",
        "\n",
        "# # Encodage des positions\n",
        "# class EncodagePosition(tf.keras.layers.Layer):\n",
        "#     def __init__(self, sequence_len=None, embedding_dim=None, **kwargs):\n",
        "#         self.sequence_len = sequence_len\n",
        "#         self.embedding_dim = embedding_dim\n",
        "#         super(EncodagePosition, self).__init__(**kwargs)\n",
        "\n",
        "#     def call(self, inputs):\n",
        "#         if self.embedding_dim is None:\n",
        "#             self.embedding_dim = int(inputs.shape[-1])\n",
        "\n",
        "#         encodage_position = np.array([\n",
        "#             [pos / np.power(10000, 2. * i / self.embedding_dim) for i in range(self.embedding_dim)]\n",
        "#             for pos in range(self.sequence_len)])\n",
        "\n",
        "#         encodage_position[:, 0::2] = np.sin(encodage_position[:, 0::2])  # dim 2i\n",
        "#         encodage_position[:, 1::2] = np.cos(encodage_position[:, 1::2])  # dim 2i+1\n",
        "\n",
        "#         encodage_position = tf.cast(encodage_position, dtype=tf.float32)\n",
        "\n",
        "#         return encodage_position + inputs\n",
        "\n",
        "#     def compute_output_shape(self, input_shape):\n",
        "#         return input_shape\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIOdU0wvKVkC",
        "outputId": "f11314b6-642b-43ee-b9dc-2202d1610ffa"
      },
      "outputs": [],
      "source": [
        "# #################### Sa marche mais ne pas executer #########################\n",
        "# #############################################################################\n",
        "\n",
        "# import pandas as pd\n",
        "# import zipfile\n",
        "# import os\n",
        "# import shutil\n",
        "\n",
        "# # Chemin vers l'archive zip\n",
        "# chemin_zip = \"Benign.zip\"\n",
        "\n",
        "# # Fonction pour charger les fichiers CSV à partir de l'archive zip extraite\n",
        "# def charger_csv(chemin_zip, sous_dossier):\n",
        "#     dataframes = []  # Stocker les dataframes chargés à partir des fichiers CSV\n",
        "\n",
        "#     with zipfile.ZipFile(chemin_zip, 'r') as zip_ref:\n",
        "#         # Extraire tous les fichiers dans un sous-dossier temporaire\n",
        "#         zip_ref.extractall(\"extraction_temp\")\n",
        "\n",
        "#     # Parcourir les fichiers extraits dans le sous-dossier spécifié\n",
        "#     for fichier in os.listdir(os.path.join(\"extraction_temp\", sous_dossier)):\n",
        "#         chemin_fichier = os.path.join(\"extraction_temp\", sous_dossier, fichier)\n",
        "#         if fichier.endswith(\".csv\"):\n",
        "#             df = pd.read_csv(chemin_fichier)\n",
        "#             dataframes.append(df)\n",
        "\n",
        "#     # Supprimer le sous-dossier temporaire après avoir chargé les fichiers CSV\n",
        "#     shutil.rmtree(os.path.join(\"extraction_temp\", sous_dossier))\n",
        "\n",
        "#     # Concaténer tous les dataframes en un seul\n",
        "#     merged_dataframe = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "#     return merged_dataframe\n",
        "\n",
        "# # Appeler la fonction pour charger les fichiers CSV depuis l'archive zip\n",
        "# merged_stateful_benign = charger_csv(chemin_zip, \"Benign\")\n",
        "# merged_stateless_benign = charger_csv(chemin_zip, \"Benign\")\n",
        "\n",
        "# # Afficher les premières lignes des données chargées pour vérification\n",
        "# print(\"merged_stateful_benign:\")\n",
        "# print(merged_stateful_benign.head())\n",
        "\n",
        "# print(\"\\nmerged_stateless_benign:\")\n",
        "# print(merged_stateless_benign.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jD3yfgsaMK6x"
      },
      "outputs": [],
      "source": [
        "################ Bon Code ###############\n",
        "#### charger et lire un dataset [.zip] sur coolab ####\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "import shutil\n",
        "\n",
        "# # Chemins vers les fichiers zip quand je suis sur google Coolab\n",
        "\n",
        "# chemin_zip_heavy_attacks = \"/content/AttacksHeavy.zip\"\n",
        "# chemin_zip_heavy_benign = \"/content/BenignHeavy.zip\"\n",
        "\n",
        "\n",
        "# chemin_zip_light_attacks = \"/content/AttacksLight.zip\"\n",
        "# chemin_zip_light_benign = \"/content/BenignLight.zip\"\n",
        "\n",
        "# Chemins vers les fichiers zip En local\n",
        "\n",
        "chemin_zip_heavy_attacks = \"AttacksHeavy.zip\"\n",
        "chemin_zip_heavy_benign = \"BenignHeavy.zip\"\n",
        "\n",
        "\n",
        "chemin_zip_light_attacks = \"AttacksLight.zip\"\n",
        "chemin_zip_light_benign = \"BenignLight.zip\"\n",
        "\n",
        "\n",
        "# Fonction pour extraire les fichiers zip\n",
        "def extraire_zip(chemin_zip):\n",
        "    with zipfile.ZipFile(chemin_zip, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"extraction_temp\")  # Extraire les fichiers zip dans un répertoire temporaire\n",
        "\n",
        "# Fonction pour charger les fichiers CSV d'un type spécifique (stateful ou stateless)\n",
        "def charger_concatener_donnees(sous_dossier, prefixe):\n",
        "    # Lister tous les fichiers CSV dans le sous-dossier\n",
        "    fichiers_csv = [f for f in os.listdir(f\"extraction_temp/{sous_dossier}\") if f.startswith(prefixe) and f.endswith('.csv')]\n",
        "    # Lire chaque fichier CSV et le stocker dans une liste de DataFrames\n",
        "    dataframes = [pd.read_csv(f\"extraction_temp/{sous_dossier}/{f}\") for f in fichiers_csv]\n",
        "    # Concaténer les DataFrames en un seul\n",
        "    return pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "# Extraire les fichiers zip\n",
        "extraire_zip(chemin_zip_heavy_attacks)\n",
        "extraire_zip(chemin_zip_heavy_benign)\n",
        "\n",
        "extraire_zip(chemin_zip_light_attacks)\n",
        "extraire_zip(chemin_zip_light_benign)\n",
        "\n",
        "########## Heavy ############\n",
        "\n",
        "# Charger et concaténer les données stateful\n",
        "stateful_heavy_attack_data = charger_concatener_donnees(\"AttacksHeavy\", \"stateful\")\n",
        "stateful_heavy_benign_data = charger_concatener_donnees(\"BenignHeavy\", \"stateful\")\n",
        "\n",
        "# Charger et concaténer les données stateless\n",
        "stateless_heavy_attack_data = charger_concatener_donnees(\"AttacksHeavy\", \"stateless\")\n",
        "stateless_heavy_benign_data = charger_concatener_donnees(\"BenignHeavy\", \"stateless\")\n",
        "\n",
        "\n",
        "#### Light ###############\n",
        "\n",
        "# Charger et concaténer les données stateful\n",
        "stateful_light_attack_data = charger_concatener_donnees(\"AttacksLight\", \"stateful\")\n",
        "stateful_light_benign_data = charger_concatener_donnees(\"BenignLight\", \"stateful\")\n",
        "\n",
        "# Charger et concaténer les données stateless\n",
        "stateless_light_attack_data = charger_concatener_donnees(\"AttacksLight\", \"stateless\")\n",
        "stateless_light_benign_data = charger_concatener_donnees(\"BenignLight\", \"stateless\")\n",
        "\n",
        "\n",
        "\n",
        "# Supprimer le répertoire temporaire après avoir terminé\n",
        "\n",
        "# Vérifier si le répertoire temporaire existe\n",
        "if os.path.exists(\"extraction_temp\"):\n",
        "    # Supprimer le répertoire temporaire et son contenu\n",
        "    shutil.rmtree(\"extraction_temp\")\n",
        "\n",
        "\n",
        "# Maintenant, vous avez vos données prêtes à être utilisées\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Taille Stateful Heavy attack puis Stateless Heavy attack\n",
            "(72028, 27)\n",
            "(251670, 15)\n",
            "Taille Stateful Bengin  heavy attack puis Stateless Begnin attack \n",
            "(69016, 27)\n",
            "(181694, 15)\n",
            "Taille Stateful Heavy Light attacks puis Stateless Light\n",
            "(11295, 27)\n",
            "(42683, 15)\n",
            "Taille Stateful Bengin Light attack puis Stateless Begnin Light\n",
            "(22768, 27)\n",
            "(60091, 15)\n",
            " cocncatenantion sur axis = 0 sur les y \n",
            "\n",
            " Heavy attack\n",
            "(323698, 42)\n",
            "(323698, 43)\n",
            " \n",
            "\n",
            " Heavy Bengnin\n",
            "(250710, 42)\n",
            "(250710, 43)\n",
            " \n",
            "\n",
            " Light attack\n",
            "(53978, 42)\n",
            "(53978, 43)\n",
            " \n",
            "\n",
            " Light Bengnin\n",
            "(82859, 42)\n",
            "(82859, 43)\n"
          ]
        }
      ],
      "source": [
        "############## taille reelle #############\n",
        "\n",
        "############## pareille que celui du troisieme papier #############\n",
        "\n",
        "print(\"Taille Stateful Heavy attack puis Stateless Heavy attack\")\n",
        "print(stateful_heavy_attack_data.shape)\n",
        "print(stateless_heavy_attack_data.shape)\n",
        "\n",
        "\n",
        "print(\"Taille Stateful Bengin  heavy attack puis Stateless Begnin attack \")\n",
        "print(stateful_heavy_benign_data.shape)\n",
        "print(stateless_heavy_benign_data.shape)\n",
        "\n",
        "\n",
        "\n",
        "############## taille reelle #############\n",
        "print(\"Taille Stateful Heavy Light attacks puis Stateless Light\")\n",
        "print(stateful_light_attack_data.shape)\n",
        "print(stateless_light_attack_data.shape)\n",
        "\n",
        "\n",
        "print(\"Taille Stateful Bengin Light attack puis Stateless Begnin Light\")\n",
        "print(stateful_light_benign_data.shape)\n",
        "print(stateless_light_benign_data.shape)\n",
        "\n",
        "#### concatenation  sur axis = 0 ########\n",
        "\n",
        "print(\" cocncatenantion sur axis = 0 sur les y \\n\")\n",
        "print(\" Heavy attack\")\n",
        "\n",
        "heavy_attack = pd.concat([stateful_heavy_attack_data, stateless_heavy_attack_data], axis=0)\n",
        "print(heavy_attack.shape)\n",
        "\n",
        "#### j'ajoute la classe / label ######\n",
        "\n",
        "heavy_attack['class'] = 'heavy_attacks'\n",
        "print(heavy_attack.shape)\n",
        "\n",
        "print(\" \\n\")\n",
        "print(\" Heavy Bengnin\")\n",
        "\n",
        "heavy_bengin = pd.concat([stateful_heavy_benign_data, stateless_heavy_benign_data], axis=0)\n",
        "print(heavy_bengin.shape)\n",
        "\n",
        "#### j'ajoute la classe / label ######\n",
        "\n",
        "heavy_bengin['class'] = 'heavy_bengnin'\n",
        "print(heavy_bengin.shape)\n",
        "\n",
        "print(\" \\n\")\n",
        "print(\" Light attack\")\n",
        "\n",
        "light_attack = pd.concat([stateful_light_attack_data, stateless_light_attack_data], axis=0)\n",
        "print(light_attack.shape)\n",
        "\n",
        "#### j'ajoute la classe / label ######\n",
        "light_attack['class'] = 'light_attacks'\n",
        "print(light_attack.shape)\n",
        "\n",
        "\n",
        "print(\" \\n\")\n",
        "print(\" Light Bengnin\")\n",
        "\n",
        "light_bengin = pd.concat([stateful_light_benign_data, stateless_light_benign_data], axis=0)\n",
        "print(light_bengin.shape)\n",
        "\n",
        "#### j'ajoute la classe / label ######\n",
        "light_bengin['class'] = 'light_bengnin'\n",
        "print(light_bengin.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Taille Stateful Heavy attack puis Stateless Heavy attack\n",
            "(72028, 27)\n",
            "(251670, 15)\n",
            "  \n",
            "\n",
            "Taille Stateful Bengin attack puis Stateless Begnin attack \n",
            "(156014, 27)\n",
            "(402767, 15)\n",
            "  \n",
            "\n",
            "Taille Stateful Heavy Light puis Stateless Light\n",
            "(11295, 27)\n",
            "(42683, 15)\n",
            "  \n",
            "\n",
            "Taille Stateful Bengin Light puis Stateless Begnin Light\n",
            "(109766, 27)\n",
            "(281164, 15)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# #### Echantillonage comme dans le papier ayat produit ce dataset ####\n",
        "\n",
        "# ##  Heavy Attack   72,028(stateful)      251,670 (stateless)\n",
        "\n",
        "# ##  Heavy-Benign      156,014                  402,767\n",
        "\n",
        "# ### Light Attack      11,295                   42,683\n",
        "\n",
        "# ### Light-Benign      109,766                  281,164\n",
        "\n",
        "\n",
        "# #### Heavy ATTACK #########\n",
        "# stateful_heavy_attack_data = stateful_heavy_attack_data.sample(72028, random_state=42)\n",
        "# stateful_heavy_benign_data = stateful_heavy_benign_data.sample(156014, random_state=42,replace=True)\n",
        "\n",
        "# stateless_heavy_attack_data = stateless_heavy_attack_data.sample(251670, random_state=42)\n",
        "# stateless_heavy_benign_data = stateless_heavy_benign_data.sample(402767, random_state=42,replace=True)\n",
        "\n",
        "# #### Light ATTACK #########\n",
        "\n",
        "# # Charger les données stateful\n",
        "# stateful_light_attack_data = stateful_light_attack_data.sample(11295, random_state=42)\n",
        "# stateful_light_benign_data = stateful_light_benign_data.sample(109766, random_state=42,replace=True)\n",
        "# # Charger les données stateless\n",
        "# stateless_light_attack_data = stateless_light_attack_data.sample(42683, random_state=42)\n",
        "# stateless_light_benign_data = stateless_light_benign_data.sample(281164, random_state=42,replace=True)\n",
        "\n",
        "# ############## taille apres re-echantillonage #############\n",
        "# print(\"Taille Stateful Heavy attack puis Stateless Heavy attack\")\n",
        "# print(stateful_heavy_attack_data.shape)\n",
        "# print(stateless_heavy_attack_data.shape)\n",
        "\n",
        "# print(\"  \\n\")\n",
        "\n",
        "# print(\"Taille Stateful Bengin attack puis Stateless Begnin attack \")\n",
        "# print(stateful_heavy_benign_data.shape)\n",
        "# print(stateless_heavy_benign_data.shape)\n",
        "\n",
        "# print(\"  \\n\")\n",
        "\n",
        "\n",
        "# ############## taille apres re-echantillonage #############\n",
        "# print(\"Taille Stateful Heavy Light puis Stateless Light\")\n",
        "# print(stateful_light_attack_data.shape)\n",
        "# print(stateless_light_attack_data.shape)\n",
        "\n",
        "# print(\"  \\n\")\n",
        "\n",
        "# print(\"Taille Stateful Bengin Light puis Stateless Begnin Light\")\n",
        "# print(stateful_light_benign_data.shape)\n",
        "# print(stateless_light_benign_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ######################################################################################\n",
        "# ######################################################################################\n",
        "# ### Ne pas executer car ici c'es le cas d'une classification binaraire que je test ####\n",
        "# ######################################################################################\n",
        "# ######################################################################################\n",
        "\n",
        "\n",
        "# ##### pharse de concatenation tres importante car les jeu de donnee n'ont pas tous les memes schemas ####\n",
        "\n",
        "\n",
        "# ### (axis=0) car ils ont les memes colonnes donc ont empile ; (axis=1) colonne different on juxtapose\n",
        "\n",
        "# merged_statful_heavy_light_attack = pd.concat([stateful_heavy_attack_data, stateful_light_attack_data], axis=0, ignore_index=True)\n",
        "# merged_stateless_heavy_light_attack = pd.concat([stateless_heavy_attack_data, stateless_light_attack_data], axis=0, ignore_index=True)\n",
        "\n",
        "# merged_statful_heavy_light_bengnin = pd.concat([stateful_heavy_benign_data, stateful_light_benign_data], axis=0, ignore_index=True)\n",
        "# merged_stateless_heavy_light_bengnin = pd.concat([stateless_heavy_benign_data, stateless_light_benign_data], axis=0, ignore_index=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ############## taille apres re-echantillonage  et Concatenantion #############\n",
        "# print(\"Taille Stateful Heavy attack puis Stateless Light attacks \")\n",
        "# print(merged_statful_heavy_light_attack.shape)\n",
        "# print(merged_stateless_heavy_light_attack.shape)\n",
        "\n",
        "# print(\"  \\n\")\n",
        "\n",
        "# print(\"Taille Stateful Bengin Light puis Stateless Begnin Light\")\n",
        "# print(merged_statful_heavy_light_bengnin.shape)\n",
        "# print(merged_stateless_heavy_light_bengnin.shape)\n",
        "\n",
        "# print(\"  \\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Fusionner les données stateful et stateless\n",
        "# final_attack_data = pd.concat([merged_statful_heavy_light_attack, merged_stateless_heavy_light_attack], axis=1)\n",
        "# final_benign_data = pd.concat([merged_statful_heavy_light_bengnin, merged_stateless_heavy_light_bengnin], axis=1)\n",
        "\n",
        "# # Ajouter les étiquettes\n",
        "# final_attack_data['label'] = 'attack heavy _light'\n",
        "# final_benign_data['label'] = 'benign heavy _light'\n",
        "\n",
        "# print(final_attack_data.shape)\n",
        "# print(final_benign_data.shape)\n",
        "\n",
        "# final_attack_data.isnull().sum().sort_values(ascending=False)\n",
        "# final_benign_data.isnull().sum().sort_values(ascending=False)\n",
        "\n",
        "\n",
        "# ##################################################################################################\n",
        "# ########################## End ###################################################################\n",
        "# ##################################################################################################\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6XTf3qjNNCQ",
        "outputId": "a9535173-8dd3-44c8-e54a-51e758eaf0c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['heavy_attacks' 'heavy_bengnin' 'light_bengnin' 'light_attacks']\n",
            "class\n",
            "heavy_attacks    323698\n",
            "heavy_bengnin    250710\n",
            "light_bengnin     82859\n",
            "light_attacks     53978\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "################################### CONCATENATION Final des donnee sur axis = 0 ########\n",
        "########################################################################################\n",
        "########################################################################################\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "# 2. Concaténer les données\n",
        "\n",
        "final_data = pd.concat([heavy_attack, heavy_bengin,light_attack,light_bengin], axis=0, ignore_index=True)\n",
        "\n",
        "# 3. Supprimer les colonnes redondantes dans les données catégorielles\n",
        "final_data = final_data.loc[:, ~final_data.columns.duplicated()]\n",
        "\n",
        "final_data = shuffle(final_data, random_state=42)\n",
        "\n",
        "\n",
        "# X_numerical = final_data.select_dtypes(include=['int64', 'float64'])\n",
        "\n",
        "# X_categorical = final_data.select_dtypes(exclude='number').drop('class', axis=1)\n",
        "\n",
        "### Selection / Usage manuelle des features du papier selectionee avec de GOA-GA (17 features) ####\n",
        "\n",
        "# X_numerical = final_data[['rr','A_frequency','FQDN_count','upper','lower','numeric','entropy','special', 'labels', 'labels_max','labels_average','len']]\n",
        "\n",
        "# X_categorical = final_data[['rr_type','unique_ttl','timestamp', 'longest_word', 'sld']]\n",
        "\n",
        "\n",
        "print(final_data['class'].unique())\n",
        "print(final_data['class'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "class\n",
            "light_bengnin    323698\n",
            "light_attacks    323698\n",
            "heavy_attacks    323698\n",
            "heavy_bengnin    323698\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# Identifier la classe majoritaire\n",
        "major_class = final_data['class'].value_counts().idxmax()\n",
        "major_count = final_data['class'].value_counts().max()\n",
        "\n",
        "# Sur-échantillonnage des classes minoritaires pour les ramener à la taille de la classe majoritaire\n",
        "over_sampler = RandomOverSampler(sampling_strategy={class_: major_count for class_ in final_data['class'].unique() if class_ != major_class}, random_state=42)\n",
        "X_over, y_over = over_sampler.fit_resample(final_data.drop(columns=['class']), final_data['class'])\n",
        "\n",
        "# Concaténer les données sur-échantillonnées avec la classe majoritaire\n",
        "balanced_data = pd.concat([pd.DataFrame(X_over, columns=final_data.drop(columns=['class']).columns), pd.Series(y_over, name='class')], axis=1)\n",
        "\n",
        "# Mélanger les données\n",
        "balanced_data = shuffle(balanced_data, random_state=42)\n",
        "\n",
        "# Afficher les classes équilibrées\n",
        "print(balanced_data['class'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1294792, 12)\n",
            "(1294792, 4)\n",
            "(1294792,)\n",
            "(1294792, 43)\n"
          ]
        }
      ],
      "source": [
        "X_numerical = balanced_data[['rr','A_frequency','FQDN_count','upper','lower','numeric','entropy','special', 'labels', 'labels_max','labels_average','len']]\n",
        "\n",
        "X_categorical = balanced_data[['rr_type','unique_ttl','longest_word', 'sld']]\n",
        "\n",
        "y = balanced_data['class']\n",
        "\n",
        "print(X_numerical.shape)\n",
        "print(X_categorical.shape)\n",
        "\n",
        "print(y.shape)\n",
        "print(balanced_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ############ NE PAS EXECUTER #################################\n",
        "# ################################### CONCATENATION Final des donnee sur axis = 1 ########\n",
        "# ########################################################################################\n",
        "# ########################################################################################\n",
        "\n",
        "# ############## Ne pas executer ,executer si et seulement si jai executer la concatenation sur axis =1 ####\n",
        "\n",
        "\n",
        "\n",
        "# # 2. Concaténer les données\n",
        "\n",
        "# final_data = pd.concat([heavy_attack, heavy_bengin,light_attack,light_bengin], axis=1, ignore_index=True)\n",
        "\n",
        "# # 3. Supprimer les colonnes redondantes dans les données catégorielles\n",
        "# final_data = final_data.loc[:, ~final_data.columns.duplicated()]\n",
        "\n",
        "# X_numerical = final_data.select_dtypes(include=['int64', 'float64'])\n",
        "\n",
        "# X_categorical = final_data.select_dtypes(exclude='number').drop('class', axis=1)\n",
        "# y = final_data['class']\n",
        "\n",
        "# print(X_numerical.shape)\n",
        "# print(X_categorical.shape)\n",
        "\n",
        "# print(y.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXx2T7bCNW3y",
        "outputId": "b25cfcf2-d4b8-4dbf-e6f5-e13c485a92cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['heavy_attacks' 'heavy_bengnin' 'light_bengnin' 'light_attacks']\n",
            "class\n",
            "heavy_attacks    323698\n",
            "heavy_bengnin    250710\n",
            "light_bengnin     82859\n",
            "light_attacks     53978\n",
            "Name: count, dtype: int64\n",
            "class\n",
            "heavy_attacks    133358\n",
            "heavy_bengnin    133358\n",
            "light_attacks    133358\n",
            "light_bengnin    133358\n",
            "Name: count, dtype: int64\n",
            "Total instances: 533432\n"
          ]
        }
      ],
      "source": [
        "# ##### equilibrage strict ########\n",
        "########## Marche mais je ne veux pas #########\n",
        "\n",
        "\n",
        "\n",
        "# import pandas as pd\n",
        "# from imblearn.over_sampling import RandomOverSampler\n",
        "# from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "\n",
        "\n",
        "# # Classe et leur distribution actuelle\n",
        "# print(final_data['class'].unique())\n",
        "# print(final_data['class'].value_counts())\n",
        "\n",
        "# # Nombre total d'instances souhaité\n",
        "# total_instances = 533433\n",
        "\n",
        "\n",
        "# # Calculez le nombre cible d'instances par classe\n",
        "# target_class_count = total_instances // len(final_data['class'].unique())\n",
        "\n",
        "# # Sur-échantillonnage\n",
        "# over_sampler = RandomOverSampler(sampling_strategy='not majority', random_state=42)\n",
        "# X_over, y_over = over_sampler.fit_resample(final_data.drop('class', axis=1), final_data['class'])\n",
        "\n",
        "# # Combinez les données sur-échantillonnées\n",
        "# over_data = pd.DataFrame(X_over, columns=final_data.drop('class', axis=1).columns)\n",
        "# over_data['class'] = y_over\n",
        "\n",
        "# # Sous-échantillonnage pour obtenir le nombre total d'instances souhaité\n",
        "# under_sampler = RandomUnderSampler(sampling_strategy={cls: target_class_count for cls in final_data['class'].unique()}, random_state=42)\n",
        "# X_balanced, y_balanced = under_sampler.fit_resample(over_data.drop('class', axis=1), over_data['class'])\n",
        "\n",
        "# # Créez le DataFrame équilibré final\n",
        "# balanced_data = pd.DataFrame(X_balanced, columns=over_data.drop('class', axis=1).columns)\n",
        "# balanced_data['class'] = y_balanced\n",
        "\n",
        "# # Affichez les nouvelles tailles des classes équilibrées\n",
        "# print(balanced_data['class'].value_counts())\n",
        "\n",
        "# # Vérifiez le nombre total d'instances\n",
        "# print(\"Total instances:\", len(balanced_data))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWCRSwL6NbYQ",
        "outputId": "e1e3ab09-023d-4a75-c441-a3b3d2bc3951"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Après imputation\n",
            "         rr_type unique_ttl longest_word                               sld\n",
            "0        {'PTR'}     [1, 1]        sport                       sahifasport\n",
            "1        {'PTR'}     [1, 1]            2                               192\n",
            "2        {'PTR'}     [1, 1]            2                               192\n",
            "3        {'PTR'}     [1, 1]            A  EJFDEBFEEBFACACACACACACACACACAAA\n",
            "4        {'PTR'}     [1, 1]            2                               192\n",
            "...          ...        ...          ...                               ...\n",
            "1294787  {'PTR'}     [1, 1]            2                               192\n",
            "1294788  {'PTR'}     [1, 1]            4                               224\n",
            "1294789  {'PTR'}     [1, 1]            4                               224\n",
            "1294790  {'PTR'}     [1, 1]            2                               192\n",
            "1294791  {'PTR'}     [1, 1]            4                               224\n",
            "\n",
            "[1294792 rows x 4 columns]\n",
            "Taille totale des caractéristiques catégorielles après imputation : (1294792, 4)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Vérification des colonnes vides\n",
        "if X_categorical.isnull().any().any():\n",
        "    # Imputer les valeurs manquantes pour les caractéristiques catégorielles\n",
        "    categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
        "    X_categorical_imputed = pd.DataFrame(categorical_imputer.fit_transform(X_categorical), columns=X_categorical.columns)\n",
        "\n",
        "    # Afficher le DataFrame avec les valeurs imputées\n",
        "    print(\"Après imputation\")\n",
        "    print(X_categorical_imputed)\n",
        "\n",
        "    total_size_categorical = X_categorical_imputed.shape\n",
        "\n",
        "    print(\"Taille totale des caractéristiques catégorielles après imputation :\", total_size_categorical)\n",
        "\n",
        "else:\n",
        "    print(\"Pas de valeurs manquantes dans les caractéristiques catégorielles. Aucune imputation nécessaire.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Taille totale des caracteristiques numeriques apres preprocessing : (1294792, 12)\n"
          ]
        }
      ],
      "source": [
        "########### CONTINUER L'EXECUTION ICI ###########\n",
        "\n",
        "############ je continue ici ###################\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Imputer les valeurs manquantes pour les caractéristiques numériques\n",
        "\n",
        "# Imputer les valeurs manquantes pour les caractéristiques numériques\n",
        "numerical_imputer = SimpleImputer(strategy='mean')\n",
        "X_numerical_imputed = pd.DataFrame(numerical_imputer.fit_transform(X_numerical), columns=X_numerical.columns)\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "#prepocessing des features numeriques soit  avec le  LabelEncoder soit le MinMaxScaler()\n",
        "\n",
        "# Sélection des fonctionnalités numériques\n",
        "\n",
        "# numeric_features = X_numerical_imputed[numeric_imputed_list] ## cas ou je veux selectionné certains features\n",
        "\n",
        "# Création d'un scaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Ajustement du scaler aux données\n",
        "scaler.fit(X_numerical_imputed)\n",
        "\n",
        "# Transformation des fonctionnalités numériques\n",
        "scaled_numeric = scaler.transform(X_numerical_imputed)\n",
        "\n",
        "# Apres transformation Création d' un DataFrame à partir des valeurs transformées\n",
        "\n",
        "scaled_df = pd.DataFrame(scaled_numeric, columns=X_numerical_imputed.columns)\n",
        "\n",
        "\n",
        "total_size = scaled_df.shape\n",
        "\n",
        "print(\"Taille totale des caracteristiques numeriques apres preprocessing :\", total_size)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yr_pMknkNjas",
        "outputId": "1294f58c-1810-4bd3-c3c5-c29c66475a80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Longueur maximale du vecteur : 21\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "X_copy = X_categorical_imputed.copy()\n",
        "\n",
        "\n",
        "# Appliquer une tokenisation à chaque colonne catégorielle\n",
        "for feature in X_categorical_imputed.columns.tolist():\n",
        "    X_copy[feature] = X_copy[feature].astype(str)\n",
        "\n",
        "\n",
        "# Combinez les colonnes catégorielles dans une colonne 'combined_text'\n",
        "\n",
        "X_copy['combined_text'] = X_copy[X_categorical_imputed.columns.tolist()].apply(lambda row: ' '.join(row), axis=1)\n",
        "\n",
        "\n",
        "# Tokenisation\n",
        "tokenizer = Tokenizer(num_words=100, filters=' ', split=' ')\n",
        "tokenizer.fit_on_texts(X_copy['combined_text'])\n",
        "tokens = tokenizer.texts_to_sequences(X_copy['combined_text'])\n",
        "\n",
        "# Calcul de la longueur maximale du vecteur\n",
        "max_sequence_length = max(len(seq) for seq in tokens)\n",
        "\n",
        "\n",
        "### PAS BESOIN D'EXECUTER CE CECI  CAR ma machine ne dispose pas d'assez de ressources #####\n",
        "\n",
        "# Ajout des colonnes tokenisées au DataFrame\n",
        "# for i in range(1, max_sequence_length + 1):\n",
        "    # X_copy[f'token_{i}'] = [seq[i - 1] if len(seq) >= i else 0 for seq in tokens]\n",
        "\n",
        "# Suppression des colonnes originales et la colonne temporaire 'combined_text'\n",
        "# X_copy.drop(columns=X_categorical_imputed.columns.tolist() + ['combined_text'], inplace=True)\n",
        "\n",
        "##################### End ##############################################\n",
        "\n",
        "# Afficher les tokens et les longueurs de séquence\n",
        "# print(tokens)\n",
        "\n",
        "\n",
        "# Affichage de la longueur maximale\n",
        "print(f\"Longueur maximale du vecteur : {max_sequence_length}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Taille réelle du vocabulaire: 42111\n"
          ]
        }
      ],
      "source": [
        "# Calculer la taille du vocabulaire réel\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Ajoutez 1 pour tenir compte du padding\n",
        "\n",
        "# Afficher la taille du vocabulaire\n",
        "print(\"Taille réelle du vocabulaire:\", vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "ayB987TtNm35",
        "outputId": "87ac341c-6643-4d4e-ee07-873b406c7827"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "mean_length = np.mean(max_sequence_length)\n",
        "max_length = np.max(max_sequence_length)\n",
        "min_length = np.min(max_sequence_length)\n",
        "std_dev = np.std(max_sequence_length)\n",
        "\n",
        "# Visualisation de la distribution des longueurs des séquences\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(max_sequence_length, bins=30)\n",
        "plt.xlabel('Longueur de Séquence')\n",
        "plt.ylabel('Nombre de Séquences')\n",
        "plt.title('Distribution des Longueurs des Séquences')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Taille réelle du vocabulaire: 42111\n"
          ]
        }
      ],
      "source": [
        "# Calculer la taille du vocabulaire réel\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Ajoutez 1 pour tenir compte du padding\n",
        "\n",
        "# Afficher la taille du vocabulaire\n",
        "print(\"Taille réelle du vocabulaire:\", vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "g7Tz55i-Nvly"
      },
      "outputs": [],
      "source": [
        "# Hyperparamètres et dimensions des données*\n",
        "taille_num_features = scaled_df.shape[1]\n",
        "taille_text_features = max_sequence_length # je donne la taille max parmi les longueur des sequences\n",
        "vocab_size = vocab_size ### ici vu que j'utilise la tokenisation keras la taille du vocabulaires est en realaite le paramtre ['num_word] passer a mon tokeniser donc inutile cette ligne \n",
        "embedding_dim = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ey7t0eviNx-_",
        "outputId": "67b98ddf-0bc4-4eb3-a47d-b3267d14bc63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 12)]         0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 21)]         0           []                               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 256)          3328        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 21, 128)      5390208     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 128)          32896       ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 2688)         0           ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 2816)         0           ['dense_1[0][0]',                \n",
            "                                                                  'flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_21 (Dropout)           (None, 2816)         0           ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dense_32 (Dense)               (None, 64)           180288      ['dropout_21[0][0]']             \n",
            "                                                                                                  \n",
            " dense_33 (Dense)               (None, 32)           2080        ['dense_32[0][0]']               \n",
            "                                                                                                  \n",
            " dense_34 (Dense)               (None, 16)           528         ['dense_33[0][0]']               \n",
            "                                                                                                  \n",
            " dense_35 (Dense)               (None, 4)            68          ['dense_34[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,609,396\n",
            "Trainable params: 5,609,396\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Entrées\n",
        "input_num = tf.keras.layers.Input(shape=(taille_num_features,))\n",
        "input_text = tf.keras.layers.Input(shape=(taille_text_features,))\n",
        "\n",
        "\n",
        "# Branches du modèle\n",
        "# Branche numérique - FFN\n",
        "\n",
        "num_branch = tf.keras.layers.Dense(256, activation='relu')(input_num)\n",
        "num_branch = tf.keras.layers.Dense(128, activation='relu')(num_branch)\n",
        "\n",
        "\n",
        "# Branche textuelle - Embedding + Transformer (Un block)\n",
        "\n",
        "text_branch = Embedding(vocab_size, embedding_dim, input_length=taille_text_features)(input_text)\n",
        "\n",
        "mask_inputs = masque_remplissage(input_text)\n",
        "\n",
        "out_seq = Encodeur(\n",
        "            n_layers=5,\n",
        "            d_model=128,\n",
        "            num_heads=2,\n",
        "            middle_units=256,\n",
        "            max_seq_len=taille_text_features)([text_branch, mask_inputs])\n",
        "# out_seq = GlobalAveragePooling1D()(out_seq)\n",
        "out_seq = Dropout(0.2)(out_seq)\n",
        "\n",
        "# Fusion des branches\n",
        "\n",
        "flattened_text_branch = tf.keras.layers.Flatten()(text_branch) # je remodelise les dimension\n",
        "merged = tf.keras.layers.concatenate([num_branch, flattened_text_branch])\n",
        "\n",
        "\n",
        "# Couches supplémentaires après la fusion\n",
        "merged = tf.keras.layers.Dropout(0.2)(merged)\n",
        "merged = tf.keras.layers.Dense(64, activation='relu')(merged)\n",
        "merged = tf.keras.layers.Dense(32, activation='relu')(merged)\n",
        "merged = tf.keras.layers.Dense(16, activation='relu')(merged)\n",
        "\n",
        "output = tf.keras.layers.Dense(4, activation='softmax')(merged)\n",
        "\n",
        "\n",
        "# Création et compilation du modèle\n",
        "model = Model(inputs=[input_num, input_text], outputs=output)\n",
        "\n",
        "opt = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3rqf694OHtl",
        "outputId": "525f70d5-80e3-4547-e416-44cd19f7f166"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of data_num: (1294792, 12)\n",
            "Shape of data_text: (1294792, 21)\n",
            "Shape of labels: (1294792,)\n",
            "[3 2 2 ... 0 0 1]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "\n",
        "# Entrées pour l'entraînement\n",
        "data_num = scaled_df\n",
        "data_text = pad_sequences(tokens, maxlen=max_length,padding='post')\n",
        "\n",
        "# Assurez-vous que les données numériques sont correctes\n",
        "print(\"Shape of data_num:\", data_num.shape)\n",
        "\n",
        "# Assurez-vous que les données textuelles sont correctes après le rembourrage\n",
        "print(\"Shape of data_text:\", data_text.shape)\n",
        "\n",
        "# Assurez-vous que les étiquettes sont correctes\n",
        "print(\"Shape of labels:\", y.shape)\n",
        "\n",
        "# NB utiliser le resultat obtenu pour modifier les tailles ou dimension de mes entrées definie plus haut\n",
        "\n",
        "\n",
        "# 6. Encodage des étiquettes\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "print(y_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train_numerical\n",
            "(426745, 12)\n",
            "X_train_categorical\n",
            "(426745, 21)\n",
            "y_train\n",
            "(426745,)\n",
            "X_test_numerical\n",
            "(106687, 12)\n",
            "X_test_categorical\n",
            "(106687, 21)\n",
            "y_test\n",
            "(106687,)\n",
            "\n",
            "\n",
            "(426745,)\n"
          ]
        }
      ],
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# # Diviser les données en ensembles d'entraînement et de test\n",
        "# X_train_numerical, X_test_numerical, X_train_categorical, X_test_categorical, y_train, y_test = train_test_split(data_num, data_text, y_encoded, test_size=0.20,random_state=42)\n",
        "\n",
        "# #X_train_num, X_val_num, X_train_cate, X_val_cate, y_train, y_val = train_test_split(X_train_numerical, X_train_categorical, y_train, test_size=0.10, random_state=42)\n",
        "\n",
        "\n",
        "# print(\"X_train_numerical\")\n",
        "# print(X_train_numerical.shape)\n",
        "# print(\"X_train_categorical\")\n",
        "# print(X_train_categorical.shape)\n",
        "# print(\"y_train\")\n",
        "# print(y_train.shape)\n",
        "# print(\"X_test_numerical\")\n",
        "# print(X_test_numerical.shape)\n",
        "# print(\"X_test_categorical\")\n",
        "# print(X_test_categorical.shape)\n",
        "# print(\"y_test\")\n",
        "# print(y_test.shape)\n",
        "\n",
        "# print(\"\\n\")\n",
        "\n",
        "# #print(X_train_num.shape)\n",
        "# #print(X_train_cate.shape)\n",
        "# print(y_train.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['heavy_attacks' 'heavy_bengnin' 'light_attacks' 'light_bengnin']\n"
          ]
        }
      ],
      "source": [
        "print(label_encoder.classes_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 906354 samples, validate on 194219 samples\n",
            "Epoch 1/10\n",
            "669504/906354 [=====================>........] - ETA: 11:12 - loss: 1.0979 - accuracy: 0.4094"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[24], line 14\u001b[0m\n\u001b[0;32m      9\u001b[0m X_train_num, X_val_num, X_train_cat, X_val_cat, y_train, y_val \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m     10\u001b[0m     X_train_num, X_train_cat, y_train, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.15\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m0.85\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Entraîner le modèle avec les données d'entraînement et de validation\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_train_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_cat\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_val_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_cat\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\python install\\lib\\site-packages\\keras\\engine\\training_v1.py:856\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_call_args(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    855\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_training_loop(x)\n\u001b[1;32m--> 856\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\python install\\lib\\site-packages\\keras\\engine\\training_arrays_v1.py:734\u001b[0m, in \u001b[0;36mArrayLikeTrainingLoop.fit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    729\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`validation_steps` should not be specified if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    730\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`validation_data` is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    731\u001b[0m         )\n\u001b[0;32m    732\u001b[0m     val_x, val_y, val_sample_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 734\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    736\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_targets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_sample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msteps_per_epoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\python install\\lib\\site-packages\\keras\\engine\\training_arrays_v1.py:421\u001b[0m, in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    416\u001b[0m callbacks\u001b[38;5;241m.\u001b[39m_call_batch_hook(\n\u001b[0;32m    417\u001b[0m     mode, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch_index, batch_logs\n\u001b[0;32m    418\u001b[0m )\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# Get outputs.\u001b[39;00m\n\u001b[1;32m--> 421\u001b[0m batch_outs \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mins_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_outs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    423\u001b[0m     batch_outs \u001b[38;5;241m=\u001b[39m [batch_outs]\n",
            "File \u001b[1;32mc:\\python install\\lib\\site-packages\\keras\\backend.py:4608\u001b[0m, in \u001b[0;36mGraphExecutionFunction.__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   4598\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4599\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   4600\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m feed_arrays \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feed_arrays\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4604\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m session \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\n\u001b[0;32m   4605\u001b[0m ):\n\u001b[0;32m   4606\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n\u001b[1;32m-> 4608\u001b[0m fetched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marray_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4609\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_fetch_callbacks(fetched[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetches) :])\n\u001b[0;32m   4610\u001b[0m output_structure \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[0;32m   4611\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_structure,\n\u001b[0;32m   4612\u001b[0m     fetched[: \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs)],\n\u001b[0;32m   4613\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   4614\u001b[0m )\n",
            "File \u001b[1;32mc:\\python install\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1481\u001b[0m, in \u001b[0;36mBaseSession._Callable.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1479\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1480\u001b[0m   run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1481\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRunCallable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1482\u001b[0m \u001b[43m                                         \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1483\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1484\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[0;32m   1485\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Diviser les données en ensembles d'entraînement et de test (15% pour le test)\n",
        "X_train_num, X_test_num, X_train_cat, X_test_cat, y_train, y_test = train_test_split(\n",
        "    data_num, data_text, y_encoded, test_size=0.15, random_state=42\n",
        ")\n",
        "\n",
        "# Diviser l'ensemble d'entraînement en sous-ensembles d'entraînement et de validation (15% pour la validation)\n",
        "X_train_num, X_val_num, X_train_cat, X_val_cat, y_train, y_val = train_test_split(\n",
        "    X_train_num, X_train_cat, y_train, test_size=0.15 / 0.85, random_state=42\n",
        ")\n",
        "\n",
        "# Entraîner le modèle avec les données d'entraînement et de validation\n",
        "history = model.fit(\n",
        "    [X_train_num, X_train_cat], y_train,\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    validation_data=([X_val_num, X_val_cat], y_val)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "##################### NE PAS EXECUTER ################\n",
        "\n",
        "#################### je passe les donnees par lots pour accelerer l'entrainement et economiser en memoire ########\n",
        "### contraiment a la methode [model.fit(qui va charger tout les donnee en memoire durant le le training)]\n",
        "\n",
        "\n",
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, X_num, X_text, y, batch_size):\n",
        "        self.X_num = X_num\n",
        "        self.X_text = X_text\n",
        "        self.y = y\n",
        "        self.batch_size = batch_size\n",
        "        self.indexes = np.arange(len(self.X_num))\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.X_num) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        start_index = index * self.batch_size\n",
        "        end_index = min((index + 1) * self.batch_size, len(self.X_num))\n",
        "        batch_X_num = self.X_num[start_index:end_index]\n",
        "        batch_X_text = self.X_text[start_index:end_index]\n",
        "        batch_y = self.y[start_index:end_index]\n",
        "        return [batch_X_num, batch_X_text], batch_y\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Diviser les données en ensembles d'entraînement et de test\n",
        "X_train_numerical, X_test_numerical, X_train_categorical, X_test_categorical, y_train, y_test = train_test_split(data_num, data_text, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 128\n",
        "train_generator = DataGenerator(X_train_numerical, X_train_categorical, y_train, batch_size)\n",
        "validation_generator = DataGenerator(X_test_numerical, X_test_categorical, y_test, batch_size)\n",
        "\n",
        "\n",
        "#### je call le generatuer de donneee pour l'entrainement ########\n",
        "\n",
        "# Utilisation de fit() au lieu de fit_generator() (deprecated) ## doncj je dois remplcaer le fit_genrator par (fit())\n",
        "\n",
        "history = model.fit_generator(\n",
        "    generator=train_generator,\n",
        "    steps_per_epoch=len(X_train_numerical) // batch_size,\n",
        "    epochs=15,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=len(X_test_numerical) // batch_size\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FopsyeqtOSnX",
        "outputId": "d1e084ab-6c63-41a0-a28f-aa94e39f408a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 155456 samples, validate on 17273 samples\n",
            "Epoch 1/20\n",
            "155456/155456 [==============================] - ETA: 0s - loss: 1.1009 - accuracy: 0.4069"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\python install\\lib\\site-packages\\keras\\engine\\training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "155456/155456 [==============================] - 1022s 7ms/sample - loss: 1.1009 - accuracy: 0.4069 - val_loss: 1.0966 - val_accuracy: 0.4096\n",
            "Epoch 2/20\n",
            " 48512/155456 [========>.....................] - ETA: 11:51 - loss: 1.0965 - accuracy: 0.4090"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[23], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m##### cette methode est gourmenete etant donnee que jai pratiquement 1/2 million de donnee et seulememt 8 gb de ram ####\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m##### ce facon de proceder charge tout mes donnee en memoire durrant le trainig  ce qui n'est pas bon ; il faut utiliser un generateur  de donnee pour le training comme jai fais dans la cellule en haut ##\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_train_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_train_cate\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_val_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_val_cate\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\python install\\lib\\site-packages\\keras\\engine\\training_v1.py:856\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_call_args(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    855\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_training_loop(x)\n\u001b[1;32m--> 856\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\python install\\lib\\site-packages\\keras\\engine\\training_arrays_v1.py:734\u001b[0m, in \u001b[0;36mArrayLikeTrainingLoop.fit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    729\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`validation_steps` should not be specified if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    730\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`validation_data` is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    731\u001b[0m         )\n\u001b[0;32m    732\u001b[0m     val_x, val_y, val_sample_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 734\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    736\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_targets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_sample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msteps_per_epoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\python install\\lib\\site-packages\\keras\\engine\\training_arrays_v1.py:421\u001b[0m, in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    416\u001b[0m callbacks\u001b[38;5;241m.\u001b[39m_call_batch_hook(\n\u001b[0;32m    417\u001b[0m     mode, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch_index, batch_logs\n\u001b[0;32m    418\u001b[0m )\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# Get outputs.\u001b[39;00m\n\u001b[1;32m--> 421\u001b[0m batch_outs \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mins_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_outs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    423\u001b[0m     batch_outs \u001b[38;5;241m=\u001b[39m [batch_outs]\n",
            "File \u001b[1;32mc:\\python install\\lib\\site-packages\\keras\\backend.py:4608\u001b[0m, in \u001b[0;36mGraphExecutionFunction.__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   4598\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4599\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   4600\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m feed_arrays \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feed_arrays\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4604\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m session \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\n\u001b[0;32m   4605\u001b[0m ):\n\u001b[0;32m   4606\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n\u001b[1;32m-> 4608\u001b[0m fetched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marray_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4609\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_fetch_callbacks(fetched[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetches) :])\n\u001b[0;32m   4610\u001b[0m output_structure \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[0;32m   4611\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_structure,\n\u001b[0;32m   4612\u001b[0m     fetched[: \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs)],\n\u001b[0;32m   4613\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   4614\u001b[0m )\n",
            "File \u001b[1;32mc:\\python install\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1481\u001b[0m, in \u001b[0;36mBaseSession._Callable.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1479\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1480\u001b[0m   run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1481\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRunCallable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1482\u001b[0m \u001b[43m                                         \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1483\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1484\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[0;32m   1485\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "##### cette methode est gourmenete etant donnee que jai pratiquement 1/2 million de donnee et seulememt 8 gb de ram ####\n",
        "##### ce facon de proceder charge tout mes donnee en memoire durrant le trainig  ce qui n'est pas bon ; il faut utiliser un generateur  de donnee pour le training comme jai fais dans la cellule en haut ##\n",
        "history = model.fit([X_train_num,X_train_cate], y_train, epochs=20, batch_size=32, validation_data=([X_val_num,X_val_cate], y_val))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "pip install keras-tuner\n",
        "\n",
        "########## POUR LES HYPERPARAMETRE TUNING #############\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reloading Tuner from hyperband\\text_numerical_model_tuning\\tuner0.json\n",
            "\n",
            "Search: Running Trial #3\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "320               |320               |num_units_1\n",
            "0.1               |0.1               |num_dropout_1\n",
            "256               |256               |num_units_2\n",
            "0.5               |0.5               |num_dropout_2\n",
            "512               |512               |embedding_dim\n",
            "5                 |5                 |n_layers\n",
            "4                 |4                 |num_heads\n",
            "128               |128               |middle_units\n",
            "0.2               |0.2               |transformer_dropout\n",
            "256               |256               |merged_units_1\n",
            "0.5               |0.5               |merged_dropout_1\n",
            "64                |64                |merged_units_2\n",
            "0.1               |0.1               |merged_dropout_2\n",
            "0.0003033         |0.0003033         |learning_rate\n",
            "2                 |2                 |tuner/epochs\n",
            "0                 |0                 |tuner/initial_epoch\n",
            "2                 |2                 |tuner/bracket\n",
            "0                 |0                 |tuner/round\n",
            "\n",
            "Train on 533433 samples, validate on 177812 samples\n",
            "Epoch 1/2\n",
            " 24640/533433 [>.............................] - ETA: 9:12:21 - loss: 1.0392 - accuracy: 0.6232"
          ]
        }
      ],
      "source": [
        "import keras_tuner as kt\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "taille_num_features = taille_num_features  \n",
        "taille_text_features = taille_text_features  \n",
        "vocab_size = vocab_size  \n",
        "    \n",
        "\n",
        "def build_model(hp):\n",
        "    \n",
        "    input_num = Input(shape=(taille_num_features,))\n",
        "    input_text = Input(shape=(taille_text_features,))\n",
        "\n",
        "    # Branche numérique - FFN\n",
        "    num_branch = Dense(units=hp.Int('num_units_1', min_value=64, max_value=512, step=64), activation='relu')(input_num)\n",
        "    num_branch = BatchNormalization()(num_branch)\n",
        "    num_branch = Dropout(rate=hp.Float('num_dropout_1', min_value=0.1, max_value=0.5, step=0.1))(num_branch)\n",
        "    num_branch = Dense(units=hp.Int('num_units_2', min_value=64, max_value=256, step=64), activation='relu')(num_branch)\n",
        "    num_branch = BatchNormalization()(num_branch)\n",
        "    num_branch = Dropout(rate=hp.Float('num_dropout_2', min_value=0.1, max_value=0.5, step=0.1))(num_branch)\n",
        "\n",
        "    # Branche textuelle - Embedding + Transformer\n",
        "    embedding_dim = hp.Choice('embedding_dim', values=[128, 256, 512])\n",
        "    text_branch = Embedding(vocab_size, embedding_dim, input_length=taille_text_features)(input_text)\n",
        "    mask_inputs = masque_remplissage(input_text)\n",
        "    out_seq = Encodeur(\n",
        "                n_layers=hp.Int('n_layers', 1, 6, step=1),\n",
        "                d_model=embedding_dim,\n",
        "                num_heads=hp.Choice('num_heads', values=[4, 8, 16]),\n",
        "                middle_units=hp.Int('middle_units', 128, 512, step=128),\n",
        "                max_seq_len=taille_text_features)([text_branch, mask_inputs])\n",
        "    out_seq = GlobalAveragePooling1D()(out_seq)\n",
        "    out_seq = Dropout(rate=hp.Float('transformer_dropout', 0.1, 0.5, step=0.1))(out_seq)\n",
        "\n",
        "    merged = concatenate([num_branch, out_seq])\n",
        "\n",
        "    # Couches supplémentaires après la fusion\n",
        "    merged = Dense(units=hp.Int('merged_units_1', 64, 256, step=64), activation='relu')(merged)\n",
        "    merged = BatchNormalization()(merged)\n",
        "    merged = Dropout(rate=hp.Float('merged_dropout_1', 0.1, 0.5, step=0.1))(merged)\n",
        "    merged = Dense(units=hp.Int('merged_units_2', 32, 128, step=32), activation='relu')(merged)\n",
        "    merged = BatchNormalization()(merged)\n",
        "    merged = Dropout(rate=hp.Float('merged_dropout_2', 0.1, 0.5, step=0.1))(merged)\n",
        "    merged = Dense(32, activation='relu')(merged)\n",
        "\n",
        "    output = Dense(4, activation='softmax')(merged)\n",
        "\n",
        "    model = Model(inputs=[input_num, input_text], outputs=output)\n",
        "\n",
        "    opt = Adam(learning_rate=hp.Float('learning_rate', 1e-4, 1e-2, sampling='log'))\n",
        "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Définir la recherche d'hyperparamètres\n",
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=10,\n",
        "    factor=3,\n",
        "    directory='hyperband',\n",
        "    project_name='text_numerical_model_tuning'\n",
        ")\n",
        "\n",
        "# Diviser les données en ensembles d'entraînement et de validation\n",
        "X_train_numerical, X_val_numerical, X_train_categorical, X_val_categorical, y_train, y_val = train_test_split(\n",
        "    data_num, data_text, y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Préparation des  données pour le tuner\n",
        "train_data = [X_train_numerical, X_train_categorical]\n",
        "val_data = [X_val_numerical, X_val_categorical]\n",
        "\n",
        "# Lancer la recherche d'hyperparamètres\n",
        "tuner.search(train_data, y_train, epochs=10, validation_data=(val_data, y_val), batch_size=32)\n",
        "\n",
        "# résultats\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(f\"\"\"\n",
        "Les meilleurs hyperparamètres sont :\n",
        "- embedding_dim : {best_hps.get('embedding_dim')}\n",
        "- num_units_1 : {best_hps.get('num_units_1')}\n",
        "- num_dropout_1 : {best_hps.get('num_dropout_1')}\n",
        "- num_units_2 : {best_hps.get('num_units_2')}\n",
        "- num_dropout_2 : {best_hps.get('num_dropout_2')}\n",
        "- n_layers : {best_hps.get('n_layers')}\n",
        "- num_heads : {best_hps.get('num_heads')}\n",
        "- middle_units : {best_hps.get('middle_units')}\n",
        "- transformer_dropout : {best_hps.get('transformer_dropout')}\n",
        "- merged_units_1 : {best_hps.get('merged_units_1')}\n",
        "- merged_dropout_1 : {best_hps.get('merged_dropout_1')}\n",
        "- merged_units_2 : {best_hps.get('merged_units_2')}\n",
        "- merged_dropout_2 : {best_hps.get('merged_dropout_2')}\n",
        "- learning_rate : {best_hps.get('learning_rate')}\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Perte sur les données de test: 0.6193836101729409\n",
            "Précision sur les données de test: 0.80855\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\python install\\lib\\site-packages\\keras\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[7.9097688e-01 8.4833212e-02 1.2417506e-01 1.4918560e-05]\n",
            " [7.9097688e-01 8.4833212e-02 1.2417506e-01 1.4918560e-05]\n",
            " [7.9097688e-01 8.4833212e-02 1.2417506e-01 1.4918560e-05]\n",
            " ...\n",
            " [7.9097688e-01 8.4833212e-02 1.2417506e-01 1.4918560e-05]\n",
            " [7.9097688e-01 8.4833212e-02 1.2417506e-01 1.4918560e-05]\n",
            " [7.9097688e-01 8.4833212e-02 1.2417506e-01 1.4918560e-05]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\python install\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\python install\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\python install\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rapport de classification :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      1.00      0.89    108374\n",
            "           1       0.00      0.00      0.00     10699\n",
            "           2       0.00      0.00      0.00     14962\n",
            "\n",
            "    accuracy                           0.81    134035\n",
            "   macro avg       0.27      0.33      0.30    134035\n",
            "weighted avg       0.65      0.81      0.72    134035\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "# Évaluation du modèle sur les données de test\n",
        "evaluation_results = model.evaluate([X_test_numerical, X_test_categorical], y_test)\n",
        "\n",
        "# print(f'Accuracy: {accuracy}, Loss: {loss}')\n",
        "print(\"Perte sur les données de test:\", evaluation_results[0])\n",
        "print(\"Précision sur les données de test:\", evaluation_results[1])\n",
        "\n",
        "#on effectue les prediction sur les donnees de test\n",
        "\n",
        "y_pred = model.predict([X_test_numerical, X_test_categorical])\n",
        "\n",
        "print(y_pred)\n",
        "\n",
        "\n",
        "# Convertir les indices des classes prédites en étiquettes\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Afficher le rapport de classification\n",
        "class_report = classification_report(y_test, y_pred_classes)\n",
        "print(\"Rapport de classification :\\n\", class_report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Extraction des métriques d'entraînement\n",
        "loss = history.history['loss']\n",
        "accuracy = history.history['accuracy']\n",
        "val_loss = history.history['val_loss']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "# Affichage des courbes de perte et d'exactitude séparément\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "# Affichage des courbes d'apprentissage et de validation\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot de la perte d'entraînement et de la perte de validation\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation loss')\n",
        "plt.title('Courbe de Perte')\n",
        "plt.xlabel('Épochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "# Plot de la précision d'entraînement et de la précision de validation\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation accuracy')\n",
        "plt.title('Courbe de Précision')\n",
        "plt.xlabel('Épochs')\n",
        "plt.ylabel('Précision')\n",
        "plt.legend()\n",
        "\n",
        "# Afficher les deux sous-plots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
        "\n",
        "\n",
        "\n",
        "# Matrice de confusion\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
        "# class_names = ['heavy attacks', 'heavy bengnin', 'light attacks', 'light bengnin']\n",
        "\n",
        "class_names = ['heavy_attacks', 'heavy_bengnin', 'light_attacks', 'light_bengnin']\n",
        "\n",
        "df_cm = pd.DataFrame(conf_matrix, index=class_names, columns=class_names)\n",
        "\n",
        "# Afficher la matrice de confusion avec seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sn.heatmap(df_cm, annot=True, fmt='g', cmap='Blues', cbar=False)\n",
        "plt.title('Matrice de Confusion')\n",
        "plt.xlabel('Prédictions')\n",
        "plt.ylabel('Vraies valeurs')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
