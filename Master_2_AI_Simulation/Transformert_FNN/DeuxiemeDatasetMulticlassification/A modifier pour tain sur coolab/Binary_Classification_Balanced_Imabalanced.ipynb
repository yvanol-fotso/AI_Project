{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, classification_report\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, Embedding, GlobalAveragePooling1D, Dropout, Dense\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "from TransformerComplet import *\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, Input, Concatenate, MultiHeadAttention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des fichiers CSV\n",
    "# Chargement des fichiers CSV\n",
    "benin_data = pd.read_csv(\"../../data/Bell_DNS Dataset/features_domain_benign_csv.csv\")\n",
    "malware_data = pd.read_csv(\"../../data/Bell_DNS Dataset/features-domain_Malware.csv\")\n",
    "phishing_data = pd.read_csv(\"../../data/Bell_DNS Dataset/features-domain_phishing.csv\")\n",
    "spam_data = pd.read_csv(\"../../data/Bell_DNS Dataset/features-domain_Spam.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Size Malicioux data\n",
      "class\n",
      "malicioux    13011\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      " Size Bengnin data\n",
      "class\n",
      "bengnin    20000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      " Size all data\n",
      "class\n",
      "bengnin      20000\n",
      "malicioux    13011\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      " Size all data shape\n",
      "(33011, 36)\n"
     ]
    }
   ],
   "source": [
    "##################################################################\n",
    "#################################################################\n",
    "################## Equilibrer #################################\n",
    "\n",
    "# Prélèvement d'échantillons pour l'ensemble équilibré\n",
    "\n",
    "# Échantillons bénins équilibrés : 20,000\n",
    "benign_balanced_samples = benin_data.sample(20000, random_state=42)\n",
    "benign_balanced_samples['class'] = 'bengnin'\n",
    "\n",
    "balanced_spam = spam_data.sample(4337, random_state=42)\n",
    "balanced_malware = malware_data.sample(4337, random_state=42)\n",
    "balanced_phishing = phishing_data.sample(4337, random_state=42)\n",
    "\n",
    "# Concaténation des échantillons équilibrés\n",
    "malicioux_balanced_samples = pd.concat([balanced_spam, balanced_malware, balanced_phishing],axis=0, ignore_index=True)\n",
    "malicioux_balanced_samples['class'] = 'malicioux'\n",
    "\n",
    "balanced_all_data_resampled = pd.concat([malicioux_balanced_samples,benign_balanced_samples],axis=0, ignore_index=True)\n",
    "\n",
    "print(\" Size Malicioux data\")\n",
    "print(malicioux_balanced_samples['class'].value_counts())\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\" Size Bengnin data\")\n",
    "print(benign_balanced_samples['class'].value_counts())\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\" Size all data\")\n",
    "print(balanced_all_data_resampled['class'].value_counts())\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\" Size all data shape\")\n",
    "print(balanced_all_data_resampled.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Size Malicioux data\n",
      "class\n",
      "malicioux    13011\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      " Size Bengnin data\n",
      "class\n",
      "bengnin    400000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      " Size all data\n",
      "class\n",
      "bengnin      400000\n",
      "malicioux     13011\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      " Size all data shape\n",
      "(413011, 36)\n"
     ]
    }
   ],
   "source": [
    "##################################################################\n",
    "#################################################################\n",
    "################## desquilibrer #################################\n",
    "\n",
    "# Échantillons bénins déséquilibrés : 400,000\n",
    "# benign_imbalanced_samples = benin_data.sample(400000, random_state=42)\n",
    "\n",
    "benign_imbalanced_samples = benin_data.sample(400000, replace=True, random_state=42)\n",
    "benign_imbalanced_samples['class'] = 'bengnin'\n",
    "\n",
    "balanced_spam = spam_data.sample(4337, random_state=42)\n",
    "balanced_malware = malware_data.sample(4337, random_state=42)\n",
    "balanced_phishing = phishing_data.sample(4337, random_state=42)\n",
    "\n",
    "\n",
    "# Concaténation des échantillons équilibrés\n",
    "malicioux_balanced_samples = pd.concat([balanced_spam, balanced_malware, balanced_phishing],axis=0, ignore_index=True)\n",
    "malicioux_balanced_samples['class'] = 'malicioux'\n",
    "\n",
    "imbalanced_all_data_resampled = pd.concat([malicioux_balanced_samples,benign_imbalanced_samples],axis=0, ignore_index=True)\n",
    "\n",
    "print(\" Size Malicioux data\")\n",
    "print(malicioux_balanced_samples['class'].value_counts())\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\" Size Bengnin data\")\n",
    "print(benign_imbalanced_samples['class'].value_counts())\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\" Size all data\")\n",
    "print(imbalanced_all_data_resampled['class'].value_counts())\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\" Size all data shape\")\n",
    "print(imbalanced_all_data_resampled.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33011, 13)\n",
      "(33011, 22)\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 33011 entries, 0 to 33010\n",
      "Series name: class\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "33011 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 258.0+ KB\n",
      "None\n",
      "\n",
      "\n",
      "(413011, 13)\n",
      "(413011, 22)\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 413011 entries, 0 to 413010\n",
      "Series name: class\n",
      "Non-Null Count   Dtype \n",
      "--------------   ----- \n",
      "413011 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 3.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Séparer les caractéristiques numériques et catégorielles (Balanced /Imbalanced)\n",
    "\n",
    "X_numerical_balanced = balanced_all_data_resampled.select_dtypes(include=['int64', 'float64'])\n",
    "X_categorical_balanced = balanced_all_data_resampled.select_dtypes(exclude='number').drop('class', axis=1)\n",
    "y_balanced = balanced_all_data_resampled['class']\n",
    "\n",
    "print(X_numerical_balanced.shape)\n",
    "print(X_categorical_balanced.shape)\n",
    "print(y_balanced.info())\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "X_numerical_imbalanced = imbalanced_all_data_resampled.select_dtypes(include=['int64', 'float64'])\n",
    "X_categorical_imbalanced = imbalanced_all_data_resampled.select_dtypes(exclude='number').drop('class', axis=1)\n",
    "y_imbalanced = imbalanced_all_data_resampled['class']\n",
    "\n",
    "print(X_numerical_imbalanced.shape)\n",
    "print(X_categorical_imbalanced.shape)\n",
    "print(y_imbalanced.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Imputer les valeurs manquantes pour les caractéristiques numériques\n",
    "\n",
    "# Imputer les valeurs manquantes pour les caractéristiques numériques\n",
    "numerical_imputer = SimpleImputer(strategy='mean')\n",
    "X_numerical_balanced_imputed = pd.DataFrame(numerical_imputer.fit_transform(X_numerical_balanced), columns=X_numerical_balanced.columns)\n",
    "X_numerical_imbalanced_imputed = pd.DataFrame(numerical_imputer.fit_transform(X_numerical_imbalanced), columns=X_numerical_imbalanced.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Imputer les valeurs manquantes pour les caractéristiques catégorielles\n",
    "\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "categorical_balanced_imputed = pd.DataFrame(categorical_imputer.fit_transform(X_categorical_balanced),columns=X_categorical_balanced.columns)\n",
    "categorical_imbalanced_imputed = pd.DataFrame(categorical_imputer.fit_transform(X_categorical_imbalanced),columns=X_categorical_imbalanced.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['subdomain', 'len', 'numeric_percentage', 'entropy', 'dec_8', 'dec_32', 'oc_8', 'oc_32', 'hex_8', 'hex_32', 'puny_coded', 'Alexa_Rank', 'Page_Rank']\n"
     ]
    }
   ],
   "source": [
    "############# Ne plus executer #################################\n",
    "\n",
    "numeric_balanced_imputed_list = X_numerical_balanced_imputed.columns.tolist()\n",
    "numeric_imbalanced_imputed_list = X_numerical_imbalanced_imputed.columns.tolist()\n",
    "\n",
    "print(numeric_balanced_imputed_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille totale des caracteristiques numeriques apres preprocessing : (33011, 13)\n",
      "Taille totale des caracteristiques numeriques apres preprocessing : (413011, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "#prepocessing des features numeriques soit  avec le  LabelEncoder soit le MinMaxScaler()\n",
    "\n",
    "# Sélection des fonctionnalités numériques\n",
    "\n",
    "# numeric_features = X_numerical_imputed[numeric_imputed_list] ## cas ou je veux selectionné certains features\n",
    "\n",
    "# Création d'un scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Ajustement du scaler aux données\n",
    "scaler.fit(X_numerical_balanced_imputed)\n",
    "scaler.fit(X_numerical_imbalanced_imputed)\n",
    "\n",
    "# Transformation des fonctionnalités numériques\n",
    "scaled_numeric_balanced = scaler.transform(X_numerical_balanced_imputed)\n",
    "scaled_numeric_imbalanced = scaler.transform(X_numerical_imbalanced_imputed)\n",
    "\n",
    "# Apres transformation Création d' un DataFrame à partir des valeurs transformées\n",
    "\n",
    "scaled_df_balanced = pd.DataFrame(scaled_numeric_balanced, columns=X_numerical_balanced_imputed.columns)\n",
    "scaled_df_imbalanced = pd.DataFrame(scaled_numeric_imbalanced, columns=X_numerical_imbalanced_imputed.columns)\n",
    "\n",
    "\n",
    "total_size_balanced = scaled_df_balanced.shape\n",
    "total_size_imbalanced = scaled_df_imbalanced.shape\n",
    "\n",
    "print(\"Taille totale des caracteristiques numeriques apres preprocessing :\", total_size_balanced)\n",
    "print(\"Taille totale des caracteristiques numeriques apres preprocessing :\", total_size_imbalanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Domain_Age', 'sld', 'Emails', 'Domain_Name', '3gram', 'distance_from_bad_words', 'Country', 'typos', 'Registrar', '2gram', 'State', '1gram', 'obfuscate_at_sign', 'Registrant_Name', 'char_distribution', 'shortened', 'longest_word', 'Name_Server_Count', 'Creation_Date_Time', 'Organization', 'tld', 'Unnamed: 34']\n",
      "\n",
      "\n",
      "['Domain_Age', 'sld', 'Emails', 'Domain_Name', '3gram', 'distance_from_bad_words', 'Country', 'typos', 'Registrar', '2gram', 'State', '1gram', 'obfuscate_at_sign', 'Registrant_Name', 'char_distribution', 'shortened', 'longest_word', 'Name_Server_Count', 'Creation_Date_Time', 'Organization', 'tld', 'Unnamed: 34']\n",
      "\n",
      "\n",
      "(33011, 22)\n",
      "(413011, 22)\n"
     ]
    }
   ],
   "source": [
    "#############  executer #################################\n",
    "\n",
    "\n",
    "categorical_balanced_imputed_list = categorical_balanced_imputed.columns.tolist()\n",
    "categorical_imbalanced_imputed_list = categorical_imbalanced_imputed.columns.tolist()\n",
    "\n",
    "print(categorical_balanced_imputed_list)\n",
    "print(\"\\n\")\n",
    "print(categorical_imbalanced_imputed_list)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(categorical_balanced_imputed.shape)\n",
    "print(categorical_imbalanced_imputed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens_balanced:\n",
      "Longueur maximale du vecteur balanced : 117\n",
      "tokens_imbalanced:\n",
      "Longueur maximale du vecteur imbalanced : 108\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#Créer une copie du DataFrame pour éviter SettingWithCopyWarning\n",
    "\n",
    "X_copy_balanced = categorical_balanced_imputed.copy()  \n",
    "X_copy_imbalanced = categorical_imbalanced_imputed.copy()  \n",
    "\n",
    "# Appliquer une tokenisation à chaque colonne catégorielle\n",
    "for feature in categorical_balanced_imputed_list:\n",
    "    X_copy_balanced[feature] = X_copy_balanced[feature].astype(str)\n",
    "\n",
    "X_copy_balanced['combined_text'] = X_copy_balanced[categorical_balanced_imputed_list].apply(lambda row: ' '.join(row), axis=1)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=100, filters=' ', split=' ')\n",
    "tokenizer.fit_on_texts(X_copy_balanced['combined_text'])\n",
    "tokens_balanced = tokenizer.texts_to_sequences(X_copy_balanced['combined_text'])\n",
    "\n",
    "# Calcul de la longueur maximale du vecteur\n",
    "max_sequence_length_balanced = max(len(seq) for seq in tokens_balanced)\n",
    "\n",
    "\n",
    "#### Pas necessaire cas gourmanad en memoire pour mon pc ############\n",
    "####################################################################\n",
    "\n",
    "\n",
    "# Ajout des colonnes tokenisées au DataFrame\n",
    "# for i in range(1, max_sequence_length_balanced + 1):\n",
    "    # X_copy_balanced[f'token_{i}'] = [seq[i - 1] if len(seq) >= i else 0 for seq in tokens_balanced]\n",
    "\n",
    "# Suppression des colonnes originales et la colonne temporaire 'combined_text'\n",
    "# X_copy_balanced.drop(columns=categorical_balanced_imputed_list + ['combined_text'], inplace=True)\n",
    "\n",
    "###################################### Fin ####################################\n",
    "\n",
    "\n",
    "# Afficher les tokens_balanced et les longueurs de séquence\n",
    "print(\"tokens_balanced:\")\n",
    "# print(tokens_balanced)\n",
    "\n",
    "\n",
    "\n",
    "# Affichage de la longueur maximale\n",
    "print(f\"Longueur maximale du vecteur balanced : {max_sequence_length_balanced}\")\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "############################### Imbalanced ###################################\n",
    "\n",
    "# Appliquer une tokenisation à chaque colonne catégorielle\n",
    "for feature in categorical_balanced_imputed_list:\n",
    "    X_copy_imbalanced[feature] = X_copy_imbalanced[feature].astype(str)\n",
    "\n",
    "X_copy_imbalanced['combined_text'] = X_copy_imbalanced[categorical_balanced_imputed_list].apply(lambda row: ' '.join(row), axis=1)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=100, filters=' ', split=' ')\n",
    "tokenizer.fit_on_texts(X_copy_imbalanced['combined_text'])\n",
    "tokens_imbalanced = tokenizer.texts_to_sequences(X_copy_imbalanced['combined_text'])\n",
    "\n",
    "# Calcul de la longueur maximale du vecteur\n",
    "max_sequence_length_imbalanced = max(len(seq) for seq in tokens_imbalanced)\n",
    "\n",
    "\n",
    "#### Pas necessaire cas gourmanad en memoire pour mon pc ############\n",
    "####################################################################\n",
    "\n",
    "# Ajout des colonnes tokenisées au DataFrame\n",
    "# for i in range(1, max_sequence_length_imbalanced + 1):\n",
    "    # X_copy_imbalanced[f'token_{i}'] = [seq[i - 1] if len(seq) >= i else 0 for seq in tokens_imbalanced]\n",
    "\n",
    "# Suppression des colonnes originales et la colonne temporaire 'combined_text'\n",
    "# X_copy_imbalanced.drop(columns=categorical_balanced_imputed_list + ['combined_text'], inplace=True)\n",
    "\n",
    "###################################### Fin ####################################\n",
    "\n",
    "# Afficher les tokens_imbalanced et les longueurs de séquence\n",
    "print(\"tokens_imbalanced:\")\n",
    "# print(tokens_imbalanced)\n",
    "\n",
    "# Affichage de la longueur maximale\n",
    "print(f\"Longueur maximale du vecteur imbalanced : {max_sequence_length_imbalanced}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "############ affichage longueur  max \"balanced categorical feature\"\n",
    "\n",
    "mean_length = np.mean(max_sequence_length_balanced)\n",
    "max_length = np.max(max_sequence_length_balanced)\n",
    "min_length = np.min(max_sequence_length_balanced)\n",
    "std_dev = np.std(max_sequence_length_balanced)\n",
    "\n",
    "# Visualisation de la distribution des longueurs des séquences\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(max_sequence_length_balanced, bins=30)\n",
    "plt.xlabel('Longueur de Séquence')\n",
    "plt.ylabel('Nombre de Séquences')\n",
    "plt.title('Distribution des Longueurs des Séquences')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamètres et dimensions des données*\n",
    "taille_num_features_balanced = scaled_df_balanced.shape[1]\n",
    "taille_text_features_balanced = max_sequence_length_balanced   # je donne la taille max parmi les longueur des sequences \n",
    "embedding_dim = 256 #128  ## sa dimension ne doit pas depasser la valeur du [d_model dans l'encodeur] \n",
    "\n",
    "vocab_size = 2000\n",
    "taille_num_features_imbalanced = scaled_df_imbalanced.shape[1]\n",
    "taille_text_features_imbalanced = max_sequence_length_imbalanced   # je donne la taille max parmi les longueur des sequences \n",
    "embedding_dim = 256 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 13)]         0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 117)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 64)           896         ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 117, 256)     512000      ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 32)           2080        ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 29952)        0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 29984)        0           ['dense_3[0][0]',                \n",
      "                                                                  'flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_33 (Dropout)           (None, 29984)        0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_100 (Dense)              (None, 16)           479760      ['dropout_33[0][0]']             \n",
      "                                                                                                  \n",
      " dense_101 (Dense)              (None, 1)            17          ['dense_100[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 994,753\n",
      "Trainable params: 994,753\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Entrées\n",
    "\n",
    "############## Balanced Model ####################\n",
    "\n",
    "input_num = tf.keras.layers.Input(shape=(taille_num_features_balanced,))\n",
    "input_text = tf.keras.layers.Input(shape=(taille_text_features_balanced,))\n",
    "\n",
    "\n",
    "# Branches du modèle\n",
    "# Branche numérique - FFN\n",
    "\n",
    "num_branch = tf.keras.layers.Dense(64, activation='relu')(input_num)\n",
    "num_branch = tf.keras.layers.Dense(32, activation='relu')(num_branch)\n",
    "\n",
    "\n",
    "# Branche textuelle - Embedding + LSTM\n",
    "# Branche textuelle - Embedding + Transformer (Un block)\n",
    "\n",
    "text_branch = Embedding(vocab_size, embedding_dim, input_length=taille_text_features_balanced)(input_text)\n",
    "\n",
    "mask_inputs = masque_remplissage(input_text) \n",
    "\n",
    "num_blocks = 4\n",
    "out_seq = text_branch  # Initialisation avec les embeddings\n",
    "for _ in range(num_blocks):\n",
    "    out_seq = Encodeur(\n",
    "            n_layers=4,\n",
    "            d_model=256, \n",
    "            num_heads=8,\n",
    "            middle_units=256,\n",
    "            max_seq_len=taille_text_features_balanced)([text_branch, mask_inputs])\n",
    "out_seq = GlobalAveragePooling1D()(out_seq)\n",
    "out_seq = Dropout(0.3)(out_seq)\n",
    "\n",
    "# Fusion des branches \n",
    "\n",
    "# Fusion des branches \n",
    "\n",
    "flattened_text_branch = tf.keras.layers.Flatten()(text_branch) # je remodelise les dimension\n",
    "merged = tf.keras.layers.concatenate([num_branch, flattened_text_branch])\n",
    "\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, LSTM, concatenate, Dropout\n",
    "\n",
    "# Couches supplémentaires après la fusion\n",
    "merged = Dropout(0.5)(merged)\n",
    "merged = Dense(16, activation='relu')(merged)\n",
    "output = Dense(1, activation='sigmoid')(merged) \n",
    "\n",
    "# Création et compilation du modèle\n",
    "\n",
    "model_balanced = Model(inputs=[input_num, input_text], outputs=output)\n",
    "\n",
    "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy', AUC()])\n",
    "\n",
    "model_balanced.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(model_balanced.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 13)]         0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 108)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_102 (Dense)              (None, 64)           896         ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 108, 256)     512000      ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_103 (Dense)              (None, 32)           2080        ['dense_102[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 27648)        0           ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 27680)        0           ['dense_103[0][0]',              \n",
      "                                                                  'flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_67 (Dropout)           (None, 27680)        0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_200 (Dense)              (None, 16)           442896      ['dropout_67[0][0]']             \n",
      "                                                                                                  \n",
      " dense_201 (Dense)              (None, 1)            17          ['dense_200[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 957,889\n",
      "Trainable params: 957,889\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Entrées\n",
    "\n",
    "############## ImBalanced Model ####################\n",
    "\n",
    "input_num = tf.keras.layers.Input(shape=(taille_num_features_imbalanced,))\n",
    "input_text = tf.keras.layers.Input(shape=(taille_text_features_imbalanced,))\n",
    "\n",
    "\n",
    "# Branches du modèle\n",
    "# Branche numérique - FFN\n",
    "\n",
    "num_branch = tf.keras.layers.Dense(64, activation='relu')(input_num)\n",
    "num_branch = tf.keras.layers.Dense(32, activation='relu')(num_branch)\n",
    "\n",
    "\n",
    "# Branche textuelle - Embedding + LSTM\n",
    "# Branche textuelle - Embedding + Transformer (Un block)\n",
    "\n",
    "text_branch = Embedding(vocab_size, embedding_dim, input_length=taille_text_features_imbalanced)(input_text)\n",
    "\n",
    "mask_inputs = masque_remplissage(input_text) \n",
    "\n",
    "num_blocks = 4\n",
    "out_seq = text_branch  # Initialisation avec les embeddings\n",
    "for _ in range(num_blocks):\n",
    "    out_seq = Encodeur(\n",
    "            n_layers=4,\n",
    "            d_model=256, \n",
    "            num_heads=8,\n",
    "            middle_units=256,\n",
    "            max_seq_len=taille_text_features_imbalanced)([text_branch, mask_inputs])\n",
    "out_seq = GlobalAveragePooling1D()(out_seq)\n",
    "out_seq = Dropout(0.3)(out_seq)\n",
    "\n",
    "# Fusion des branches \n",
    "\n",
    "# Fusion des branches \n",
    "\n",
    "flattened_text_branch = tf.keras.layers.Flatten()(text_branch) # je remodelise les dimension\n",
    "merged = tf.keras.layers.concatenate([num_branch, flattened_text_branch])\n",
    "\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, LSTM, concatenate, Dropout\n",
    "\n",
    "# Couches supplémentaires après la fusion\n",
    "merged = Dropout(0.5)(merged)\n",
    "merged = Dense(16, activation='relu')(merged)\n",
    "output = Dense(1, activation='sigmoid')(merged) \n",
    "\n",
    "# Création et compilation du modèle\n",
    "\n",
    "model_imbalanced = Model(inputs=[input_num, input_text], outputs=output)\n",
    "\n",
    "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy', AUC()])\n",
    "\n",
    "model_imbalanced.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(model_imbalanced.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Entrées pour l'entraînement\n",
    "data_num_balanced = scaled_df_balanced   \n",
    "data_text_balanced = pad_sequences(tokens_balanced, maxlen=max_sequence_length_balanced,padding='post')\n",
    "\n",
    "# Entrées pour l'entraînement\n",
    "data_num_imbalanced = scaled_df_imbalanced  \n",
    "data_text_imbalanced = pad_sequences(tokens_imbalanced, maxlen=max_sequence_length_imbalanced,padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        malicioux\n",
      "1        malicioux\n",
      "2        malicioux\n",
      "3        malicioux\n",
      "4        malicioux\n",
      "           ...    \n",
      "33006      bengnin\n",
      "33007      bengnin\n",
      "33008      bengnin\n",
      "33009      bengnin\n",
      "33010      bengnin\n",
      "Name: class, Length: 33011, dtype: object\n",
      "[1 1 1 ... 0 0 0]\n",
      "(33011,)\n",
      "\n",
      "\n",
      "[1 1 1 ... 0 0 0]\n",
      "(413011,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "\n",
    "# Encodage de la cible en labels numériques\n",
    "label_encoder = LabelEncoder()\n",
    "# print(y_balanced) [o=bengnin ,1=malicioux]\n",
    "y_balanced_encoded = label_encoder.fit_transform(y_balanced)\n",
    "print(y_balanced_encoded)\n",
    "print(y_balanced_encoded.shape)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "y_imbalanced_encoded = label_encoder.fit_transform(y_imbalanced)\n",
    "print(y_imbalanced_encoded)\n",
    "print(y_imbalanced_encoded.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Balanced and Imbalanced #########################\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "balanced_text_train, balanced_text_test, balanced_num_train, balanced_num_test, balanced_labels_train, balanced_labels_test = train_test_split(\n",
    "    data_text_balanced, data_num_balanced, y_balanced_encoded, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "imbalanced_text_train, imbalanced_text_test, imbalanced_num_train, imbalanced_num_test, imbalanced_labels_train, imbalanced_labels_test = train_test_split(\n",
    "    data_text_imbalanced, data_num_imbalanced, y_imbalanced_encoded, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of text_train: (26408, 117)\n",
      "Shape of labels_train: (26408,)\n",
      "Shape of text_test: (6603, 117)\n",
      "Shape of labels_test: (6603,)\n",
      "Shape of num_train: (26408, 13)\n",
      "Shape of num_test: (6603, 13)\n",
      "Visualisation des dimension et du batch_size\n",
      "\n",
      "Batch size text train: 26408\n",
      "Dimension text train: 117\n",
      "Batch size num train: 26408\n",
      "Dimension num train: 13\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of text_train:\", balanced_text_train.shape)\n",
    "print(\"Shape of labels_train:\", balanced_labels_train.shape)\n",
    "print(\"Shape of text_test:\", balanced_text_test.shape)\n",
    "print(\"Shape of labels_test:\", balanced_labels_test.shape)\n",
    "print(\"Shape of num_train:\", balanced_num_train.shape)\n",
    "print(\"Shape of num_test:\", balanced_num_test.shape)\n",
    "\n",
    "print(\"Visualisation des dimension et du batch_size\\n\")\n",
    "\n",
    "batch_size, dimension = balanced_text_train.shape[0], balanced_text_train.shape[1]\n",
    "print(\"Batch size text train:\", batch_size)\n",
    "print(\"Dimension text train:\", dimension)\n",
    "\n",
    "batch_size, dimension = balanced_num_train.shape[0], balanced_num_train.shape[1]\n",
    "print(\"Batch size num train:\", batch_size)\n",
    "print(\"Dimension num train:\", dimension)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemples des données d'entraînement:\n",
      "Text_train:\n",
      "[[ 4 16 12 80 30 14 47 17 39 39 64 14 17 39 20 31  4  5  6 93  1 42  1 22\n",
      "   3 59  1 24  1 51  1 38 21 27  1 18 84 10 54 57 44 25 28 23  2  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [13 41 16 15 12 43 26 20 19 31 37 47 39 53 66 76  4  7  9  8  5  6  3 24\n",
      "   1 32  1 36  1 33  3 42  1 49  1 56 11 10 54 44  2  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4 41 72 73 22 16 15 12 43 26 95 30 17 31 17 47 17  4  7  9  8  5  6 93\n",
      "   1 42  3 27  1 22 10 45 57 44 25 28 23  2  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [13 61 15 62 12 40 17 39 14 55 19 29  4  7  9  8  5  6  3 22  1 38  1 18\n",
      "   1 32  1 27  1 36 11 10 45 25 28 23  2  2  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [13 74 15 77 12 40 39 14 35 29 19 55 14 47 17 37 37 20 39 86  4  7  9  8\n",
      "   5  6 82  1 42  1 27  1 70  1 38  3 22  3 33  3 34  1 24  1 18 21 52 11\n",
      "  10 45 25 28 23  2  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "\n",
      "Num_train:\n",
      "       oc_8  hex_32  puny_coded  Page_Rank  Alexa_Rank  hex_8  oc_32   \n",
      "8505    0.0     0.0         0.0        0.0    0.772331    0.0    0.0  \\\n",
      "25023   0.0     0.0         0.0        0.0    0.005949    0.0    0.0   \n",
      "12291   0.0     0.0         0.0        0.0    0.053185    0.0    0.0   \n",
      "30406   0.0     0.0         0.0        0.0    0.950255    0.0    0.0   \n",
      "9892    0.0     0.0         0.0        0.0    0.000000    0.0    0.0   \n",
      "\n",
      "            len  dec_8   entropy  numeric_percentage  subdomain  dec_32  \n",
      "8505   0.084416    0.0  0.610486                 0.0        0.0     0.0  \n",
      "25023  0.064935    0.0  0.583476                 0.0        0.0     0.0  \n",
      "12291  0.045455    0.0  0.373552                 0.0        0.0     0.0  \n",
      "30406  0.051948    0.0  0.544495                 0.0        0.0     0.0  \n",
      "9892   0.103896    0.0  0.674330                 0.0        0.0     0.0  \n",
      "\n",
      "Labels_train:\n",
      "[1 0 1 0 1]\n",
      "\n",
      "Vérification des valeurs nan:\n",
      "Text_train contains nan: False\n",
      "Num_train contains nan: oc_8                  False\n",
      "hex_32                False\n",
      "puny_coded            False\n",
      "Page_Rank             False\n",
      "Alexa_Rank            False\n",
      "hex_8                 False\n",
      "oc_32                 False\n",
      "len                   False\n",
      "dec_8                 False\n",
      "entropy               False\n",
      "numeric_percentage    False\n",
      "subdomain             False\n",
      "dec_32                False\n",
      "dtype: bool\n",
      "Labels_train contains nan: False\n"
     ]
    }
   ],
   "source": [
    "# Afficher quelques exemples des données d'entraînement\n",
    "print(\"Exemples des données d'entraînement:\")\n",
    "print(\"Text_train:\")\n",
    "print(balanced_text_train[:5])\n",
    "print(\"\\nNum_train:\")\n",
    "print(balanced_num_train[:5])\n",
    "print(\"\\nLabels_train:\")\n",
    "print(balanced_labels_train[:5])\n",
    "\n",
    "# Faire de même pour les données de test\n",
    "\n",
    "\n",
    "# Vérifier si des valeurs nan sont présentes\n",
    "print(\"\\nVérification des valeurs nan:\")\n",
    "print(\"Text_train contains nan:\", np.isnan(balanced_text_train).any())\n",
    "print(\"Num_train contains nan:\", np.isnan(balanced_num_train).any())\n",
    "print(\"Labels_train contains nan:\", np.isnan(balanced_labels_train).any())\n",
    "\n",
    "# Faire de même pour les données de test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40124 samples, validate on 10032 samples\n",
      "Epoch 1/10\n",
      "40124/40124 [==============================] - ETA: 0s - loss: 1.1588 - accuracy: 0.4672"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python install\\lib\\site-packages\\keras\\engine\\training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40124/40124 [==============================] - 81s 2ms/sample - loss: 1.1588 - accuracy: 0.4672 - val_loss: 1.0689 - val_accuracy: 0.5166\n",
      "Epoch 2/10\n",
      "40124/40124 [==============================] - 76s 2ms/sample - loss: 1.0511 - accuracy: 0.5268 - val_loss: 1.0152 - val_accuracy: 0.5527\n",
      "Epoch 3/10\n",
      "40124/40124 [==============================] - 76s 2ms/sample - loss: 1.0031 - accuracy: 0.5530 - val_loss: 0.9807 - val_accuracy: 0.5670\n",
      "Epoch 4/10\n",
      "40124/40124 [==============================] - 78s 2ms/sample - loss: 0.9705 - accuracy: 0.5710 - val_loss: 0.9491 - val_accuracy: 0.5770\n",
      "Epoch 5/10\n",
      "40124/40124 [==============================] - 74s 2ms/sample - loss: 0.9531 - accuracy: 0.5824 - val_loss: 0.9353 - val_accuracy: 0.6006\n",
      "Epoch 6/10\n",
      "40124/40124 [==============================] - 75s 2ms/sample - loss: 0.9382 - accuracy: 0.5893 - val_loss: 0.9194 - val_accuracy: 0.6017\n",
      "Epoch 7/10\n",
      "40124/40124 [==============================] - 82s 2ms/sample - loss: 0.9253 - accuracy: 0.5949 - val_loss: 0.9023 - val_accuracy: 0.6108\n",
      "Epoch 8/10\n",
      "40124/40124 [==============================] - 84s 2ms/sample - loss: 0.9157 - accuracy: 0.6022 - val_loss: 0.8963 - val_accuracy: 0.6171\n",
      "Epoch 9/10\n",
      "40124/40124 [==============================] - 86s 2ms/sample - loss: 0.9060 - accuracy: 0.6080 - val_loss: 0.8765 - val_accuracy: 0.6261\n",
      "Epoch 10/10\n",
      "40124/40124 [==============================] - 86s 2ms/sample - loss: 0.8932 - accuracy: 0.6147 - val_loss: 0.8790 - val_accuracy: 0.6302\n"
     ]
    }
   ],
   "source": [
    "### Balanced \n",
    "\n",
    "history_balanced= model_balanced.fit([balanced_num_train,balanced_text_train], balanced_labels_train , epochs=10, batch_size=64, validation_data=([balanced_num_test,balanced_text_test],balanced_labels_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ImBalanced \n",
    "\n",
    "\n",
    "history_imbalanced= model_imbalanced.fit([imbalanced_num_train,imbalanced_text_train], imbalanced_labels_train , epochs=10, batch_size=64, validation_data=([imbalanced_num_test,imbalanced_text_test],imbalanced_labels_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on effectue les prediction sur les donnees de test\n",
    "\n",
    "y_pred_balanced = model_balanced.predict([balanced_num_test,balanced_text_test])\n",
    "\n",
    "y_pred_imbalanced = model_imbalanced.predict([imbalanced_num_test,imbalanced_text_test])\n",
    "\n",
    "# necessaire pour afficher la matrix de confusion car a besoin que la probabilité retourner pqr lq fonction sigmoid soir saoit 0 ou 1 pour travailler dessus\n",
    "\n",
    "y_pred_balanced = np.round(y_pred_balanced)\n",
    "y_pred_imbalanced = np.round(y_pred_imbalanced)\n",
    "                    \n",
    "### Evaluation\n",
    "                             \n",
    "evaluation_results_balanced = model_balanced.evaluate([balanced_num_test,balanced_text_test], balanced_labels_test)\n",
    "evaluation_results_imbalanced = model_imbalanced.evaluate([imbalanced_num_test,imbalanced_text_test], imbalanced_labels_test)\n",
    "# loss, accuracy = model.evaluate([num_test, text_test], labels_test)\n",
    "\n",
    "\n",
    "# Affichage des résultats\n",
    "\n",
    "# print(f'Accuracy: {accuracy}, Loss: {loss}')\n",
    "print(\"Balanced Perte sur les données de test:\", evaluation_results_balanced[0])\n",
    "print(\"Balanced Précision sur les données de test:\", evaluation_results_balanced[1])\n",
    "\n",
    "print(\"  \\n\")\n",
    "\n",
    "print(\"ImBalanced Perte sur les données de test:\", evaluation_results_imbalanced[0])\n",
    "print(\"ImBalanced Précision sur les données de test:\", evaluation_results_imbalanced[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "\n",
    "\n",
    "# Afficher le rapport de classification\n",
    "class_report_balanced = classification_report(balanced_labels_test, y_pred_balanced)\n",
    "print(\"Balanced Rapport de classification :\\n\", class_report_balanced)\n",
    "\n",
    "print(\" \\n\")\n",
    "\n",
    "class_report_imbalanced = classification_report(imbalanced_labels_test, y_pred_imbalanced)\n",
    "print(\"Balanced Rapport de classification :\\n\", class_report_imbalanced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Balanced ########\n",
    "\n",
    "# Extraction des métriques d'entraînement\n",
    "loss = history_balanced.history['loss']\n",
    "accuracy = history_balanced.history['accuracy']\n",
    "val_loss = history_balanced.history['val_loss']\n",
    "val_accuracy = history_balanced.history['val_accuracy']\n",
    "\n",
    "# Affichage des courbes de perte et d'exactitude séparément\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# Affichage des courbes d'apprentissage et de validation\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot de la perte d'entraînement et de la perte de validation\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_balanced.history['loss'], label='Training loss')\n",
    "plt.plot(history_balanced.history['val_loss'], label='Validation loss')\n",
    "plt.title('Courbe de Perte')\n",
    "plt.xlabel('Épochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "# Plot de la précision d'entraînement et de la précision de validation\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_balanced.history['accuracy'], label='Training accuracy')\n",
    "plt.plot(history_balanced.history['val_accuracy'], label='Validation accuracy')\n",
    "plt.title('Courbe de Précision')\n",
    "plt.xlabel('Épochs')\n",
    "plt.ylabel('Précision')\n",
    "plt.legend()\n",
    "\n",
    "# Afficher les deux sous-plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## ImBalanced ########\n",
    "\n",
    "# Extraction des métriques d'entraînement\n",
    "loss = history_imbalanced.history['loss']\n",
    "accuracy = history_imbalanced.history['accuracy']\n",
    "val_loss = history_imbalanced.history['val_loss']\n",
    "val_accuracy = history_imbalanced.history['val_accuracy']\n",
    "\n",
    "# Affichage des courbes de perte et d'exactitude séparément\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# Affichage des courbes d'apprentissage et de validation\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot de la perte d'entraînement et de la perte de validation\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_imbalanced.history['loss'], label='Training loss')\n",
    "plt.plot(history_imbalanced.history['val_loss'], label='Validation loss')\n",
    "plt.title('Courbe de Perte')\n",
    "plt.xlabel('Épochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "# Plot de la précision d'entraînement et de la précision de validation\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_imbalanced.history['accuracy'], label='Training accuracy')\n",
    "plt.plot(history_imbalanced.history['val_accuracy'], label='Validation accuracy')\n",
    "plt.title('Courbe de Précision')\n",
    "plt.xlabel('Épochs')\n",
    "plt.ylabel('Précision')\n",
    "plt.legend()\n",
    "\n",
    "# Afficher les deux sous-plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Balanced #######\n",
    "\n",
    "\n",
    "#affichage de la matrixe de confusion\n",
    "\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "#calul preliminaire pour obtenir la matrice de confusion\n",
    "\n",
    "conf_matrix = confusion_matrix(balanced_labels_test,y_pred_balanced)\n",
    "true_negatives, false_positives,false_negatives, true_positives = conf_matrix.ravel()\n",
    "\n",
    "# Créer la matrice de confusion\n",
    "conf_matrix = np.array([[true_negatives, false_positives], [false_negatives, true_positives]])\n",
    "\n",
    "# Afficher la matrice de confusion avec seaborn\n",
    "df_cm = pd.DataFrame(conf_matrix, index=['Bengnin 0', 'Malicioux 1'], columns=['Bengnin 0', 'Malicioux 1'])\n",
    "sn.heatmap(df_cm, annot=True, cmap='Blues', fmt='g')\n",
    "plt.title('Matrice de Confusion')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Balanced #######\n",
    "\n",
    "\n",
    "#affichage de la matrixe de confusion\n",
    "\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "#calul preliminaire pour obtenir la matrice de confusion\n",
    "\n",
    "conf_matrix = confusion_matrix(imbalanced_labels_test,y_pred_imbalanced)\n",
    "true_negatives, false_positives,false_negatives, true_positives = conf_matrix.ravel()\n",
    "\n",
    "# Créer la matrice de confusion\n",
    "conf_matrix = np.array([[true_negatives, false_positives], [false_negatives, true_positives]])\n",
    "\n",
    "# Afficher la matrice de confusion avec seaborn\n",
    "df_cm = pd.DataFrame(conf_matrix, index=['Bengnin 0', 'Malicioux 1'], columns=['Bengnin 0', 'Malicioux 1'])\n",
    "sn.heatmap(df_cm, annot=True, cmap='Blues', fmt='g')\n",
    "plt.title('Matrice de Confusion')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ Marche tres bien ############\n",
    "################################## En utilisant le BayesianOptimization() et le ModelChekpoint qui detient le meilleur model ] #######################\n",
    "\n",
    "\n",
    "##### Hyper parametre Tuning\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from kerastuner.tuners import BayesianOptimization\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Définir la fonction pour la recherche des hyperparamètres\n",
    "def build_model(hp):\n",
    "    model = Model(inputs=[input_num, input_text], outputs=output)\n",
    "\n",
    "    # Définir les hyperparamètres à optimiser\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[0.01, 0.001, 0.0001])\n",
    "    hp_lstm_units = hp.Choice('lstm_units', values=[64, 128, 256])\n",
    "    hp_dense_units = hp.Choice('dense_units', values=[16, 32, 64])\n",
    "    hp_embedding_dim = hp.Choice('embedding_dim', values=[64, 128, 256])\n",
    "\n",
    "    # Compiler le modèle avec les hyperparamètres\n",
    "    # optimizer = Adam(lr=hp_learning_rate)\n",
    "\n",
    "    optimizer = Adam(learning_rate=hp_learning_rate)\n",
    "\n",
    "    # model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy', AUC()])\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "text_train, text_test, num_train, num_test, labels_train, labels_test = train_test_split(\n",
    "    data_text, data_num, y_encoded, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "#Pour resoudre les erreur \n",
    "import os\n",
    "\n",
    "# Vérifier si le répertoire existe, sinon le créer\n",
    "save_directory = 'my_dir'\n",
    "if not os.path.exists(save_directory):\n",
    "    os.makedirs(save_directory)\n",
    "\n",
    "# Créer un tuner pour la recherche des hyperparamètres\n",
    "\n",
    "tuner = BayesianOptimization(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    hyperparameters=HyperParameters(),\n",
    "    directory=save_directory,\n",
    "    project_name='lstm_ffn_hyperparam_tuning'\n",
    ")\n",
    "\n",
    "# Définir un callback ModelCheckpoint pour sauvegarder le meilleur modèle\n",
    "filepath=os.path.abspath('my_dir/lstm_ffn_hyperparam_tuning/best_model.h5')\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=filepath,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# Rechercher les meilleurs hyperparamètres en utilisant les données d'entraînement et de validation\n",
    "# Utiliser le callback BayesianOptimizationCallback\n",
    "\n",
    "tuner.search([num_train, text_train], labels_train, epochs=5, validation_data=([num_test, text_test], labels_test), callbacks=[checkpoint_callback])\n",
    "\n",
    "# Obtenir les meilleurs hyperparamètres trouvés\n",
    "best_hps = tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters\n",
    "print(f\"Best hyperparameters: {best_hps}\")\n",
    "\n",
    "# Réutiliser les meilleurs hyperparamètres pour construire le modèle final\n",
    "model = build_model(best_hps)\n",
    "\n",
    "# Entraîner le modèle avec les données complètes\n",
    "model.fit([num_train, text_train], labels_train, epochs=5, batch_size=32, validation_data=([num_test, text_test], labels_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "\n",
    "\n",
    "############################################ Marche tres bien ############\n",
    "################################## En utilisant le BayesianOptimization() et le ModelChekpoint qui detient le meilleur model ] #######################\n",
    "\n",
    "\n",
    "##### Hyper parametre Tuning ##############\n",
    "\n",
    "# Définir la fonction pour la recherche des hyperparamètres\n",
    "def build_model(hp):\n",
    "    model = Model(inputs=[input_num, input_text], outputs=output)\n",
    "\n",
    "    # Définir les hyperparamètres à optimiser\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[0.01, 0.001, 0.0001])\n",
    "    hp_lstm_units = hp.Choice('lstm_units', values=[64, 128, 256])\n",
    "    hp_dense_units = hp.Choice('dense_units', values=[16, 32, 64])\n",
    "    hp_embedding_dim = hp.Choice('embedding_dim', values=[64, 128, 256])\n",
    "\n",
    "    # Compiler le modèle avec les hyperparamètres\n",
    "    # optimizer = Adam(lr=hp_learning_rate)\n",
    "    optimizer = Adam(learning_rate=hp_learning_rate)\n",
    "\n",
    "    # model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy', AUC()])\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "text_train, text_test, num_train, num_test, labels_train, labels_test = train_test_split(\n",
    "    data_text, data_num, y_encoded, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "#Pour resoudre les erreur \n",
    "import os\n",
    "\n",
    "# Vérifier si le répertoire existe, sinon le créer\n",
    "save_directory = 'my_dir'\n",
    "if not os.path.exists(save_directory):\n",
    "    os.makedirs(save_directory)\n",
    "\n",
    "# Créer un tuner pour la recherche des hyperparamètres\n",
    "\n",
    "tuner = BayesianOptimization(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    hyperparameters=HyperParameters(),\n",
    "    directory=save_directory,\n",
    "    project_name='lstm_ffn_hyperparam_tuning'\n",
    ")\n",
    "\n",
    "\n",
    "# Définir un callback ModelCheckpoint pour sauvegarder le meilleur modèle\n",
    "filepath=os.path.abspath('my_dir/lstm_ffn_hyperparam_tuning/best_model.h5')\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=filepath,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# Rechercher les meilleurs hyperparamètres en utilisant les données d'entraînement et de validation\n",
    "# Utiliser le callback BayesianOptimizationCallback\n",
    "\n",
    "tuner.search([num_train, text_train], labels_train, epochs=5, validation_data=([num_test, text_test], labels_test), callbacks=[checkpoint_callback])\n",
    "\n",
    "# Obtenir les meilleurs hyperparamètres trouvés\n",
    "best_hps = tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters\n",
    "print(f\"Best hyperparameters: {best_hps}\")\n",
    "\n",
    "# Réutiliser les meilleurs hyperparamètres pour construire le modèle final\n",
    "model = build_model(best_hps)\n",
    "\n",
    "# Entraîner le modèle avec les données complètes\n",
    "history = model.fit([num_train, text_train], labels_train, epochs=5, batch_size=32, validation_data=([num_test, text_test], labels_test))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
