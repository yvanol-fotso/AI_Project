{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5961,"status":"ok","timestamp":1712179060550,"user":{"displayName":"Pr Kengne Research Team","userId":"06174679572112259337"},"user_tz":0},"id":"RyxRNePLjDkV"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Model\n","from transformers import BertTokenizer, TFBertModel\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":67239,"status":"ok","timestamp":1712179025295,"user":{"displayName":"Pr Kengne Research Team","userId":"06174679572112259337"},"user_tz":0},"id":"dacJV3m7WXJ8","outputId":"a8509cef-739d-41ad-e6cf-c9a1ac7bd4f8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow==2.12.0\n","  Downloading tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (24.3.25)\n","Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.12.0)\n","  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.62.1)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.9.0)\n","Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.4.23)\n","Collecting keras<2.13,>=2.12.0 (from tensorflow==2.12.0)\n","  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (18.1.1)\n","Collecting numpy<1.24,>=1.22 (from tensorflow==2.12.0)\n","  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (24.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.16.0)\n","Collecting tensorboard<2.13,>=2.12 (from tensorflow==2.12.0)\n","  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow==2.12.0)\n","  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (4.10.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.36.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.43.0)\n","Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.2.0)\n","Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.11.4)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.27.0)\n","Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow==2.12.0)\n","  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.2)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.1.5)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n","Installing collected packages: tensorflow-estimator, numpy, keras, gast, google-auth-oauthlib, tensorboard, tensorflow\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.15.0\n","    Uninstalling tensorflow-estimator-2.15.0:\n","      Successfully uninstalled tensorflow-estimator-2.15.0\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.25.2\n","    Uninstalling numpy-1.25.2:\n","      Successfully uninstalled numpy-1.25.2\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.15.0\n","    Uninstalling keras-2.15.0:\n","      Successfully uninstalled keras-2.15.0\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.5.4\n","    Uninstalling gast-0.5.4:\n","      Successfully uninstalled gast-0.5.4\n","  Attempting uninstall: google-auth-oauthlib\n","    Found existing installation: google-auth-oauthlib 1.2.0\n","    Uninstalling google-auth-oauthlib-1.2.0:\n","      Successfully uninstalled google-auth-oauthlib-1.2.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.15.2\n","    Uninstalling tensorboard-2.15.2:\n","      Successfully uninstalled tensorboard-2.15.2\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.15.0\n","    Uninstalling tensorflow-2.15.0:\n","      Successfully uninstalled tensorflow-2.15.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n","pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n","tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.12.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 keras-2.12.0 numpy-1.23.5 tensorboard-2.12.3 tensorflow-2.12.0 tensorflow-estimator-2.12.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["gast","keras","numpy","tensorboard","tensorflow"]},"id":"65b1e98d62f84ce19fdad0e3fbcdaf71"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting transformers==4.37.1\n","  Downloading transformers-4.37.1-py3-none-any.whl (8.4 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/8.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/8.4 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m6.5/8.4 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m107.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.1) (3.13.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.1) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.1) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.1) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.1) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.1) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.1) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.1) (0.15.2)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.1) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.1) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.1) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.1) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.1) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.1) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.1) (2024.2.2)\n","Installing collected packages: transformers\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.38.2\n","    Uninstalling transformers-4.38.2:\n","      Successfully uninstalled transformers-4.38.2\n","Successfully installed transformers-4.37.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["transformers"]},"id":"24592eadc3c246fcb3a6cafefc3a1dcb"}},"metadata":{}}],"source":["########### c'est cette version qu'il faut installer car toute les version que j'installe ici ne marche pas j;ai pris celle qui marche sur mon pc\n","########## Ne pas executer deux fois #############\n","\n","!pip install --upgrade tensorflow==2.12.0\n","!pip install transformers==4.37.1"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1712179085548,"user":{"displayName":"Pr Kengne Research Team","userId":"06174679572112259337"},"user_tz":0},"id":"6x_RXo5xWhwv","outputId":"f9d106ac-6d7b-4f99-ba5b-0b118661d118"},"outputs":[{"output_type":"stream","name":"stdout","text":["Version de TensorFlow : 2.12.0\n","Version de Transformers : 4.37.1\n"]}],"source":["########### c'est cette version qu'il faut installer car toute les version que j'installe ici ne marche pas j;ai pris celle qui marche sur mon pc\n","\n","\n","import tensorflow as tf\n","import transformers\n","\n","print(\"Version de TensorFlow :\", tf.__version__)\n","print(\"Version de Transformers :\", transformers.__version__)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":2612,"status":"ok","timestamp":1712179100191,"user":{"displayName":"Pr Kengne Research Team","userId":"06174679572112259337"},"user_tz":0},"id":"L8x97jafWhhE"},"outputs":[],"source":["################ Bon Code ###############\n","#### charger et lire un dataset [.zip] sur coolab ####\n","\n","import zipfile\n","import os\n","import pandas as pd\n","\n","import shutil\n","\n","\n","chemin_zip_heavy_attacks = \"AttacksHeavy.zip\"\n","chemin_zip_heavy_benign = \"BenignHeavy.zip\"\n","\n","\n","chemin_zip_light_attacks = \"AttacksLight.zip\"\n","chemin_zip_light_benign = \"BenignLight.zip\"\n","\n","\n","# Fonction pour extraire les fichiers zip\n","def extraire_zip(chemin_zip):\n","    with zipfile.ZipFile(chemin_zip, 'r') as zip_ref:\n","        zip_ref.extractall(\"extraction_temp\")  # Extraire les fichiers zip dans un répertoire temporaire\n","\n","# Fonction pour charger les fichiers CSV d'un type spécifique (stateful ou stateless)\n","def charger_concatener_donnees(sous_dossier, prefixe):\n","    # Lister tous les fichiers CSV dans le sous-dossier\n","    fichiers_csv = [f for f in os.listdir(f\"extraction_temp/{sous_dossier}\") if f.startswith(prefixe) and f.endswith('.csv')]\n","    # Lire chaque fichier CSV et le stocker dans une liste de DataFrames\n","    dataframes = [pd.read_csv(f\"extraction_temp/{sous_dossier}/{f}\") for f in fichiers_csv]\n","    # Concaténer les DataFrames en un seul\n","    return pd.concat(dataframes, ignore_index=True)\n","\n","# Extraire les fichiers zip\n","extraire_zip(chemin_zip_heavy_attacks)\n","extraire_zip(chemin_zip_heavy_benign)\n","\n","extraire_zip(chemin_zip_light_attacks)\n","extraire_zip(chemin_zip_light_benign)\n","\n","########## Heavy ############\n","\n","# Charger et concaténer les données stateful\n","stateful_heavy_attack_data = charger_concatener_donnees(\"AttacksHeavy\", \"stateful\")\n","stateful_heavy_benign_data = charger_concatener_donnees(\"BenignHeavy\", \"stateful\")\n","\n","# Charger et concaténer les données stateless\n","stateless_heavy_attack_data = charger_concatener_donnees(\"AttacksHeavy\", \"stateless\")\n","stateless_heavy_benign_data = charger_concatener_donnees(\"BenignHeavy\", \"stateless\")\n","\n","\n","#### Light ###############\n","\n","# Charger et concaténer les données stateful\n","stateful_light_attack_data = charger_concatener_donnees(\"AttacksLight\", \"stateful\")\n","stateful_light_benign_data = charger_concatener_donnees(\"BenignLight\", \"stateful\")\n","\n","# Charger et concaténer les données stateless\n","stateless_light_attack_data = charger_concatener_donnees(\"AttacksLight\", \"stateless\")\n","stateless_light_benign_data = charger_concatener_donnees(\"BenignLight\", \"stateless\")\n","\n","\n","\n","# Supprimer le répertoire temporaire après avoir terminé\n","\n","# Vérifier si le répertoire temporaire existe\n","if os.path.exists(\"extraction_temp\"):\n","    # Supprimer le répertoire temporaire et son contenu\n","    shutil.rmtree(\"extraction_temp\")\n","\n","\n","# Maintenant, vous avez vos données prêtes à être utilisées\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":775,"status":"ok","timestamp":1712179346765,"user":{"displayName":"Pr Kengne Research Team","userId":"06174679572112259337"},"user_tz":0},"id":"C8Rxv0-0Wy2T","outputId":"af55a32a-6a40-432b-876d-dc783b7f61a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Taille Stateful Heavy attack puis Stateless Heavy attack\n","(72028, 27)\n","(251670, 15)\n","  \n","\n","Taille Stateful Bengin attack puis Stateless Begnin attack \n","(156014, 27)\n","(402767, 15)\n","  \n","\n","Taille Stateful Heavy Light puis Stateless Light\n","(11295, 27)\n","(42683, 15)\n","  \n","\n","Taille Stateful Bengin Light puis Stateless Begnin Light\n","(109766, 27)\n","(281164, 15)\n"," cocncatenantion sur axis = 0 sur les y \n","\n"," Heavy attack\n","(323698, 42)\n","(323698, 43)\n"," \n","\n"," Heavy Bengnin\n","(558781, 42)\n","(558781, 43)\n"," \n","\n"," Light attack\n","(53978, 42)\n","(53978, 43)\n"," \n","\n"," Light Bengnin\n","(390930, 42)\n","(390930, 43)\n"]}],"source":["\n","#### Sur-Echantillonage dataset  ####\n","\n","##  Heavy Attack   72,028(stateful)      251,670 (stateless)\n","\n","##  Heavy-Benign      156,014                  402,767\n","\n","### Light Attack      11,295                   42,683\n","\n","### Light-Benign      109,766                  281,164\n","\n","\n","#### Heavy ATTACK #########\n","stateful_heavy_attack_data = stateful_heavy_attack_data.sample(72028, random_state=42)\n","stateful_heavy_benign_data = stateful_heavy_benign_data.sample(156014, random_state=42,replace=True)\n","\n","stateless_heavy_attack_data = stateless_heavy_attack_data.sample(251670, random_state=42)\n","stateless_heavy_benign_data = stateless_heavy_benign_data.sample(402767, random_state=42,replace=True)\n","\n","#### Light ATTACK #########\n","\n","# Charger les données stateful\n","stateful_light_attack_data = stateful_light_attack_data.sample(11295, random_state=42)\n","stateful_light_benign_data = stateful_light_benign_data.sample(109766, random_state=42,replace=True)\n","# Charger les données stateless\n","stateless_light_attack_data = stateless_light_attack_data.sample(42683, random_state=42)\n","stateless_light_benign_data = stateless_light_benign_data.sample(281164, random_state=42,replace=True)\n","\n","############## taille apres re-echantillonage #############\n","print(\"Taille Stateful Heavy attack puis Stateless Heavy attack\")\n","print(stateful_heavy_attack_data.shape)\n","print(stateless_heavy_attack_data.shape)\n","\n","print(\"  \\n\")\n","\n","print(\"Taille Stateful Bengin attack puis Stateless Begnin attack \")\n","print(stateful_heavy_benign_data.shape)\n","print(stateless_heavy_benign_data.shape)\n","\n","print(\"  \\n\")\n","\n","\n","############## taille apres re-echantillonage #############\n","print(\"Taille Stateful Heavy Light puis Stateless Light\")\n","print(stateful_light_attack_data.shape)\n","print(stateless_light_attack_data.shape)\n","\n","print(\"  \\n\")\n","\n","print(\"Taille Stateful Bengin Light puis Stateless Begnin Light\")\n","print(stateful_light_benign_data.shape)\n","print(stateless_light_benign_data.shape)\n","\n","\n","#### concatenation  sur axis = 1 ########\n","\n","print(\" cocncatenantion sur axis = 0 sur les y \\n\")\n","print(\" Heavy attack\")\n","\n","heavy_attack = pd.concat([stateful_heavy_attack_data, stateless_heavy_attack_data], axis=0)\n","print(heavy_attack.shape)\n","\n","#### j'ajoute la classe / label ######\n","\n","heavy_attack['class'] = 'heavy_attacks'\n","print(heavy_attack.shape)\n","\n","print(\" \\n\")\n","print(\" Heavy Bengnin\")\n","\n","heavy_bengin = pd.concat([stateful_heavy_benign_data, stateless_heavy_benign_data], axis=0)\n","print(heavy_bengin.shape)\n","\n","#### j'ajoute la classe / label ######\n","\n","heavy_bengin['class'] = 'heavy_bengnin'\n","print(heavy_bengin.shape)\n","\n","print(\" \\n\")\n","print(\" Light attack\")\n","\n","light_attack = pd.concat([stateful_light_attack_data, stateless_light_attack_data], axis=0)\n","print(light_attack.shape)\n","\n","\n","#### j'ajoute la classe / label ######\n","light_attack['class'] = 'light_attacks'\n","print(light_attack.shape)\n","\n","\n","print(\" \\n\")\n","print(\" Light Bengnin\")\n","\n","light_bengin = pd.concat([stateful_light_benign_data, stateless_light_benign_data], axis=0)\n","print(light_bengin.shape)\n","\n","#### j'ajoute la classe / label ######\n","light_bengin['class'] = 'light_bengnin'\n","print(light_bengin.shape)\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2285,"status":"ok","timestamp":1712179500728,"user":{"displayName":"Pr Kengne Research Team","userId":"06174679572112259337"},"user_tz":0},"id":"nIDm6JyCW186","outputId":"a54e7b3e-81ae-40ac-90f9-e3f45410ff16"},"outputs":[{"output_type":"stream","name":"stdout","text":["(1327387, 12)\n","(1327387, 5)\n","(1327387,)\n","(1327387, 43)\n"]}],"source":["################################### CONCATENATION Final des donnee sur axis = 0 ########\n","########################################################################################\n","########################################################################################\n","\n","\n","# 2. Concaténer les données\n","\n","final_data = pd.concat([heavy_attack, heavy_bengin,light_attack,light_bengin], axis=0, ignore_index=True)\n","\n","# 3. Supprimer les colonnes redondantes dans les données catégorielles\n","final_data = final_data.loc[:, ~final_data.columns.duplicated()]\n","\n","# X_numerical = final_data.select_dtypes(include=['int64', 'float64'])\n","\n","# X_categorical = final_data.select_dtypes(exclude='number').drop('class', axis=1)\n","\n","X_numerical = final_data[['rr','A_frequency','FQDN_count','upper','lower','numeric','entropy','special', 'labels', 'labels_max','labels_average','len']]\n","\n","X_categorical = final_data[['rr_type','unique_ttl','timestamp', 'longest_word', 'sld']]\n","\n","y = final_data['class']\n","\n","print(X_numerical.shape)\n","print(X_categorical.shape)\n","\n","print(y.shape)\n","print(final_data.shape)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"elapsed":3015,"status":"error","timestamp":1710322730128,"user":{"displayName":"FOTSO TATCHUM YVANOL ROSLY","userId":"06840443639537519869"},"user_tz":0},"id":"S8XGINXwnkao","outputId":"6456eb7e-6fca-4bd2-cabc-0cea722fc8f6"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-f64443f33817>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 1. Résumé des données : Calcul des statistiques descriptives\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0msummary_statistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_statistics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdescribe\u001b[0;34m(self, percentiles, include, exclude, datetime_is_numeric)\u001b[0m\n\u001b[1;32m  10938\u001b[0m         \u001b[0mmax\u001b[0m            \u001b[0mNaN\u001b[0m      \u001b[0;36m3.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10939\u001b[0m         \"\"\"\n\u001b[0;32m> 10940\u001b[0;31m         return describe_ndframe(\n\u001b[0m\u001b[1;32m  10941\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10942\u001b[0m             \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/describe.py\u001b[0m in \u001b[0;36mdescribe_ndframe\u001b[0;34m(obj, include, exclude, datetime_is_numeric, percentiles)\u001b[0m\n\u001b[1;32m     99\u001b[0m         )\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdescriber\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpercentiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpercentiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNDFrameT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/describe.py\u001b[0m in \u001b[0;36mdescribe\u001b[0;34m(self, percentiles)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseries\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mdescribe_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_describe_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime_is_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0mldesc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescribe_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mcol_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreorder_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mldesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/describe.py\u001b[0m in \u001b[0;36mdescribe_numeric_1d\u001b[0;34m(series, percentiles)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0mstat_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"count\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"std\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"min\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mformatted_percentiles\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"max\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     d = (\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m         \u001b[0;34m+\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpercentiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mstd\u001b[0;34m(self, axis, skipna, level, ddof, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11715\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11716\u001b[0m         ):\n\u001b[0;32m> 11717\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  11718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11719\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"std\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mstd\u001b[0;34m(self, axis, skipna, level, ddof, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11303\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11304\u001b[0m     ) -> Series | float:\n\u001b[0;32m> 11305\u001b[0;31m         return self._stat_function_ddof(\n\u001b[0m\u001b[1;32m  11306\u001b[0m             \u001b[0;34m\"std\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnanops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11307\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_stat_function_ddof\u001b[0;34m(self, name, func, axis, skipna, level, ddof, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11264\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mddof\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11265\u001b[0m             )\n\u001b[0;32m> 11266\u001b[0;31m         return self._reduce(\n\u001b[0m\u001b[1;32m  11267\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mddof\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11268\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4814\u001b[0m                 )\n\u001b[1;32m   4815\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4816\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4818\u001b[0m     def _reindex_indexer(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    153\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnanstd\u001b[0;34m(values, axis, skipna, ddof, mask)\u001b[0m\n\u001b[1;32m    904\u001b[0m     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnanvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mddof\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrap_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;31m# we want to transform an object array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    153\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnanvar\u001b[0;34m(values, axis, skipna, ddof, mask)\u001b[0m\n\u001b[1;32m    967\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputmask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;31m# Return variance as np.float64 (the datatype used in the accumulator),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     47\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     48\u001b[0m          initial=_NoValue, where=True):\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["################# EDA ########################\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","\n","# 1. Résumé des données : Calcul des statistiques descriptives\n","summary_statistics = final_data.describe()\n","print(summary_statistics)\n","\n","# 2. Visualisation des données\n","# Histogrammes pour les variables numériques\n","for column in final_data.select_dtypes(include=['int64', 'float64']).columns:\n","    plt.figure(figsize=(8, 6))\n","    sns.histplot(final_data[column], bins=30, kde=True)\n","    plt.title(f'Histogramme de {column}')\n","    plt.xlabel(column)\n","    plt.ylabel('Fréquence')\n","    plt.show()\n","\n","# Boîtes à moustaches pour les variables numériques\n","for column in final_data.select_dtypes(include=['int64', 'float64']).columns:\n","    plt.figure(figsize=(8, 6))\n","    sns.boxplot(y=final_data[column])\n","    plt.title(f'Boîte à moustaches de {column}')\n","    plt.ylabel(column)\n","    plt.show()\n","\n","# Diagrammes en barres pour les variables catégorielles\n","for column in final_data.select_dtypes(exclude=['int64', 'float64']).columns:\n","    plt.figure(figsize=(8, 6))\n","    sns.countplot(x=column, data=final_data)\n","    plt.title(f'Diagramme en barres de {column}')\n","    plt.xlabel(column)\n","    plt.ylabel('Comptage')\n","    plt.xticks(rotation=45)\n","    plt.show()\n","\n","# 3. Nettoyage des données : À faire en fonction des observations de l'EDA\n","\n","# 4. Analyse des relations entre les variables : À faire en fonction des observations de l'EDA\n","\n","# 5. Identification des tendances et des modèles : À faire en fonction des observations de l'EDA\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-tE1RFyxpWWv"},"outputs":[],"source":["############## SUITE EDA #############################\n","\n","# Calcul de la matrice de corrélation\n","correlation_matrix = final_data.corr()\n","\n","# Affichage de la matrice de corrélation\n","plt.figure(figsize=(12, 10))\n","sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n","plt.title(\"Matrice de corrélation des variables numériques\")\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qPmoBw94qCPE"},"outputs":[],"source":["################## SUITE EDA ###########################\n","\n","# Identifier les corrélations élevées\n","high_corr_threshold = 0.7  # Définir un seuil de corrélation élevé\n","high_corr_pairs = []\n","for i in range(len(correlation_matrix.columns)):\n","    for j in range(i+1, len(correlation_matrix.columns)):\n","        if abs(correlation_matrix.iloc[i, j]) > high_corr_threshold:\n","            high_corr_pairs.append((correlation_matrix.columns[i], correlation_matrix.columns[j], correlation_matrix.iloc[i, j]))\n","\n","if len(high_corr_pairs) > 0:\n","    print(\"Paires de variables fortement corrélées :\")\n","    for pair in high_corr_pairs:\n","        print(pair)\n","\n","# Supprimer les variables redondantes\n","# Vous pouvez choisir de supprimer l'une des variables de chaque paire de manière arbitraire, ou baser votre décision sur des considérations spécifiques à votre problème.\n","\n","# Supprimer les variables peu informatives\n","# Vous pouvez définir un seuil pour la corrélation minimale avec d'autres variables en dessous duquel une variable est considérée comme peu informative, puis la supprimer.\n","low_corr_threshold = 0.1  # Définir un seuil de corrélation faible\n","low_corr_variables = correlation_matrix.columns[correlation_matrix.abs().mean() < low_corr_threshold]\n","\n","if len(low_corr_variables) > 0:\n","    print(\"\\nVariables peu corrélées avec les autres variables :\")\n","    print(low_corr_variables)\n","\n","# Supprimer les variables identifiées comme redondantes ou peu informatives\n","# Assurez-vous de conserver une copie de votre jeu de données original si vous avez besoin de revenir en arrière\n","final_data_cleaned = final_data.drop(columns=low_corr_variables)  # Supprimer les variables peu informatives\n","\n","\n","print(final_data_cleaned.shape)\n","print(final_data_cleaned.columns)\n","\n","\n","############## FIN EDA ###################"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xX7NyAzHsSvz"},"outputs":[],"source":["############################# REDUCTION DES DIMENTIONNALITE PCA FEATURES NUMERIQUES ##################\n","from sklearn.decomposition import PCA\n","\n","# Appliquer l'ACP\n","pca = PCA(n_components=10)  # Choisir le nombre de composantes principales à conserver\n","X_numerical_reduced = pca.fit_transform(X_numerical)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D2ZPWUmysba9"},"outputs":[],"source":["############################# REDUCTION DES DIMENTIONNALITE SVD  FEATURES NUMERIQUES##################\n","\n","from sklearn.decomposition import TruncatedSVD\n","\n","# Appliquer la SVD\n","svd = TruncatedSVD(n_components=10)  # Choisir le nombre de composantes à conserver\n","X_numerical_reduced = svd.fit_transform(X_numerical)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t1YtiqjKs1q0"},"outputs":[],"source":["############################# REDUCTION DES DIMENTIONNALITE SVD  FEATURES CATEFORICIEL ##################\n","\n","\n","from sklearn.preprocessing import OneHotEncoder\n","\n","# Appliquer l'encodage one-hot\n","encoder = OneHotEncoder()\n","X_categorical_encoded = encoder.fit_transform(X_categorical)\n","\n","# Convertir en DataFrame\n","X_categorical_encoded_df = pd.DataFrame(X_categorical_encoded.toarray(), columns=encoder.get_feature_names_out())\n","\n","# Réduire la dimensionnalité (utiliser l'ACP ou la SVD comme décrit ci-dessus)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2019,"status":"ok","timestamp":1712179520707,"user":{"displayName":"Pr Kengne Research Team","userId":"06174679572112259337"},"user_tz":0},"id":"0Z0rN-zmXRJN","outputId":"70dec12b-9848-47a6-a515-64936fc1f59a"},"outputs":[{"output_type":"stream","name":"stdout","text":["               rr  A_frequency  FQDN_count     upper     lower   numeric  \\\n","0        0.000000     0.000000    0.549427  0.021083  0.319857  0.434684   \n","1        0.000000     0.000000    0.549427  0.021083  0.319857  0.434684   \n","2        0.000000     0.000000    0.549427  0.021083  0.319857  0.434684   \n","3        0.000000     0.000000    0.549427  0.021083  0.319857  0.434684   \n","4        0.000000     0.000000    0.549427  0.021083  0.319857  0.434684   \n","...           ...          ...         ...       ...       ...       ...   \n","1327382  0.101486     0.101486    0.647059  0.000000  0.294118  0.666667   \n","1327383  0.101486     0.101486    0.735294  0.000000  0.294118  0.916667   \n","1327384  0.101486     0.101486    0.264706  0.000000  0.294118  0.000000   \n","1327385  0.101486     0.101486    0.647059  0.000000  0.294118  0.666667   \n","1327386  0.101486     0.101486    0.647059  0.000000  0.294118  0.666667   \n","\n","          entropy   special    labels  labels_max  labels_average       len  \n","0        0.551800  0.489313  0.550153    0.214888        0.113748  0.310825  \n","1        0.551800  0.489313  0.550153    0.214888        0.113748  0.310825  \n","2        0.551800  0.489313  0.550153    0.214888        0.113748  0.310825  \n","3        0.551800  0.489313  0.550153    0.214888        0.113748  0.310825  \n","4        0.551800  0.489313  0.550153    0.214888        0.113748  0.310825  \n","...           ...       ...       ...         ...             ...       ...  \n","1327382  0.442238  0.750000  0.833333    0.166667        0.054645  0.272727  \n","1327383  0.614128  0.750000  0.833333    0.166667        0.071038  0.363636  \n","1327384  0.519600  0.125000  0.166667    0.166667        0.114754  0.181818  \n","1327385  0.442238  0.750000  0.833333    0.166667        0.054645  0.272727  \n","1327386  0.442238  0.750000  0.833333    0.166667        0.054645  0.272727  \n","\n","[1327387 rows x 12 columns]\n","Taille totale des caractéristiques numériques après transformations : (1327387, 12)\n"]}],"source":["######## je continue ici ###########\n","\n","\n","from sklearn.impute import SimpleImputer\n","\n","# Séparer les caractéristiques numériques et catégorielles\n","\n","# Imputation des valeurs manquantes pour les caractéristiques numériques\n","numerical_imputer = SimpleImputer(strategy='mean')\n","X_numerical_imputed = pd.DataFrame(numerical_imputer.fit_transform(X_numerical), columns=X_numerical.columns)\n","\n","\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# 2. Vérification des colonnes vides\n","if X_numerical.isnull().any().any():\n","    # Imputer les valeurs manquantes pour les caractéristiques numériques\n","    numerical_imputer = SimpleImputer(strategy='mean')\n","    X_numerical_imputed = pd.DataFrame(numerical_imputer.fit_transform(X_numerical), columns=X_numerical.columns)\n","\n","    #prepocessing des features numeriques soit  avec le  LabelEncoder soit le MinMaxScaler()\n","\n","    # Création d'un scaler\n","    scaler = MinMaxScaler()\n","\n","    # Ajustement du scaler aux données\n","    scaler.fit(X_numerical_imputed)\n","\n","    # Transformation des fonctionnalités numériques\n","    scaled_numeric_features = scaler.transform(X_numerical_imputed)\n","\n","    # print(scaled_numeric_features)\n","\n","    # Apres transformation Création d' un DataFrame à partir des valeurs transformées\n","\n","    scaled_df = pd.DataFrame(scaled_numeric_features, columns=X_numerical_imputed.columns)\n","\n","    # Afficher le DataFrame avec les valeurs transformées\n","    # print(\"Après transformation\")\n","    print(scaled_df)\n","\n","    total_size = scaled_df.shape\n","    print(\"Taille totale des caractéristiques numériques après transformations :\", total_size)\n","else:\n","    print(\"Pas de valeurs manquantes dans les caractéristiques numériques. Aucune imputation nécessaire.\")\n","\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1764,"status":"ok","timestamp":1712179525212,"user":{"displayName":"Pr Kengne Research Team","userId":"06174679572112259337"},"user_tz":0},"id":"C9KFndtMXeI8","outputId":"1c814a2c-c5dd-4b68-8026-bd5c0a19a809"},"outputs":[{"output_type":"stream","name":"stdout","text":["Après imputation\n","         rr_type    unique_ttl                   timestamp longest_word  \\\n","0        {'PTR'}  [1, 1, 1, 1]  2020-11-21 14:31:29.947599            2   \n","1        {'PTR'}        [1, 1]  2020-11-21 14:31:29.947599            2   \n","2        {'PTR'}  [1, 1, 1, 1]  2020-11-21 14:31:29.947599            2   \n","3        {'PTR'}        [1, 1]  2020-11-21 14:31:29.947599            2   \n","4          set()           [1]  2020-11-21 14:31:29.947599            2   \n","...          ...           ...                         ...          ...   \n","1327382    {'A'}        [1, 1]  2020-11-21 17:23:53.970643            4   \n","1327383    {'A'}        [1, 1]  2020-11-21 14:21:20.974091            2   \n","1327384    {'A'}        [1, 1]  2020-11-21 16:47:46.775938        arena   \n","1327385    {'A'}        [1, 1]  2020-11-21 15:30:48.467504            4   \n","1327386    {'A'}        [1, 1]  2020-11-21 17:56:31.624535            4   \n","\n","             sld  \n","0            192  \n","1            192  \n","2            192  \n","3            192  \n","4            192  \n","...          ...  \n","1327382      224  \n","1327383      192  \n","1327384  arenabg  \n","1327385      224  \n","1327386      224  \n","\n","[1327387 rows x 5 columns]\n","Taille totale des caractéristiques catégorielles après imputation : (1327387, 5)\n"]}],"source":["from sklearn.impute import SimpleImputer\n","\n","# Vérification des colonnes vides\n","if X_categorical.isnull().any().any():\n","    # Imputer les valeurs manquantes pour les caractéristiques catégorielles\n","    categorical_imputer = SimpleImputer(strategy='most_frequent')\n","    X_categorical_imputed = pd.DataFrame(categorical_imputer.fit_transform(X_categorical), columns=X_categorical.columns)\n","\n","    # Afficher le DataFrame avec les valeurs imputées\n","    print(\"Après imputation\")\n","    print(X_categorical_imputed)\n","\n","    total_size_categorical = X_categorical_imputed.shape\n","\n","    print(\"Taille totale des caractéristiques catégorielles après imputation :\", total_size_categorical)\n","\n","else:\n","    print(\"Pas de valeurs manquantes dans les caractéristiques catégorielles. Aucune imputation nécessaire.\")\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":651,"referenced_widgets":["9f37ca116d934aeea04f4d5df945cafc","a3afd9b5344e488eb975ace431968ac3","385ac930faba45d4a8c20aa540690931","aae669207d3e49dcbd8f67c41fc42be5","e567bccb396f4669acb76ab29203679b","627d1090834241c59f85395226f82f8d","ed1da62206a94045bf060018bb4bde44","f7620ffa1f784ab2bfd26d45840f869d","4a03a882557c46298752259bd9f726d1","8a23286c8bd24125a1e0dbf5717dd64f","5f331793810c40a7a05459c3c5766957","d75fa30f5236496fb74b191a8b817fde","382ccfc01ccd4c79b963d5a68856b5cd","69409f4d49c14d91adee569db36d2c8d","4e11d3e69fad444c829ee4c57557c8c5","836db9a919704833a389272d03c6aecf","69159e9bb229410f88690d6100696233","93b0cf3bdaec40e7bf055ece020c965d","4e62b571783f439f8c05cb3e0bb7f826","46e8d2c1295740d1aa7eab8c3096976e","f4639de6c6a4480bbb6f38778acd227d","8a3e0ce0e9e44facb1f42ce08c76e57f","f3655d013e5a418b9206bc99ed31f416","f8f5587ed8ae436483acb44ddad3b787","a1c3fed766cd452a8e8a67d91ee88994","36a5d09bc4b14a11b4caf9aca4e31d25","fb2142f004ea41b1a2f26d057f6804a6","095753f26f904fba9d3536815f8b9bbb","6a45a2d2258242d78739c33b40a28431","602d507895944d008bff20807cc24449","a20bd4e222dc4618abb1f9d13e0e0e1e","cad2519173924aeaa50bf86d3ea7b657","33c565d31b8d4a60bac0264234544137","7b295a2b95cf4fecbd2e4bd9f0aafdb3","62c43e15145e4b968622a2fe13868a04","1e042a6aa8bc414bbdc482bcbc45681b","db7ba1bc7f794d5eb2f9e643c33e5d0c","591547a2af114ad881f0438c05004f6f","4d73ddf763a24d1683ff2a8a497e4e34","d47a26201bc448c2b77067ebea206677","ddfc56d7ad2c479f99992c9b5d268f0e","3c1242cd694747af8177d956ff7d606f","297343bc7e1f4fe78946ce1c538d0676","b7030554649c40499feb79eef8f14040"]},"executionInfo":{"elapsed":402553,"status":"ok","timestamp":1712179929639,"user":{"displayName":"Pr Kengne Research Team","userId":"06174679572112259337"},"user_tz":0},"id":"KmNgheaRZAaO","outputId":"a871ff38-e38b-4e5c-a950-52d48bf7a755"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f37ca116d934aeea04f4d5df945cafc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d75fa30f5236496fb74b191a8b817fde"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3655d013e5a418b9206bc99ed31f416"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b295a2b95cf4fecbd2e4bd9f0aafdb3"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'input_ids': <tf.Tensor: shape=(1327387, 62), dtype=int32, numpy=\n","array([[ 101, 1063, 1005, ...,    0,    0,    0],\n","       [ 101, 1063, 1005, ...,    0,    0,    0],\n","       [ 101, 1063, 1005, ...,    0,    0,    0],\n","       ...,\n","       [ 101, 1063, 1005, ...,    0,    0,    0],\n","       [ 101, 1063, 1005, ...,    0,    0,    0],\n","       [ 101, 1063, 1005, ...,    0,    0,    0]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(1327387, 62), dtype=int32, numpy=\n","array([[0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       ...,\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1327387, 62), dtype=int32, numpy=\n","array([[1, 1, 1, ..., 0, 0, 0],\n","       [1, 1, 1, ..., 0, 0, 0],\n","       [1, 1, 1, ..., 0, 0, 0],\n","       ...,\n","       [1, 1, 1, ..., 0, 0, 0],\n","       [1, 1, 1, ..., 0, 0, 0],\n","       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>}\n"]}],"source":["from transformers import BertTokenizer\n","\n","# Créer un tokenizer BERT\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","# Convertir les données catégorielles imputées en listes\n","categorical_features = [X_categorical_imputed[col].astype(str).tolist() for col in X_categorical_imputed.columns]\n","\n","# Fusionner les textes catégoriels en une seule liste de textes\n","combined_texts = [' '.join([f\"{col_value}\" for col_value in row]) for row in zip(*categorical_features)]\n","\n","# Tokeniser les textes combinés\n","tokens = tokenizer(combined_texts, padding=True, truncation=True, return_tensors='tf', max_length=64)\n","\n","# Afficher les tokens\n","print(tokens)\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":473},"executionInfo":{"elapsed":5533,"status":"ok","timestamp":1712179935165,"user":{"displayName":"Pr Kengne Research Team","userId":"06174679572112259337"},"user_tz":0},"id":"J6FHW2N0b6EW","outputId":"f8272112-5cc8-4592-ca78-fa8b590fd587"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["# Obtenir les longueurs de séquence\n","sequence_lengths = [len(token_ids) for token_ids in tokens['input_ids'].numpy()]\n","\n","# Afficher l'histogramme des longueurs de séquence\n","plt.hist(sequence_lengths, bins=20)\n","plt.title('Histogramme des longueurs de séquence')\n","plt.xlabel('Longueur de séquence')\n","plt.ylabel('Fréquence')\n","plt.show()"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1712179935166,"user":{"displayName":"Pr Kengne Research Team","userId":"06174679572112259337"},"user_tz":0},"id":"m1nt-lRVcsEC","outputId":"3eff956f-9440-48de-e0bc-14a693020133"},"outputs":[{"output_type":"stream","name":"stdout","text":["Longueur maximale du vecteur : 62\n","Longueur de la plus longue séquence : 62\n"]}],"source":["# Obtenir la longueur maximale\n","max_sequence_length = max(sequence_lengths)\n","\n","# Obtenir l'indice de la plus longue séquence\n","indice_plus_longue_sequence = sequence_lengths.index(max_sequence_length)\n","\n","# Longueur de la plus longue séquence\n","longueur_plus_longue_sequence = sequence_lengths[indice_plus_longue_sequence]\n","\n","print(f\"Longueur maximale du vecteur : {max_sequence_length}\")\n","print(f\"Longueur de la plus longue séquence : {longueur_plus_longue_sequence}\")\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1924,"status":"ok","timestamp":1712179937081,"user":{"displayName":"Pr Kengne Research Team","userId":"06174679572112259337"},"user_tz":0},"id":"Yhq8doxhbBGo","outputId":"e2a05f4b-429b-4642-ddaa-d55c5c6c1ab0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of data_num: (1327387, 12)\n","Shape of data_text: (1327387, 62)\n","Shape of labels: (1327387,)\n","[0 0 0 ... 3 3 3]\n"]}],"source":["from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.preprocessing import  LabelEncoder\n","\n","# Entrées pour l'entraînement\n","data_num = scaled_df\n","data_text = pad_sequences(tokens['input_ids'].numpy(), maxlen=max_sequence_length, padding='post')\n","\n","# verification les données numériques sont correctes\n","print(\"Shape of data_num:\", data_num.shape)\n","\n","# verification les données textuelles sont correctes après le rembourrage\n","print(\"Shape of data_text:\", data_text.shape)\n","\n","# verification les étiquettes sont correctes\n","print(\"Shape of labels:\", y.shape)\n","\n","# Encodage des étiquettes\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)\n","\n","print(y_encoded)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":156,"referenced_widgets":["45c53474c083441db7491b15f808c879","cf7c53d75ad743ca9629341f9383d58c","8cf49fbda56e4ed38a8cf1cb3c987483","593cb3a4dbed48b4b183c353ab5c4d36","39a8db57b4f84db2bef772349268c93e","237fe1d6eaff40f5b94b9a27c115758f","36ac877aa0194ab2b1e0e60443e8ef4d","764fe1561db446fba49551948e22dc23","45a8a0feaf634218a0e47880cd8859e5","7b6d6036d7344f759d0fe7d10e41c5fd","83586844e3c849588c6d82b58df72f6d"]},"executionInfo":{"elapsed":7908,"status":"ok","timestamp":1712179944979,"user":{"displayName":"Pr Kengne Research Team","userId":"06174679572112259337"},"user_tz":0},"id":"Ch7-S6fud8qI","outputId":"3eb610fe-e568-4690-ee61-74e8686fc6cb"},"outputs":[{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45c53474c083441db7491b15f808c879"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]}],"source":["from transformers import TFBertModel, BertTokenizer\n","from tensorflow.keras import layers, Model\n","\n","# Entrées\n","input_num = layers.Input(shape=(scaled_df.shape[1],))\n","input_text = layers.Input(shape=(data_text.shape[1],), dtype=tf.int32)\n","\n","# Branches du modèle\n","# Branche numérique - FFN\n","num_branch = layers.Dense(128, activation='relu')(input_num)\n","num_branch = layers.Dense(64, activation='relu')(num_branch)\n","\n","# Branche textuelle - BERT\n","bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n","text_branch = bert_model(input_text)['pooler_output']\n","\n","# Fusion des branches\n","merged = layers.concatenate([num_branch, text_branch])\n","\n","# Couches supplémentaires après la fusion\n","merged = layers.Dropout(0.5)(merged)\n","merged = layers.Dense(16, activation='relu')(merged)\n","output = layers.Dense(4, activation='softmax')(merged)\n","\n","# Création et compilation du modèle\n","model = Model(inputs=[input_num, input_text], outputs=output)\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":73,"status":"ok","timestamp":1712179944983,"user":{"displayName":"Pr Kengne Research Team","userId":"06174679572112259337"},"user_tz":0},"id":"nMqGps5leYm5","outputId":"e49d65c9-ebe9-49d1-ab9c-bad79eafb37e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 12)]         0           []                               \n","                                                                                                  \n"," dense (Dense)                  (None, 128)          1664        ['input_1[0][0]']                \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, 62)]         0           []                               \n","                                                                                                  \n"," dense_1 (Dense)                (None, 64)           8256        ['dense[0][0]']                  \n","                                                                                                  \n"," tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_2[0][0]']                \n","                                thPoolingAndCrossAt                                               \n","                                tentions(last_hidde                                               \n","                                n_state=(None, 62,                                                \n","                                768),                                                             \n","                                 pooler_output=(Non                                               \n","                                e, 768),                                                          \n","                                 past_key_values=No                                               \n","                                ne, hidden_states=N                                               \n","                                one, attentions=Non                                               \n","                                e, cross_attentions                                               \n","                                =None)                                                            \n","                                                                                                  \n"," concatenate (Concatenate)      (None, 832)          0           ['dense_1[0][0]',                \n","                                                                  'tf_bert_model[0][1]']          \n","                                                                                                  \n"," dropout_37 (Dropout)           (None, 832)          0           ['concatenate[0][0]']            \n","                                                                                                  \n"," dense_2 (Dense)                (None, 16)           13328       ['dropout_37[0][0]']             \n","                                                                                                  \n"," dense_3 (Dense)                (None, 4)            68          ['dense_2[0][0]']                \n","                                                                                                  \n","==================================================================================================\n","Total params: 109,505,556\n","Trainable params: 109,505,556\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n"]}],"source":["print(model.summary())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mx6VhQ38eZ2J","outputId":"e65a37c8-a385-4e8a-953a-0415c69d5462"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n"," 5539/16593 [=========>....................] - ETA: 12:39:49 - loss: 1.0043 - accuracy: 0.5023"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","# Diviser les données en ensembles d'entraînement et de test\n","text_train, text_test, num_train, num_test, labels_train, labels_test = train_test_split(\n","    data_text,  # Utilisation de data_text\n","    scaled_df,\n","    y_encoded,\n","    test_size=0.2,\n","    random_state=42\n",")\n","\n","\n","########### premier test #############################################################\n","############ Meme sur deux epoch j'ai toujours un probleme de ressource RAM ##########\n","history = model.fit([num_train, text_train], labels_train, epochs=20, batch_size=64, validation_data=([num_test, text_test], labels_test))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6314,"status":"ok","timestamp":1710325460762,"user":{"displayName":"FOTSO TATCHUM YVANOL ROSLY","userId":"06840443639537519869"},"user_tz":0},"id":"8pmoshZ7t3cz","outputId":"005a7d29-f9d5-4d73-c997-4a0f4419bc8e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: keras-tuner in /usr/local/lib/python3.10/dist-packages (1.4.7)\n","Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.12.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n","Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (1.0.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.2.2)\n"]}],"source":["!pip install keras-tuner\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"NofpkDORlOam","outputId":"d4febe2f-7e3b-4d69-f501-8a2b05dd0500"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"name":"stdout","output_type":"stream","text":["\n","Search: Running Trial #1\n","\n","Value             |Best Value So Far |Hyperparameter\n","128               |128               |num_units\n","0.5               |0.5               |dropout\n","32                |32                |dense_units\n","32                |32                |batch_size\n","\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","  936/33185 [..............................] - ETA: 188:38:32 - loss: 1.0460 - accuracy: 0.4793"]}],"source":["import numpy as np\n","from sklearn.model_selection import train_test_split\n","from kerastuner.tuners import BayesianOptimization\n","from kerastuner.engine.hyperparameters import HyperParameters\n","from transformers import TFBertModel, BertTokenizer\n","from tensorflow.keras import layers, Model, Input\n","from sklearn.metrics import accuracy_score\n","\n","# Fonction pour construire le modèle\n","def build_model(hp):\n","    input_num = Input(shape=(scaled_df.shape[1],))\n","    input_text = Input(shape=(data_text.shape[1],), dtype=tf.int32)\n","\n","    # Branches du modèle\n","    # Branche numérique - FFN\n","    num_branch = layers.Dense(hp.Choice('num_units', values=[64, 128, 256]), activation='relu')(input_num)\n","    num_branch = layers.Dense(hp.Choice('num_units', values=[32, 64, 128]), activation='relu')(num_branch)\n","\n","    # Branche textuelle - BERT\n","    bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n","    text_branch = bert_model(input_text)['pooler_output']\n","\n","    # Fusion des branches\n","    merged = layers.concatenate([num_branch, text_branch])\n","\n","    # Couches supplémentaires après la fusion\n","    merged = layers.Dropout(hp.Choice('dropout', values=[0.3, 0.5]))(merged)\n","    merged = layers.Dense(hp.Choice('dense_units', values=[16, 32, 64]), activation='relu')(merged)\n","\n","    output = layers.Dense(4, activation='softmax')(merged)\n","\n","    model = Model(inputs=[input_num, input_text], outputs=output)\n","\n","    batch_size = hp.Choice('batch_size', values=[16, 32, 64])\n","    model.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","    return model\n","\n","# Division des données en ensembles d'entraînement et de test\n","text_train, text_test, num_train, num_test, labels_train, labels_test = train_test_split(\n","    data_text,\n","    scaled_df,\n","    y_encoded,\n","    test_size=0.2,\n","    random_state=42\n",")\n","\n","# Recherche des meilleurs hyperparamètres\n","tuner = BayesianOptimization(\n","    build_model,\n","    objective='val_accuracy',\n","    max_trials=5,\n","    hyperparameters=HyperParameters(),\n","    directory='./my_dir/',\n","    project_name='bert_ffn_hyperparam_tuning'\n",")\n","\n","tuner.search([num_train, text_train], labels_train, epochs=10, validation_data=([num_test, text_test], labels_test))\n","\n","# Obtention des meilleurs hyperparamètres trouvés\n","best_hps = tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters\n","print(f\"Meilleurs hyperparamètres: {best_hps}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ViQM6GFsnWsL"},"outputs":[],"source":["best_hyperparameters = best_hps.get_config()\n","print(\"Best Hyperparameters:\")\n","for key, value in best_hyperparameters.items():\n","    print(f\"{key}: {value}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fa7vZSDMnieY"},"outputs":[],"source":["\n","# Réutiliser les meilleurs hyperparamètres pour construire le modèle final\n","model = build_model(best_hps)\n","\n","# Entraîner le modèle\n","history = model.fit([num_train, text_train], labels_train, epochs=40, batch_size=16, validation_data=([num_test, text_test], labels_test))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rmPAyLuHoHsK"},"outputs":[],"source":["from sklearn.metrics import classification_report\n","\n","# Évaluation du modèle sur les données de test\n","evaluation_results = model.evaluate([num_test, text_test], labels_test)\n","\n","# Impression des résultats d'évaluation\n","print(\"Perte sur les données de test:\", evaluation_results[0])\n","print(\"Précision sur les données de test:\", evaluation_results[1])\n","\n","# Prédiction sur les données de test\n","y_pred = model.predict([num_test, text_test])\n","\n","print(y_pred)\n","\n","# Convertir les indices des classes prédites en étiquettes\n","y_pred_classes = np.argmax(y_pred, axis=1)\n","\n","# Afficher le rapport de classification\n","class_report = classification_report(labels_test, y_pred_classes)\n","print(\"Rapport de classification :\\n\", class_report)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-5YMtWcWoU7m"},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","\n","# Convertir les indices des classes prédites en étiquettes\n","y_true_classes = np.argmax(labels_test, axis=1) if labels_test.ndim > 1 else labels_test\n","y_pred_classes = np.argmax(y_pred, axis=1) if y_pred.ndim > 1 else y_pred\n","\n","# Calculer l'accuracy pour chaque classe\n","accuracies = []\n","for class_label in range(4):  # Il y a 4 classes numérotées de 0 à 3\n","    y_true_class = (y_true_classes == class_label).astype(int)\n","    y_pred_class = (y_pred_classes == class_label).astype(int)\n","    class_accuracy = accuracy_score(y_true_class, y_pred_class)\n","    accuracies.append(class_accuracy)\n","\n","# Afficher les accuracies pour chaque classe\n","for class_label, accuracy in enumerate(accuracies):\n","    print(f\"Accuracy for class {class_label}: {accuracy}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZPJYjZhpowq0"},"outputs":[],"source":["# Extraction of training metrics\n","training_loss = history.history['loss']\n","training_accuracy = history.history['accuracy']\n","validation_loss = history.history['val_loss']\n","validation_accuracy = history.history['val_accuracy']\n","\n","# Plotting loss and accuracy curves separately\n","epochs = range(1, len(training_loss) + 1)\n","\n","# Plotting training and validation curves\n","plt.figure(figsize=(12, 6))\n","\n","# Plotting training and validation loss\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs, training_loss, label='Training loss')\n","plt.plot(epochs, validation_loss, label='Validation loss')\n","plt.title('Loss Curve')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","# Plotting training and validation accuracy\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs, training_accuracy, label='Training accuracy')\n","plt.plot(epochs, validation_accuracy, label='Validation accuracy')\n","plt.title('Accuracy Curve')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","# Displaying both subplots\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TG28w37Ipe5k"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","\n","# Matrice de confusion\n","conf_matrix = confusion_matrix(labels_test, y_pred_classes)\n","class_names = ['heavy_attacks', 'heavy_benign', 'light_attacks', 'light_benign']\n","\n","df_cm = pd.DataFrame(conf_matrix, index=class_names, columns=class_names)\n","\n","# Afficher la matrice de confusion avec seaborn\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(df_cm, annot=True, fmt='g', cmap='Blues', cbar=False)\n","plt.title('Matrice de Confusion')\n","plt.xlabel('Prédictions')\n","plt.ylabel('Vraies valeurs')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hJOm0fsjp87g"},"outputs":[],"source":["# Vérifier la forme des tableaux labels_test et y_pred_classes\n","print(\"Shape of labels_test:\", labels_test.shape)\n","print(\"Shape of y_pred_classes:\", y_pred_classes.shape)\n","\n","from sklearn.preprocessing import LabelBinarizer\n","\n","# Binariser labels_test\n","lb = LabelBinarizer()\n","labels_test_binary = lb.fit_transform(labels_test)\n","\n","\n","from sklearn.metrics import roc_curve, auc\n","import matplotlib.pyplot as plt\n","\n","# Calcul des courbes ROC et AUC pour chaque classe\n","fpr = dict()\n","tpr = dict()\n","roc_auc = dict()\n","for i in range(4):\n","    fpr[i], tpr[i], _ = roc_curve(labels_test_binary[:, i], y_pred[:, i])\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","# Plotter les courbes ROC pour chaque classe\n","plt.figure(figsize=(8, 6))\n","for i in range(4):\n","    plt.plot(fpr[i], tpr[i], lw=2, label='Class %d (AUC = %0.2f)' % (i, roc_auc[i]))\n","\n","plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')\n","plt.xlabel('Taux de faux positifs (FPR)')\n","plt.ylabel('Taux de vrais positifs (TPR)')\n","plt.title('Courbes ROC pour chaque classe')\n","plt.legend(loc=\"lower right\")\n","plt.show()\n"]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"9f37ca116d934aeea04f4d5df945cafc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a3afd9b5344e488eb975ace431968ac3","IPY_MODEL_385ac930faba45d4a8c20aa540690931","IPY_MODEL_aae669207d3e49dcbd8f67c41fc42be5"],"layout":"IPY_MODEL_e567bccb396f4669acb76ab29203679b"}},"a3afd9b5344e488eb975ace431968ac3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_627d1090834241c59f85395226f82f8d","placeholder":"​","style":"IPY_MODEL_ed1da62206a94045bf060018bb4bde44","value":"tokenizer_config.json: 100%"}},"385ac930faba45d4a8c20aa540690931":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7620ffa1f784ab2bfd26d45840f869d","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4a03a882557c46298752259bd9f726d1","value":48}},"aae669207d3e49dcbd8f67c41fc42be5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a23286c8bd24125a1e0dbf5717dd64f","placeholder":"​","style":"IPY_MODEL_5f331793810c40a7a05459c3c5766957","value":" 48.0/48.0 [00:00&lt;00:00, 4.39kB/s]"}},"e567bccb396f4669acb76ab29203679b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"627d1090834241c59f85395226f82f8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed1da62206a94045bf060018bb4bde44":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f7620ffa1f784ab2bfd26d45840f869d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a03a882557c46298752259bd9f726d1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8a23286c8bd24125a1e0dbf5717dd64f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f331793810c40a7a05459c3c5766957":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d75fa30f5236496fb74b191a8b817fde":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_382ccfc01ccd4c79b963d5a68856b5cd","IPY_MODEL_69409f4d49c14d91adee569db36d2c8d","IPY_MODEL_4e11d3e69fad444c829ee4c57557c8c5"],"layout":"IPY_MODEL_836db9a919704833a389272d03c6aecf"}},"382ccfc01ccd4c79b963d5a68856b5cd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69159e9bb229410f88690d6100696233","placeholder":"​","style":"IPY_MODEL_93b0cf3bdaec40e7bf055ece020c965d","value":"vocab.txt: 100%"}},"69409f4d49c14d91adee569db36d2c8d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e62b571783f439f8c05cb3e0bb7f826","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_46e8d2c1295740d1aa7eab8c3096976e","value":231508}},"4e11d3e69fad444c829ee4c57557c8c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4639de6c6a4480bbb6f38778acd227d","placeholder":"​","style":"IPY_MODEL_8a3e0ce0e9e44facb1f42ce08c76e57f","value":" 232k/232k [00:00&lt;00:00, 11.8MB/s]"}},"836db9a919704833a389272d03c6aecf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69159e9bb229410f88690d6100696233":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93b0cf3bdaec40e7bf055ece020c965d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e62b571783f439f8c05cb3e0bb7f826":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46e8d2c1295740d1aa7eab8c3096976e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f4639de6c6a4480bbb6f38778acd227d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a3e0ce0e9e44facb1f42ce08c76e57f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f3655d013e5a418b9206bc99ed31f416":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f8f5587ed8ae436483acb44ddad3b787","IPY_MODEL_a1c3fed766cd452a8e8a67d91ee88994","IPY_MODEL_36a5d09bc4b14a11b4caf9aca4e31d25"],"layout":"IPY_MODEL_fb2142f004ea41b1a2f26d057f6804a6"}},"f8f5587ed8ae436483acb44ddad3b787":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_095753f26f904fba9d3536815f8b9bbb","placeholder":"​","style":"IPY_MODEL_6a45a2d2258242d78739c33b40a28431","value":"tokenizer.json: 100%"}},"a1c3fed766cd452a8e8a67d91ee88994":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_602d507895944d008bff20807cc24449","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a20bd4e222dc4618abb1f9d13e0e0e1e","value":466062}},"36a5d09bc4b14a11b4caf9aca4e31d25":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cad2519173924aeaa50bf86d3ea7b657","placeholder":"​","style":"IPY_MODEL_33c565d31b8d4a60bac0264234544137","value":" 466k/466k [00:00&lt;00:00, 35.1MB/s]"}},"fb2142f004ea41b1a2f26d057f6804a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"095753f26f904fba9d3536815f8b9bbb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a45a2d2258242d78739c33b40a28431":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"602d507895944d008bff20807cc24449":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a20bd4e222dc4618abb1f9d13e0e0e1e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cad2519173924aeaa50bf86d3ea7b657":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33c565d31b8d4a60bac0264234544137":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b295a2b95cf4fecbd2e4bd9f0aafdb3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_62c43e15145e4b968622a2fe13868a04","IPY_MODEL_1e042a6aa8bc414bbdc482bcbc45681b","IPY_MODEL_db7ba1bc7f794d5eb2f9e643c33e5d0c"],"layout":"IPY_MODEL_591547a2af114ad881f0438c05004f6f"}},"62c43e15145e4b968622a2fe13868a04":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d73ddf763a24d1683ff2a8a497e4e34","placeholder":"​","style":"IPY_MODEL_d47a26201bc448c2b77067ebea206677","value":"config.json: 100%"}},"1e042a6aa8bc414bbdc482bcbc45681b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ddfc56d7ad2c479f99992c9b5d268f0e","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3c1242cd694747af8177d956ff7d606f","value":570}},"db7ba1bc7f794d5eb2f9e643c33e5d0c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_297343bc7e1f4fe78946ce1c538d0676","placeholder":"​","style":"IPY_MODEL_b7030554649c40499feb79eef8f14040","value":" 570/570 [00:00&lt;00:00, 53.0kB/s]"}},"591547a2af114ad881f0438c05004f6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d73ddf763a24d1683ff2a8a497e4e34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d47a26201bc448c2b77067ebea206677":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ddfc56d7ad2c479f99992c9b5d268f0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c1242cd694747af8177d956ff7d606f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"297343bc7e1f4fe78946ce1c538d0676":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7030554649c40499feb79eef8f14040":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"45c53474c083441db7491b15f808c879":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cf7c53d75ad743ca9629341f9383d58c","IPY_MODEL_8cf49fbda56e4ed38a8cf1cb3c987483","IPY_MODEL_593cb3a4dbed48b4b183c353ab5c4d36"],"layout":"IPY_MODEL_39a8db57b4f84db2bef772349268c93e"}},"cf7c53d75ad743ca9629341f9383d58c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_237fe1d6eaff40f5b94b9a27c115758f","placeholder":"​","style":"IPY_MODEL_36ac877aa0194ab2b1e0e60443e8ef4d","value":"model.safetensors: 100%"}},"8cf49fbda56e4ed38a8cf1cb3c987483":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_764fe1561db446fba49551948e22dc23","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_45a8a0feaf634218a0e47880cd8859e5","value":440449768}},"593cb3a4dbed48b4b183c353ab5c4d36":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b6d6036d7344f759d0fe7d10e41c5fd","placeholder":"​","style":"IPY_MODEL_83586844e3c849588c6d82b58df72f6d","value":" 440M/440M [00:00&lt;00:00, 523MB/s]"}},"39a8db57b4f84db2bef772349268c93e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"237fe1d6eaff40f5b94b9a27c115758f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36ac877aa0194ab2b1e0e60443e8ef4d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"764fe1561db446fba49551948e22dc23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45a8a0feaf634218a0e47880cd8859e5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7b6d6036d7344f759d0fe7d10e41c5fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83586844e3c849588c6d82b58df72f6d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}