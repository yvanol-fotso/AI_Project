{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive')\n","\n","chemin_zip_heavy_attacks = \"/content/drive/My Drive/yvanolfotso/dataset/AttacksHeavy.zip\"\n","chemin_zip_heavy_benign = \"/content/drive/My Drive/yvanolfotso/dataset/BenignHeavy.zip\"\n","\n","chemin_zip_light_attacks = \"/content/drive/My Drive/yvanolfotso/dataset/AttacksLight.zip\"\n","chemin_zip_light_benign = \"/content/drive/My Drive/yvanolfotso/dataset/BenignLight.zip\"\n","\n"],"metadata":{"id":"nltNb8v5vlHo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712212159666,"user_tz":0,"elapsed":71318,"user":{"displayName":"Pr Kengne Research Team","userId":"06174679572112259337"}},"outputId":"3e2b8d7e-670f-45c7-a009-93a4cb478636"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import zipfile\n","import os\n","import pandas as pd\n","\n","import shutil\n","\n","# Fonction pour extraire mes fichiers zip\n","def extraire_zip(chemin_zip):\n","    with zipfile.ZipFile(chemin_zip, 'r') as zip_ref:\n","        zip_ref.extractall(\"/content/extraction_temp\")  # Extraction  dans mon répertoire temporaire\n","\n","# Fonction pour charger les fichiers CSV d'un type spécifique (stateful ou stateless)\n","def charger_concatener_donnees(sous_dossier, prefixe):\n","    # Lister tous les fichiers CSV dans le sous-dossier\n","    fichiers_csv = [f for f in os.listdir(f\"{sous_dossier}\") if f.startswith(prefixe) and f.endswith('.csv')]\n","    # Lire chaque fichier CSV et le stocker dans une liste de DataFrames\n","    dataframes = [pd.read_csv(f\"{sous_dossier}/{f}\") for f in fichiers_csv]\n","    # Concaténer les DataFrames en un seul\n","    return pd.concat(dataframes, ignore_index=True)\n","\n","\n","# Extraire les fichiers zip\n","extraire_zip(chemin_zip_heavy_attacks)\n","extraire_zip(chemin_zip_heavy_benign)\n","extraire_zip(chemin_zip_light_attacks)\n","extraire_zip(chemin_zip_light_benign)\n","\n","# Charger et concaténer les données de la même manière que vous l'avez fait auparavant\n","stateful_heavy_attack_data = charger_concatener_donnees(\"/content/extraction_temp/AttacksHeavy\", \"stateful\")\n","stateful_heavy_benign_data = charger_concatener_donnees(\"/content/extraction_temp/BenignHeavy\", \"stateful\")\n","stateless_heavy_attack_data = charger_concatener_donnees(\"/content/extraction_temp/AttacksHeavy\", \"stateless\")\n","stateless_heavy_benign_data = charger_concatener_donnees(\"/content/extraction_temp/BenignHeavy\", \"stateless\")\n","\n","stateful_light_attack_data = charger_concatener_donnees(\"/content/extraction_temp/AttacksLight\", \"stateful\")\n","stateful_light_benign_data = charger_concatener_donnees(\"/content/extraction_temp/BenignLight\", \"stateful\")\n","stateless_light_attack_data = charger_concatener_donnees(\"/content/extraction_temp/AttacksLight\", \"stateless\")\n","stateless_light_benign_data = charger_concatener_donnees(\"/content/extraction_temp/BenignLight\", \"stateless\")\n","\n","# Supprimer le répertoire temporaire après avoir terminé\n","if os.path.exists(\"/content/extraction_temp\"):\n","    shutil.rmtree(\"/content/extraction_temp\")\n","\n","\n","#### concatenation  sur axis = 0 ########\n","\n","print(\" cocncatenantion sur axis = 0 sur les y \\n\")\n","print(\" Heavy attack\")\n","\n","heavy_attack = pd.concat([stateful_heavy_attack_data, stateless_heavy_attack_data], axis=0)\n","print(heavy_attack.shape)\n","\n","#### j'ajoute la classe / label ######\n","\n","heavy_attack['class'] = 'heavy_attacks'\n","print(heavy_attack.shape)\n","\n","print(\" \\n\")\n","print(\" Heavy Bengnin\")\n","\n","heavy_bengin = pd.concat([stateful_heavy_benign_data, stateless_heavy_benign_data], axis=0)\n","print(heavy_bengin.shape)\n","\n","#### j'ajoute la classe / label ######\n","\n","heavy_bengin['class'] = 'heavy_bengnin'\n","print(heavy_bengin.shape)\n","\n","print(\" \\n\")\n","print(\" Light attack\")\n","\n","light_attack = pd.concat([stateful_light_attack_data, stateless_light_attack_data], axis=0)\n","print(light_attack.shape)\n","\n","#### j'ajoute la classe / label ######\n","light_attack['class'] = 'light_attacks'\n","print(light_attack.shape)\n","\n","\n","print(\" \\n\")\n","print(\" Light Bengnin\")\n","\n","light_bengin = pd.concat([stateful_light_benign_data, stateless_light_benign_data], axis=0)\n","print(light_bengin.shape)\n","\n","#### j'ajoute la classe / label ######\n","light_bengin['class'] = 'light_bengnin'\n","print(light_bengin.shape)\n","\n","\n","final_data = pd.concat([heavy_attack, heavy_bengin,light_attack,light_bengin], axis=0, ignore_index=True)\n","\n","# Vérifier les dimensions du jeu de données final\n","print(final_data.shape)\n"],"metadata":{"id":"iMdCW_ASvmcH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712212402713,"user_tz":0,"elapsed":4682,"user":{"displayName":"Pr Kengne Research Team","userId":"06174679572112259337"}},"outputId":"5fe89036-f5e5-43a0-881e-2488c64b8688"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":[" cocncatenantion sur axis = 0 sur les y \n","\n"," Heavy attack\n","(323698, 42)\n","(323698, 43)\n"," \n","\n"," Heavy Bengnin\n","(250710, 42)\n","(250710, 43)\n"," \n","\n"," Light attack\n","(53978, 42)\n","(53978, 43)\n"," \n","\n"," Light Bengnin\n","(82859, 42)\n","(82859, 43)\n","(711245, 43)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OmNzw3fRCVIB"},"outputs":[],"source":["import pandas as pd\n","from math import log\n","import matplotlib.pyplot as plt\n","\n","def entropy(class_probabilities):\n","    \"\"\"Calculates the entropy of a list of class probabilities.\"\"\"\n","    return sum(-p * log(p, 2) for p in class_probabilities if p)\n","\n","def information_gain(data, feature_name, classes):\n","    total_entropy = entropy(data['class'].value_counts(normalize=True))\n","    values = data[feature_name].unique()\n","    weighted_entropy = 0.0\n","\n","    for v in values:\n","        subset_length = len(data[data[feature_name] == v])\n","        if subset_length == 0:\n","            continue  # Skip this value if subset length is zero to avoid division by zero\n","        subset_entropy = entropy(data[data[feature_name] == v]['class'].value_counts(normalize=True))\n","        weighted_entropy += (subset_length / len(data)) * subset_entropy\n","\n","    return total_entropy - weighted_entropy\n","\n","def calculate_information_gains(data, classes):\n","    information_gains = []\n","    total_entropy = entropy(data['class'].value_counts(normalize=True))\n","\n","    for feature_name in data.columns[:-1]:  # Exclude the last column which is the target variable\n","        gain = information_gain(data, feature_name, classes)\n","        information_gains.append((feature_name, gain))\n","\n","    return information_gains\n","\n","def select_top_features(data, classes, top_n=10):\n","    information_gains = calculate_information_gains(data, classes)\n","    top_features = sorted(information_gains, key=lambda x: x[1], reverse=True)[:top_n]\n","    return top_features\n","\n","# data = pd.read_csv(\"../data/BenignAndMaliciousDataset.csv\")\n","\n","data = final_data\n","\n","classes = data['class'].unique()\n","\n","# Calcul du gain d'information pour chaque caractéristique\n","# information_gains = calculate_information_gains(data, classes)\n","\n","# Afficher les gains d'information pour chaque caractéristique\n","# for feature_name, gain in information_gains:\n","#     print(\"Information Gain for feature\", feature_name, \":\", gain)\n","\n","# Sélectionner les 10 meilleures caractéristiques\n","top_features = select_top_features(data, classes, top_n=10)\n","\n","# Afficher les noms des 10 meilleures caractéristiques et leur gain d'information\n","for feature_name, gain in top_features:\n","    print(\"Feature:\", feature_name, \"Information Gain:\", gain)\n","\n","# Tracer les 10 meilleures caractéristiques\n","plt.figure(figsize=(10, 6))\n","plt.bar([x[0] for x in top_features], [x[1] for x in top_features], color='skyblue')\n","plt.xlabel('Features')\n","plt.ylabel('Information Gain')\n","plt.title('Top 10 Features with Highest Information Gain')\n","plt.xticks(rotation=45, ha='right')\n","plt.tight_layout()\n","plt.show()\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aXQNS17pCVIL"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","from math import log\n","\n","def entropy(class_probabilities):\n","    \"\"\"Calculates the entropy of a list of class probabilities.\"\"\"\n","    return sum(-p * log(p, 2) for p in class_probabilities if p)\n","\n","def information_gain(data, feature_name, classes):\n","    total_entropy = entropy([len(data[data['class'] == c]) / len(data) for c in classes])\n","    values = data[feature_name].unique()\n","    weighted_entropy = 0.0\n","\n","    for v in values:\n","        subset_length = len(data[data[feature_name] == v])\n","        if subset_length == 0:\n","            continue  # Skip this value if subset length is zero to avoid division by zero\n","        subset_entropy = entropy([len(data[(data[feature_name] == v) & (data['class'] == c)]) / subset_length for c in classes])\n","        weighted_entropy += (subset_length / len(data)) * subset_entropy\n","\n","    return total_entropy - weighted_entropy\n","\n","def calculate_information_gains(data, classes):\n","    information_gains = []\n","\n","    for feature_name in data.columns[:-1]:  # Exclude the last column which is the target variable\n","        gain = information_gain(data, feature_name, classes)\n","        information_gains.append((feature_name, gain))\n","\n","    return information_gains\n","\n","def gain_ratio(data, feature_name, classes):\n","    gain = information_gain(data, feature_name, classes)\n","    iv = intrinsic_value(data, feature_name)\n","    if iv == 0:  # Avoid division by zero\n","        return 0\n","    return gain / iv\n","\n","def intrinsic_value(data, feature_name):\n","    values = data[feature_name].unique()\n","    iv = sum(-(len(data[data[feature_name] == v]) / len(data)) * log(len(data[data[feature_name] == v]) / len(data), 2) for v in values if len(data[data[feature_name] == v]) > 0)\n","    return iv\n","\n","def select_top_features_with_gain_ratio(data, classes, top_n=10):\n","    gain_ratios = [(feature_name, gain_ratio(data, feature_name, classes)) for feature_name in data.columns[:-1]]\n","    top_features = sorted(gain_ratios, key=lambda x: x[1], reverse=True)[:top_n]\n","    return top_features\n","\n","def plot_top_features_gain_ratio(top_features, feature_names):\n","    top_feature_names = [feature_name for feature_name, _ in top_features]\n","    top_feature_ratios = [ratio for _, ratio in top_features]\n","\n","    plt.figure(figsize=(10, 6))\n","    plt.bar(top_feature_names, top_feature_ratios, color='lightgreen')\n","    plt.xlabel('Features')\n","    plt.ylabel('Gain Ratio')\n","    plt.title('Top 10 Features by Gain Ratio')\n","    plt.xticks(rotation=45, ha='right')\n","    plt.tight_layout()\n","    plt.show()\n","\n","# data = pd.read_csv(\"../data/BenignAndMaliciousDataset.csv\")\n","data = final_data\n","classes = data['class'].unique()\n","\n","# Sélectionner les 10 meilleures caractéristiques avec le ratio de gain\n","top_features_gain_ratio = select_top_features_with_gain_ratio(data, classes)\n","\n","# Tracer les 10 meilleures caractéristiques avec le gain ratio\n","plot_top_features_gain_ratio(top_features_gain_ratio, data.columns[:-1])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sqJUodCfCVIN"},"outputs":[],"source":["##### Dans ce cas plus la Gini est proche de Zeros plus plus le features est important cas il est pur (ie bon pour la sepration ) ##\n","\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# Fonctions pour calculer le Gini Index\n","def gini_index(data, feature_name, classes):\n","    \"\"\"Calculates the Gini index for a specific feature.\"\"\"\n","    total_instances = len(data)\n","    values = data[feature_name].unique()\n","    gini_index_feature = 0.0\n","\n","    for value in values:\n","        subset = data[data[feature_name] == value]\n","        probability = len(subset) / total_instances\n","        gini_index_feature += probability * gini(subset, classes)\n","\n","    return gini_index_feature\n","\n","def gini(data, classes):\n","    \"\"\"Calculates the Gini index for a subset of data.\"\"\"\n","    total_instances = len(data)\n","    gini_index_subset = 1.0\n","\n","    for c in classes:\n","        num_instances_in_class = len(data[data['class'] == c])\n","        if num_instances_in_class == 0:\n","            continue\n","        probability = num_instances_in_class / total_instances\n","        gini_index_subset -= probability ** 2\n","\n","    return gini_index_subset\n","\n","def select_top_features_with_gini_index(data, classes, top_n=10):\n","    gini_indices = [(feature_name, gini_index(data, feature_name, classes)) for feature_name in data.columns[:-1]]\n","    top_features = sorted(gini_indices, key=lambda x: x[1])[:top_n]\n","    return top_features\n","\n","# data = pd.read_csv(\"../data/BenignAndMaliciousDataset.csv\")\n","data = final_data\n","\n","classes = data['class'].unique()\n","\n","# Sélectionner les 10 meilleures caractéristiques avec le Gini Index\n","top_features_gini_index = select_top_features_with_gini_index(data, classes)\n","\n","# Afficher les noms et les indices de Gini des 10 meilleures caractéristiques\n","print(\"Top 10 Features with Gini Index:\")\n","for feature_name, gini_value in top_features_gini_index:\n","    print(\"Feature:\", feature_name, \", Gini Index:\", gini_value)\n","\n","# Tracer les 10 meilleures caractéristiques avec le Gini Index\n","def plot_top_features_gini_index(top_features, feature_names):\n","    top_feature_names = [feature_name for feature_name, _ in top_features]\n","    top_feature_gini = [gini_value for _, gini_value in top_features]\n","\n","    plt.figure(figsize=(10, 6))\n","    colors = ['skyblue' if gini_value > 0 else 'red' for gini_value in top_feature_gini]  # Couleur spéciale pour les Gini Index de zéro\n","    plt.bar(top_feature_names, top_feature_gini, color=colors)\n","    plt.xlabel('Features')\n","    plt.ylabel('Gini Index')\n","    plt.title('Top Features by Gini Index')\n","    plt.xticks(rotation=45, ha='right')\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Tracer les 10 meilleures caractéristiques avec le Gini Index\n","plot_top_features_gini_index(top_features_gini_index, data.columns[:-1])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y8l_S2cICVIb"},"outputs":[],"source":["#### Cas ou le Labels n'es pas numerique il faut l'encoder d'abord ##########\n","\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import LabelEncoder\n","\n","def calculate_pearson_correlation(data):\n","    # Convertir les étiquettes de classe en valeurs numériques\n","    label_encoder = LabelEncoder()\n","    labels_encoded = label_encoder.fit_transform(data['class'])\n","\n","    # Calculer le coefficient de corrélation de Pearson entre chaque caractéristique et la classe\n","    pearson_correlation = data.iloc[:, :-1].apply(lambda feature: np.abs(np.corrcoef(pd.to_numeric(feature, errors='coerce'), labels_encoded)[0, 1]))\n","\n","    return pearson_correlation\n","\n","def plot_top_features_pearson_correlation(pearson_correlation, feature_names):\n","    plt.figure(figsize=(10, 6))\n","    colors = ['orange' if correlation > 0 else 'red' for correlation in pearson_correlation]  # Couleur spéciale pour les coefficients de corrélation\n","    plt.bar(feature_names, pearson_correlation, color=colors)\n","    plt.xlabel('Features')\n","    plt.ylabel('Pearson Correlation')\n","    plt.title('Top Features by Pearson Correlation')\n","    plt.xticks(rotation=45, ha='right')\n","    plt.tight_layout()\n","    plt.show()\n","\n","# data = pd.read_csv(\"../data/BenignAndMaliciousDataset.csv\")\n","\n","data = final_data\n","\n","# Calculer les coefficients de corrélation de Pearson\n","pearson_correlation = calculate_pearson_correlation(data)\n","\n","# Afficher les coefficients de corrélation de Pearson pour chaque caractéristique\n","print(\"Pearson Correlation for each feature:\")\n","print(pearson_correlation)\n","\n","# Afficher les caractéristiques avec leur coefficient de corrélation de Pearson\n","plot_top_features_pearson_correlation(pearson_correlation, data.columns[:-1])\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}