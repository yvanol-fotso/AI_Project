{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Chargement des fichiers CSV\n",
    "benin_data = pd.read_csv(\"../data/dataBell_DNS Dataset/features_domain_benign_csv.csv\")\n",
    "malware_data = pd.read_csv(\"../data/Bell_DNS Dataset/features-domain_Malware.csv\")\n",
    "phishing_data = pd.read_csv(\"../data/Bell_DNS Dataset/features-domain_phishing.csv\")\n",
    "spam_data = pd.read_csv(\"../data/dataBell_DNS Dataset/features-domain_Spam.csv\")\n",
    "\n",
    "# Ajout de la colonne 'Class' \n",
    "benin_data['Class'] = 'Benin'\n",
    "malware_data['Class'] = 'Malware'\n",
    "phishing_data['Class'] = 'Phishing'\n",
    "spam_data['Class'] = 'Spam'\n",
    "\n",
    "\n",
    "# Concaténation de tous les ensembles de données\n",
    "all_data = pd.concat([benin_data, malware_data, phishing_data, spam_data], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spécifier la colonne cible je doit le faire avant l'encodage\n",
    "y = all_data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subdomain                  float64\n",
      "tld                         object\n",
      "sld                         object\n",
      "len                          int64\n",
      "numeric_percentage         float64\n",
      "char_distribution           object\n",
      "entropy                    float64\n",
      "1gram                       object\n",
      "2gram                       object\n",
      "3gram                       object\n",
      "longest_word                object\n",
      "distance_from_bad_words     object\n",
      "typos                       object\n",
      "obfuscate_at_sign           object\n",
      "dec_8                        int64\n",
      "dec_32                       int64\n",
      "oc_8                         int64\n",
      "oc_32                        int64\n",
      "hex_8                        int64\n",
      "hex_32                       int64\n",
      "puny_coded                   int64\n",
      "shortened                   object\n",
      "Domain_Name                 object\n",
      "Registrar                   object\n",
      "Registrant_Name             object\n",
      "Creation_Date_Time          object\n",
      "Emails                      object\n",
      "Domain_Age                  object\n",
      "Organization                object\n",
      "State                       object\n",
      "Country                     object\n",
      "Name_Server_Count           object\n",
      "Alexa_Rank                 float64\n",
      "Page_Rank                  float64\n",
      "Class                       object\n",
      "Unnamed: 34                 object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(all_data.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_data['Class'].unique())\n",
    "\n",
    "print(all_data.info())\n",
    "\n",
    "all_data.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "print(all_data.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value : {}        subdomain  Alexa_Rank  Page_Rank\n",
      "0            0.0         1.0        NaN\n",
      "1            0.0         1.0        NaN\n",
      "2            1.0         1.0        NaN\n",
      "3            1.0         1.0        NaN\n",
      "4            0.0         7.0        NaN\n",
      "...          ...         ...        ...\n",
      "50154        0.0        -1.0        NaN\n",
      "50155        0.0        -1.0        NaN\n",
      "50156        0.0        -1.0        NaN\n",
      "50157        0.0        -1.0        NaN\n",
      "50158        0.0        -1.0        NaN\n",
      "\n",
      "[50159 rows x 3 columns]\n",
      "Missing value : {}        subdomain  Alexa_Rank  Page_Rank\n",
      "0            0.0         1.0        NaN\n",
      "1            0.0         1.0        NaN\n",
      "2            1.0         1.0        NaN\n",
      "3            1.0         1.0        NaN\n",
      "4            0.0         7.0        NaN\n",
      "...          ...         ...        ...\n",
      "50154        0.0        -1.0        NaN\n",
      "50155        0.0        -1.0        NaN\n",
      "50156        0.0        -1.0        NaN\n",
      "50157        0.0        -1.0        NaN\n",
      "50158        0.0        -1.0        NaN\n",
      "\n",
      "[50159 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Concaténation de tous les ensembles de données\n",
    "all_data = pd.concat([benin_data, malware_data, phishing_data, spam_data], ignore_index=True)\n",
    "\n",
    "# Convertir les variables catégorielles en variables numériques\n",
    "all_data_encoded = pd.get_dummies(all_data, columns=['Class'], drop_first=True)\n",
    "\n",
    "# Exclure les colonnes non numériques\n",
    "\n",
    "\n",
    "#X = all_data_encoded.select_dtypes(include='number') ##### OK mais je ne veux pas faire ainsi \n",
    "\n",
    "X_numerical = all_data.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "\n",
    "# Vérifier les colonnes avec des valeurs manquantes\n",
    "missing_columns = X_numerical.columns[X_numerical.isnull().any()]\n",
    "\n",
    "print(\"Missing value : {}\", X_numerical[missing_columns])\n",
    "\n",
    "# Imputation des valeurs manquantes\n",
    "if not missing_columns.empty:\n",
    "    imputer = SimpleImputer(strategy='mean')  # Vous pouvez également utiliser 'median' ou 'most_frequent'\n",
    "    X_numerical[missing_columns] = imputer.fit_transform(X_numerical[missing_columns])\n",
    "\n",
    "\n",
    "\n",
    "#apres remplissage avec la valuer moyenne    \n",
    "print(\"Missing value : {}\", all_data[missing_columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Amelioration du code plus haut ######################\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 2. Vérification des colonnes vides\n",
    "if X_numerical.isnull().any().any():\n",
    "    # Imputer les valeurs manquantes pour les caractéristiques numériques\n",
    "    numerical_imputer = SimpleImputer(strategy='mean')\n",
    "    X_numerical_imputed = pd.DataFrame(numerical_imputer.fit_transform(X_numerical), columns=X_numerical.columns)\n",
    "\n",
    "    #prepocessing des features numeriques soit  avec le  LabelEncoder soit le MinMaxScaler()\n",
    "\n",
    "    # Création d'un scaler\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Ajustement du scaler aux données\n",
    "    scaler.fit(X_numerical_imputed)\n",
    "\n",
    "    # Transformation des fonctionnalités numériques\n",
    "    scaled_numeric_features = scaler.transform(X_numerical_imputed)\n",
    "\n",
    "\n",
    "    print(scaled_numeric_features)\n",
    "\n",
    "    # Apres transformation Création d' un DataFrame à partir des valeurs transformées\n",
    "\n",
    "    scaled_df = pd.DataFrame(scaled_numeric_features, columns=X_numerical_imputed.columns)\n",
    "\n",
    "    # Afficher le DataFrame avec les valeurs transformées\n",
    "    print(\"Après transformation\")\n",
    "    print(scaled_df)\n",
    "\n",
    "    total_size = scaled_df.shape\n",
    "    print(\"Taille totale des caractéristiques numériques après transformations :\", total_size)\n",
    "else:\n",
    "    print(\"Pas de valeurs manquantes dans les caractéristiques numériques. Aucune imputation nécessaire.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50159, 13)\n"
     ]
    }
   ],
   "source": [
    "print(X_numerical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de caractéristiques numeriques (car les autres ont été ignorer): 13\n"
     ]
    }
   ],
   "source": [
    "num_features = X_numerical.shape[1]\n",
    "print(\"Nombre total de caractéristiques numeriques (car les autres ont été ignorer):\", num_features)\n",
    "\n",
    "\n",
    "#donc dans notre fonction il faut passer un nombre de caracteristiques inferieur ou egale a 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subdomain             2.468767e-01\n",
       "len                   5.041374e+01\n",
       "numeric_percentage    4.878897e+01\n",
       "entropy               3.723222e-01\n",
       "dec_8                 0.000000e+00\n",
       "dec_32                6.559620e-03\n",
       "oc_8                  0.000000e+00\n",
       "oc_32                 7.974164e-05\n",
       "hex_8                 0.000000e+00\n",
       "hex_32                0.000000e+00\n",
       "puny_coded            4.682994e-03\n",
       "Alexa_Rank            3.907441e+12\n",
       "Page_Rank             0.000000e+00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### j'affiche voir la variance \n",
    "\n",
    "\n",
    "X_numerical.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropie de la colonne cible: 1.7561017914049486\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ... (votre code pour charger et prétraiter les données)\n",
    "\n",
    "# Calcul de l'entropie\n",
    "def calculate_entropy(y):\n",
    "    unique_classes, counts = np.unique(y, return_counts=True)\n",
    "    probabilities = counts / len(y)\n",
    "    entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "    return entropy\n",
    "\n",
    "# Spécifier la colonne cible\n",
    "y = all_data['Class']\n",
    "\n",
    "# Calcul de l'entropie pour la colonne cible\n",
    "entropy_y = calculate_entropy(y)\n",
    "print(\"Entropie de la colonne cible:\", entropy_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gain Ratio de la caractéristique: 0.11313698610951292\n"
     ]
    }
   ],
   "source": [
    "# Calcul de l'entropie de la caractéristique X\n",
    "def calculate_feature_entropy(X_feature, y):\n",
    "    unique_values, counts = np.unique(X_feature, return_counts=True)\n",
    "    entropy_feature = 0\n",
    "\n",
    "    for value, count in zip(unique_values, counts):\n",
    "        indices = X_feature == value\n",
    "        entropy_feature += (count / len(y)) * calculate_entropy(y[indices])\n",
    "\n",
    "    return entropy_feature\n",
    "\n",
    "# Calcul de l'information intrinsèque de la caractéristique X\n",
    "def calculate_intrinsic_information(X_feature):\n",
    "    unique_values, counts = np.unique(X_feature, return_counts=True)\n",
    "    intrinsic_info = 0\n",
    "\n",
    "    for count in counts:\n",
    "        intrinsic_info += (count / len(X_feature)) * np.log2(count / len(X_feature))\n",
    "\n",
    "    return -intrinsic_info\n",
    "\n",
    "# Calcul du Gain Ratio\n",
    "def calculate_gain_ratio(X_feature, y):\n",
    "    entropy_X = calculate_feature_entropy(X_feature, y)\n",
    "    intrinsic_info_X = calculate_intrinsic_information(X_feature)\n",
    "\n",
    "    gain = entropy_y - entropy_X\n",
    "    gain_ratio = gain / intrinsic_info_X\n",
    "\n",
    "    return gain_ratio\n",
    "\n",
    "# Exemple d'utilisation\n",
    "#X_feature_example = X['nom_de_la_caracteristique']  # Remplacez 'nom_de_la_caracteristique' par le nom de votre caractéristique\n",
    "\n",
    "X_feature_example = X_numerical['Alexa_Rank']\n",
    "\n",
    "gain_ratio_example = calculate_gain_ratio(X_feature_example, y)\n",
    "print(\"Gain Ratio de la caractéristique:\", gain_ratio_example)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
